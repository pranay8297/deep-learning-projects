{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "oaQ9KTDD4j2z",
        "hqB5hZWb-U07",
        "dhMXiDUHABeZ"
      ],
      "authorship_tag": "ABX9TyNsdvESFh70PUk17hPCfYcB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranay8297/deep-learning-projects/blob/master/HiGNN_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lJgxemOMeN6p"
      },
      "outputs": [],
      "source": [
        "# Get all functions from\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from random import Random\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "from torch_geometric.data import Data, InMemoryDataset\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.BRICS import FindBRICSBonds\n",
        "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
        "from rdkit import RDLogger\n",
        "\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, Sequential, Parameter, Bilinear\n",
        "\n",
        "from torch_scatter import scatter\n",
        "from torch_geometric.nn import global_add_pool, GATConv\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.nn.inits import glorot, reset\n",
        "from torch_geometric.nn.pool.pool import pool_batch\n",
        "from torch_geometric.nn.pool.consecutive import consecutive_cluster\n",
        "import wandb\n",
        "\n",
        "\n",
        "import os\n",
        "import torch.nn.init as init\n",
        "from torch_geometric.utils import softmax\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "from ipdb import set_trace as st"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section - 1: All the Helper Functions"
      ],
      "metadata": {
        "id": "lLGMhKQsJoZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell consists of all the helper functions and helper classes that are required to create a dataset.\n",
        "def onehot_encoding(x, allowable_set):\n",
        "    if x not in allowable_set:\n",
        "        raise Exception(\"input {0} not in allowable set{1}:\".format(\n",
        "            x, allowable_set))\n",
        "    return [x == s for s in allowable_set]\n",
        "\n",
        "\n",
        "def onehot_encoding_unk(x, allowable_set):\n",
        "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
        "    if x not in allowable_set:\n",
        "        x = allowable_set[-1]\n",
        "    return [x == s for s in allowable_set]\n",
        "\n",
        "\n",
        "def atom_attr(mol, explicit_H=False, use_chirality=True, pharmaco=True, scaffold=True):\n",
        "    if pharmaco:\n",
        "        mol = tag_pharmacophore(mol)\n",
        "    if scaffold:\n",
        "        mol = tag_scaffold(mol)\n",
        "\n",
        "    feat = []\n",
        "    for i, atom in enumerate(mol.GetAtoms()):\n",
        "        results = onehot_encoding_unk(\n",
        "            atom.GetSymbol(),\n",
        "            ['B', 'C', 'N', 'O', 'F', 'Si', 'P', 'S', 'Cl', 'As', 'Se', 'Br', 'Te', 'I', 'At', 'other'\n",
        "             ]) + onehot_encoding_unk(atom.GetDegree(),\n",
        "                                      [0, 1, 2, 3, 4, 5, 'other']) + \\\n",
        "                  [atom.GetFormalCharge(), atom.GetNumRadicalElectrons()] + \\\n",
        "                  onehot_encoding_unk(atom.GetHybridization(), [\n",
        "                      Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
        "                      Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.SP3D,\n",
        "                      Chem.rdchem.HybridizationType.SP3D2, 'other'\n",
        "                  ]) + [atom.GetIsAromatic()]\n",
        "        if not explicit_H:\n",
        "            results = results + onehot_encoding_unk(atom.GetTotalNumHs(),\n",
        "                                                    [0, 1, 2, 3, 4])\n",
        "        if use_chirality:\n",
        "            try:\n",
        "                results = results + onehot_encoding_unk(\n",
        "                    atom.GetProp('_CIPCode'),\n",
        "                    ['R', 'S']) + [atom.HasProp('_ChiralityPossible')]\n",
        "            # print(one_of_k_encoding_unk(atom.GetProp('_CIPCode'), ['R', 'S']) + [atom.HasProp('_ChiralityPossible')])\n",
        "            except:\n",
        "                results = results + [0, 0] + [atom.HasProp('_ChiralityPossible')]\n",
        "        if pharmaco:\n",
        "            results = results + [int(atom.GetProp('Hbond_donor'))] + [int(atom.GetProp('Hbond_acceptor'))] + \\\n",
        "                      [int(atom.GetProp('Basic'))] + [int(atom.GetProp('Acid'))] + \\\n",
        "                      [int(atom.GetProp('Halogen'))]\n",
        "        if scaffold:\n",
        "            results = results + [int(atom.GetProp('Scaffold'))]\n",
        "        feat.append(results)\n",
        "\n",
        "    return np.array(feat)\n",
        "\n",
        "\n",
        "def bond_attr(mol, use_chirality=True):\n",
        "    feat = []\n",
        "    index = []\n",
        "    n = mol.GetNumAtoms()\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if i != j:\n",
        "                bond = mol.GetBondBetweenAtoms(i, j)\n",
        "                if bond is not None:\n",
        "                    bt = bond.GetBondType()\n",
        "                    bond_feats = [\n",
        "                        bt == Chem.rdchem.BondType.SINGLE, bt == Chem.rdchem.BondType.DOUBLE,\n",
        "                        bt == Chem.rdchem.BondType.TRIPLE, bt == Chem.rdchem.BondType.AROMATIC,\n",
        "                        bond.GetIsConjugated(),\n",
        "                        bond.IsInRing()\n",
        "                    ]\n",
        "                    if use_chirality:\n",
        "                        bond_feats = bond_feats + onehot_encoding_unk(\n",
        "                            str(bond.GetStereo()),\n",
        "                            [\"STEREONONE\", \"STEREOANY\", \"STEREOZ\", \"STEREOE\"])\n",
        "                    feat.append(bond_feats)\n",
        "                    index.append([i, j])\n",
        "\n",
        "    return np.array(index), np.array(feat)\n",
        "\n",
        "\n",
        "def bond_break(mol):\n",
        "    results = np.array(sorted(list(FindBRICSBonds(mol))), dtype=np.long)\n",
        "\n",
        "    if results.size == 0:\n",
        "        cluster_idx = []\n",
        "        Chem.rdmolops.GetMolFrags(mol, asMols=True, frags=cluster_idx)\n",
        "        fra_edge_index, fra_edge_attr = bond_attr(mol)\n",
        "\n",
        "    else:\n",
        "        bond_to_break = results[:, 0, :]\n",
        "        bond_to_break = bond_to_break.tolist()\n",
        "        with Chem.RWMol(mol) as rwmol:\n",
        "            for i in bond_to_break:\n",
        "                rwmol.RemoveBond(*i)\n",
        "        rwmol = rwmol.GetMol()\n",
        "        cluster_idx = []\n",
        "        Chem.rdmolops.GetMolFrags(rwmol, asMols=True, sanitizeFrags=False, frags=cluster_idx)\n",
        "        fra_edge_index, fra_edge_attr = bond_attr(rwmol)\n",
        "        cluster_idx = torch.LongTensor(cluster_idx)\n",
        "\n",
        "    return fra_edge_index, fra_edge_attr, cluster_idx\n",
        "\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Scaffold and pharmacophore information utils\n",
        "# ---------------------------------------------\n",
        "# tag pharmoco features to each atom\n",
        "fun_smarts = {\n",
        "        'Hbond_donor': '[$([N;!H0;v3,v4&+1]),$([O,S;H1;+0]),n&H1&+0]',\n",
        "        'Hbond_acceptor': '[$([O,S;H1;v2;!$(*-*=[O,N,P,S])]),$([O,S;H0;v2]),$([O,S;-]),$([N;v3;!$(N-*=[O,N,P,S])]),n&X2&H0&+0,$([o,s;+0;!$([o,s]:n);!$([o,s]:c:n)])]',\n",
        "        'Basic': '[#7;+,$([N;H2&+0][$([C,a]);!$([C,a](=O))]),$([N;H1&+0]([$([C,a]);!$([C,a](=O))])[$([C,a]);!$([C,a](=O))]),$([N;H0&+0]([C;!$(C(=O))])([C;!$(C(=O))])[C;!$(C(=O))]),$([n;X2;+0;-0])]',\n",
        "        'Acid': '[C,S](=[O,S,P])-[O;H1,-1]',\n",
        "        'Halogen': '[F,Cl,Br,I]'\n",
        "        }\n",
        "FunQuery = dict([(pharmaco, Chem.MolFromSmarts(s)) for (pharmaco, s) in fun_smarts.items()])\n",
        "\n",
        "\n",
        "def tag_pharmacophore(mol):\n",
        "    for fungrp, qmol in FunQuery.items():\n",
        "        matches = mol.GetSubstructMatches(qmol)\n",
        "        match_idxes = []\n",
        "        for mat in matches:\n",
        "            match_idxes.extend(mat)\n",
        "        for i, atom in enumerate(mol.GetAtoms()):\n",
        "            tag = '1' if i in match_idxes else '0'\n",
        "            atom.SetProp(fungrp, tag)\n",
        "    return mol\n",
        "\n",
        "\n",
        "# tag scaffold information to each atom\n",
        "def tag_scaffold(mol):\n",
        "    core = MurckoScaffold.GetScaffoldForMol(mol)\n",
        "    match_idxes = mol.GetSubstructMatch(core)\n",
        "    for i, atom in enumerate(mol.GetAtoms()):\n",
        "        tag = '1' if i in match_idxes else '0'\n",
        "        atom.SetProp('Scaffold', tag)\n",
        "    return mol"
      ],
      "metadata": {
        "id": "kD6Ko2yBerpZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MolData(Data):\n",
        "    def __init__(self, fra_edge_index=None, fra_edge_attr=None, cluster_index=None, **kwargs):\n",
        "        super(MolData, self).__init__(**kwargs)\n",
        "        self.cluster_index = cluster_index\n",
        "        self.fra_edge_index = fra_edge_index\n",
        "        self.fra_edge_attr = fra_edge_attr\n",
        "\n",
        "    def __inc__(self, key, value, *args, **kwargs):\n",
        "        if key == 'cluster_index':\n",
        "            return int(self.cluster_index.max()) + 1\n",
        "        else:\n",
        "            return super().__inc__(key, value, *args, **kwargs)\n",
        "\n",
        "\n",
        "class MolDataset(InMemoryDataset):\n",
        "\n",
        "    def __init__(self, root, fpath, dataset, task_type, tasks, logger=None, smiles_col = 'smiles',\n",
        "                 transform=None, pre_transform=None, pre_filter=None):\n",
        "\n",
        "        self.tasks = tasks\n",
        "        self.dataset = dataset\n",
        "        self.task_type = task_type\n",
        "        self.logger = logger\n",
        "        self.fpath = fpath\n",
        "        self.smiles_col = smiles_col\n",
        "\n",
        "        super(MolDataset, self).__init__(root, transform, pre_transform, pre_filter)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return ['{}.csv'.format(self.dataset)]\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['{}.pt'.format(self.dataset)]\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "\n",
        "        df = pd.read_csv(self.fpath)\n",
        "        # df = df[:100]\n",
        "        smilesList = df[self.smiles_col].values\n",
        "\n",
        "        print(f'number of all smiles: {len(smilesList)}')\n",
        "        remained_smiles = []\n",
        "        canonical_smiles_list = []\n",
        "        for smiles in smilesList:\n",
        "            try:\n",
        "                canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
        "                remained_smiles.append(smiles)\n",
        "            except:\n",
        "                self.logger.info(f'not successfully processed smiles: {smiles}')\n",
        "                pass\n",
        "\n",
        "        print(f'number of successfully processed smiles: {len(remained_smiles)}')\n",
        "        df = df[df[self.smiles_col].isin(remained_smiles)].reset_index()\n",
        "\n",
        "        if len(self.tasks) > 0:\n",
        "            target = df[self.tasks].values\n",
        "\n",
        "        smilesList = df[self.smiles_col].values\n",
        "        data_list = []\n",
        "\n",
        "        for i, smi in enumerate(tqdm(smilesList)):\n",
        "\n",
        "            mol = Chem.MolFromSmiles(smi)\n",
        "            data = self.mol2graph(mol)\n",
        "\n",
        "            if data is not None and len(self.tasks) > 0:\n",
        "                label = target[i]\n",
        "                label[np.isnan(label)] = 666\n",
        "                data.y = torch.LongTensor([label])\n",
        "                if self.task_type == 'regression':\n",
        "                    data.y = torch.FloatTensor([label])\n",
        "                data_list.append(data)\n",
        "\n",
        "        if self.pre_filter is not None:\n",
        "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
        "        if self.pre_transform is not None:\n",
        "            data_list = [self.pre_transform(data) for data in data_list]\n",
        "\n",
        "        data, slices = self.collate(data_list)\n",
        "        torch.save((data, slices), self.processed_paths[0])\n",
        "\n",
        "    def mol2graph(self, mol):\n",
        "        smiles = Chem.MolToSmiles(mol)\n",
        "        if mol is None: return None\n",
        "        node_attr = atom_attr(mol, scaffold = False)\n",
        "        edge_index, edge_attr = bond_attr(mol)\n",
        "        fra_edge_index, fra_edge_attr, cluster_index = bond_break(mol)\n",
        "        data = MolData(\n",
        "            x=torch.FloatTensor(node_attr),\n",
        "            edge_index=torch.LongTensor(edge_index).t(),\n",
        "            edge_attr=torch.FloatTensor(edge_attr),\n",
        "            fra_edge_index=torch.LongTensor(fra_edge_index).t(),\n",
        "            fra_edge_attr=torch.FloatTensor(fra_edge_attr),\n",
        "            cluster_index=torch.LongTensor(cluster_index),\n",
        "            y=None,\n",
        "            smiles=smiles,\n",
        "        )\n",
        "        return data"
      ],
      "metadata": {
        "id": "9UEJO6rUr5z8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset_random(root, fpath, dataset, task_type, tasks=None, smiles_col = 'smiles', seed = 201):\n",
        "    # save_path = path + 'processed/train_valid_test_{}_seed_{}.ckpt'.format(dataset, seed)\n",
        "    # if os.path.isfile(save_path):\n",
        "    #     trn, val, test = torch.load(save_path)\n",
        "    #     return trn, val, test\n",
        "\n",
        "    pyg_dataset = MolDataset(root=root, fpath = fpath, dataset=dataset, task_type=task_type, tasks=tasks, smiles_col = smiles_col)\n",
        "    del pyg_dataset.data.smiles\n",
        "\n",
        "    # Seed randomness\n",
        "    random = Random(seed)\n",
        "    indices = list(range(len(pyg_dataset)))\n",
        "    random.seed(seed)\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    train_size = int(0.8 * len(pyg_dataset))\n",
        "    val_size = int(0.1 * len(pyg_dataset))\n",
        "    test_size = len(pyg_dataset) - train_size - val_size\n",
        "\n",
        "    trn_id, val_id, test_id = indices[:train_size], \\\n",
        "                              indices[train_size:(train_size + val_size)], \\\n",
        "                              indices[(train_size + val_size):]\n",
        "\n",
        "    trn, val, test = pyg_dataset[torch.LongTensor(trn_id)], \\\n",
        "                     pyg_dataset[torch.LongTensor(val_id)], \\\n",
        "                     pyg_dataset[torch.LongTensor(test_id)]\n",
        "\n",
        "    print(f'Total smiles = {len(pyg_dataset):,} | '\n",
        "                f'train smiles = {train_size:,} | '\n",
        "                f'val smiles = {val_size:,} | '\n",
        "                f'test smiles = {test_size:,}')\n",
        "\n",
        "    assert task_type == 'classification' or 'regression'\n",
        "    if task_type == 'classification':\n",
        "        weights = []\n",
        "        for i in range(len(tasks)):\n",
        "            validId = np.where((pyg_dataset.data.y[:, i] == 0) | (pyg_dataset.data.y[:, i] == 1))[0]\n",
        "            pos_len = (pyg_dataset.data.y[:, i][validId].sum()).item()\n",
        "            neg_len = len(pyg_dataset.data.y[:, i][validId]) - pos_len\n",
        "            weights.append([(neg_len + pos_len) / neg_len, (neg_len + pos_len) / pos_len])\n",
        "        trn.weights = weights\n",
        "\n",
        "    else:\n",
        "        trn.weights = None\n",
        "\n",
        "    # torch.save([trn, val, test], save_path)\n",
        "    return trn, val, test\n",
        "\n",
        "def get_loaders(root, fpath, dataset, task_type = 'regression', tasks=None, smiles_col = 'smiles', seed = 201, bs = 32):\n",
        "\n",
        "    '''\n",
        "    This function prepares data loaders by using other helper functions.\n",
        "\n",
        "    Args:\n",
        "      root {Str}: Path to store saved data. Not csv file path\n",
        "      path {Str}: Path to the CSV file\n",
        "      smiles_col {Str}: smiles column name in the csv file\n",
        "      label_col {Str or List}: Label column name in the csv file\n",
        "      task_type {Str}: is it regression or classification\n",
        "      bs {Int}: Batch size, use 32 if GPU available, else use 4.\n",
        "    '''\n",
        "\n",
        "    train, val, test = load_dataset_random(root, fpath, dataset, task_type, tasks = tasks, smiles_col = smiles_col, seed = seed)\n",
        "\n",
        "    # train, val, test = load_dataset_random()\n",
        "    train_dataloader = DataLoader(train, batch_size = bs, shuffle=True)\n",
        "    valid_dataloader = DataLoader(val, bs)\n",
        "    test_dataloader = DataLoader(test, bs)\n",
        "\n",
        "    return train_dataloader, valid_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "ehvYmfmVzcIx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project = \"PBS Run - 1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "qaEf32d08ig4",
        "outputId": "932c134d-9c80-4426-c557-788443b8cf1a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbindelapranay1997\u001b[0m (\u001b[33mcomp_chem\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "wandb version 0.15.4 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/home/ec2-user/project/wandb/run-20230628_192617-kj0u9dn0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/comp_chem/PBS%20Run%20-%201/runs/kj0u9dn0' target=\"_blank\">hearty-mountain-2</a></strong> to <a href='https://wandb.ai/comp_chem/PBS%20Run%20-%201' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/comp_chem/PBS%20Run%20-%201' target=\"_blank\">https://wandb.ai/comp_chem/PBS%20Run%20-%201</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/comp_chem/PBS%20Run%20-%201/runs/kj0u9dn0' target=\"_blank\">https://wandb.ai/comp_chem/PBS%20Run%20-%201/runs/kj0u9dn0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/comp_chem/PBS%20Run%20-%201/runs/kj0u9dn0?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f477ad5b790>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Cell consists of helper functions and base classes of HiGNN and the Message Passing Architecture.\n",
        "\n",
        "class FeatureAttention(nn.Module):\n",
        "    '''\n",
        "    c = (W5 (W4fG sum ) + W5 (W4fG max ))\n",
        "    '''\n",
        "    def __init__(self, channels, reduction):\n",
        "        super().__init__()\n",
        "        self.mlp = Sequential(\n",
        "            Linear(channels, channels // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            Linear(channels // reduction, channels, bias=False),\n",
        "        )\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        reset(self.mlp)\n",
        "\n",
        "    def forward(self, x, batch, size=None):\n",
        "        max_result = scatter(x, batch, dim=0, dim_size=size, reduce='max')\n",
        "        sum_result = scatter(x, batch, dim=0, dim_size=size, reduce='sum')\n",
        "        max_out = self.mlp(max_result)\n",
        "        sum_out = self.mlp(sum_result)\n",
        "        y = torch.sigmoid(max_out + sum_out)\n",
        "        y = y[batch]\n",
        "        return x * y\n",
        "\n",
        "# ---------------------------------------\n",
        "# Neural tensor networks conv\n",
        "# ---------------------------------------\n",
        "class NTNConv(MessagePassing):\n",
        "\n",
        "    '''\n",
        "    Base Message Passing Class for HiGNN. Core of the architecture.\n",
        "    alpha(i j) = tanh(hi W[ ]h + W[h , h ] + b)\n",
        "    d = d/a\n",
        "    mi = ReLU(reshape(alpha(i, j), hj , d))\n",
        "    β = W3T.[hi,mi,hi − mi].\n",
        "    hi = β.hi + (1 - β).mi\n",
        "    '''\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, slices, dropout, edge_dim=None, **kwargs):\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super(NTNConv, self).__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.slices = slices\n",
        "        self.dropout = dropout\n",
        "        self.edge_dim = edge_dim\n",
        "\n",
        "        self.weight_node = Parameter(torch.Tensor(in_channels,\n",
        "                                                  out_channels))\n",
        "        if edge_dim is not None:\n",
        "            self.weight_edge = Parameter(torch.Tensor(edge_dim,\n",
        "                                                      out_channels))\n",
        "        else:\n",
        "            self.weight_edge = self.register_parameter('weight_edge', None)\n",
        "\n",
        "        self.bilinear = Bilinear(out_channels, out_channels, slices, bias=False)\n",
        "\n",
        "        if self.edge_dim is not None:\n",
        "            self.linear = Linear(3 * out_channels, slices)\n",
        "        else:\n",
        "            self.linear = Linear(2 * out_channels, slices)\n",
        "\n",
        "        self._alpha = None\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        glorot(self.weight_node)\n",
        "        glorot(self.weight_edge)\n",
        "        self.bilinear.reset_parameters()\n",
        "        self.linear.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr=None, return_attention_weights=None):\n",
        "\n",
        "        x = torch.matmul(x, self.weight_node)\n",
        "\n",
        "        if self.weight_edge is not None:\n",
        "            assert edge_attr is not None\n",
        "            edge_attr = torch.matmul(edge_attr, self.weight_edge)\n",
        "\n",
        "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
        "\n",
        "        alpha = self._alpha\n",
        "        self._alpha = None\n",
        "\n",
        "        if isinstance(return_attention_weights, bool):\n",
        "            assert alpha is not None\n",
        "            return out, (edge_index, alpha)\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "    def message(self, x_i, x_j, edge_attr):\n",
        "        score = self.bilinear(x_i, x_j)\n",
        "        if edge_attr is not None:\n",
        "            vec = torch.cat((x_i, edge_attr, x_j), 1)\n",
        "            block_score = self.linear(vec)  # bias already included\n",
        "        else:\n",
        "            vec = torch.cat((x_i, x_j), 1)\n",
        "            block_score = self.linear(vec)\n",
        "        scores = score + block_score\n",
        "        alpha = torch.tanh(scores)\n",
        "        self._alpha = alpha\n",
        "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
        "\n",
        "        dim_split = self.out_channels // self.slices\n",
        "        out = torch.max(x_j, edge_attr).view(-1, self.slices, dim_split)\n",
        "\n",
        "        out = out * alpha.view(-1, self.slices, 1)\n",
        "        out = out.view(-1, self.out_channels)\n",
        "        return out\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}({}, {}, slices={})'.format(self.__class__.__name__,\n",
        "                                              self.in_channels,\n",
        "                                              self.out_channels, self.slices)\n",
        "\n",
        "class HiGNN(torch.nn.Module):\n",
        "    \"\"\"Hierarchical informative graph neural network for molecular representation.\n",
        "\n",
        "    There are 2 parts to HiGNN, one is at molecule level and other is at fragment level.\n",
        "    We do message passing at both levels (Atom Level and Fragment Level)\n",
        "\n",
        "    Once after Message Passing,\n",
        "      1. mean pool atom attributes\n",
        "      2. Calculate Cross Attention scores of each of those fragment attributes to molecule attributes\n",
        "      3. Weighted sum of fragment attributes using cross attention scores\n",
        "      4. Concatenate molecule attributes obtained from atom level features and fragment level features and get prediction.\n",
        "\n",
        "    After Message Passing\n",
        "\n",
        "    Readout:\n",
        "      hg = sigme(hi)\n",
        "\n",
        "    Cross Attention -\n",
        "    hg - Graph Readout\n",
        "    st - Fragment Representation of Message Passing.\n",
        "\n",
        "    alpha(t) = softmax(LeakyReLU(a [Whg || Wst]))\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, edge_dim, num_layers,\n",
        "                 slices, dropout, f_att=False, r=4, brics=True, cl=False, save_path = None, load_path = None, num_outputs = 1):\n",
        "        super(HiGNN, self).__init__()\n",
        "\n",
        "        self.hidden_channels = hidden_channels\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.num_outputs = num_outputs\n",
        "\n",
        "        self.f_att = f_att\n",
        "        self.brics = brics\n",
        "        self.cl = cl\n",
        "\n",
        "        self.save_path = save_path\n",
        "        self.load_path = load_path\n",
        "\n",
        "        self.pre_trained = True if load_path else False\n",
        "\n",
        "        # atom feature transformation\n",
        "        self.lin_a = Linear(in_channels, hidden_channels)\n",
        "        self.lin_b = Linear(edge_dim, hidden_channels)\n",
        "\n",
        "        # convs block\n",
        "        self.atom_convs = torch.nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            conv = NTNConv(hidden_channels, hidden_channels, slices=slices,\n",
        "                           dropout=dropout, edge_dim=hidden_channels)\n",
        "            self.atom_convs.append(conv)\n",
        "\n",
        "        self.lin_gate = Linear(3 * hidden_channels, hidden_channels)\n",
        "\n",
        "        if self.f_att:\n",
        "            self.feature_att = FeatureAttention(channels=hidden_channels, reduction=r)\n",
        "\n",
        "        if self.brics:\n",
        "            # mol-fra attention\n",
        "            self.cross_att = GATConv(hidden_channels, hidden_channels, heads=4,\n",
        "                                     dropout=dropout, add_self_loops=False,\n",
        "                                     negative_slope=0.01, concat=False)\n",
        "\n",
        "        if self.brics:\n",
        "            self.out = nn.ModuleList([Linear(2 * hidden_channels, out_channels) for i in range(self.num_outputs)])\n",
        "        else:\n",
        "            self.out = nn.ModuleList([Linear(hidden_channels, out_channels) for i in range(self.num_outputs)])\n",
        "\n",
        "        if self.cl:\n",
        "            self.lin_project = Linear(hidden_channels, int(hidden_channels/2))\n",
        "\n",
        "        if self.pre_trained:\n",
        "            self.load_model(load_model)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def save_model(self, save_path, complete_model = False):\n",
        "\n",
        "        model_dict = {\n",
        "            'atom_convs': self.atom_convs.state_dict(),\n",
        "            'lin_gate': self.lin_gate.state_dict(),\n",
        "            'lin_a': self.lin_a.state_dict(),\n",
        "            'lin_b': self.lin_b.state_dict(),\n",
        "        }\n",
        "\n",
        "        if self.f_att:\n",
        "            model_dict['feature_att'] =  self.feature_att.state_dict()\n",
        "\n",
        "        if self.brics:\n",
        "            model_dict['cross_att'] = self.cross_att.state_dict()\n",
        "\n",
        "        if complete_model:\n",
        "            model_dict['out'] = self.out.state_dict()\n",
        "\n",
        "        torch.save(model_dict, save_path)\n",
        "\n",
        "    def load_model(self, load_path):\n",
        "\n",
        "        model_dict = torch.load(load_path)\n",
        "        self.atom_convs.load_state_dict(model_dict['atom_convs'])\n",
        "        self.lin_gate.load_state_dict(model_dict['lin_gate'])\n",
        "        self.lin_a.load_state_dict(model_dict['lin_a'])\n",
        "        self.lin_b.load_state_dict(model_dict['lin_b'])\n",
        "\n",
        "        if self.f_att:\n",
        "            self.feature_att.load_state_dict(model_dict['feature_att'])\n",
        "\n",
        "        if self.brics:\n",
        "            self.cross_att.load_state_dict(model_dict['cross_att'])\n",
        "\n",
        "        if 'out' in model_dict:\n",
        "            self.out.load_state_dict(model_dict['out'])\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "\n",
        "        self.lin_a.reset_parameters()\n",
        "        self.lin_b.reset_parameters()\n",
        "\n",
        "        for conv in self.atom_convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "        self.lin_gate.reset_parameters()\n",
        "\n",
        "        if self.f_att:\n",
        "            self.feature_att.reset_parameters()\n",
        "\n",
        "        if self.brics:\n",
        "            self.cross_att.reset_parameters()\n",
        "\n",
        "        for i in self.out:\n",
        "            i.reset_parameters()\n",
        "\n",
        "        if self.cl:\n",
        "            self.lin_project.reset_parameters()\n",
        "\n",
        "    def forward(self, data):\n",
        "        # get mol input\n",
        "        x = data.x\n",
        "        edge_index = data.edge_index\n",
        "        edge_attr = data.edge_attr\n",
        "        batch = data.batch\n",
        "\n",
        "        x = F.relu(self.lin_a(x))  # (N, 46) -> (N, hidden_channels)\n",
        "        edge_attr = F.relu(self.lin_b(edge_attr))  # (N, 10) -> (N, hidden_channels)\n",
        "\n",
        "        # mol conv block\n",
        "        for i in range(0, self.num_layers):\n",
        "            h = F.relu(self.atom_convs[i](x, edge_index, edge_attr))\n",
        "            beta = self.lin_gate(torch.cat([x, h, x - h], 1)).sigmoid()\n",
        "            x = beta * x + (1 - beta) * h\n",
        "            if self.f_att:\n",
        "                x = self.feature_att(x, batch)\n",
        "\n",
        "        mol_vec = global_add_pool(x, batch).relu_()\n",
        "\n",
        "        if self.brics:\n",
        "            # get fragment input\n",
        "            fra_x = data.x\n",
        "            fra_edge_index = data.fra_edge_index\n",
        "            fra_edge_attr = data.fra_edge_attr\n",
        "            cluster = data.cluster_index\n",
        "\n",
        "            fra_x = F.relu(self.lin_a(fra_x))  # (N, 46) -> (N, hidden_channels)\n",
        "            fra_edge_attr = F.relu(self.lin_b(fra_edge_attr))  # (N, 10) -> (N, hidden_channels)\n",
        "\n",
        "            # fragment convs block\n",
        "            for i in range(0, self.num_layers):\n",
        "                fra_h = F.relu(self.atom_convs[i](fra_x, fra_edge_index, fra_edge_attr))\n",
        "                beta = self.lin_gate(torch.cat([fra_x, fra_h, fra_x - fra_h], 1)).sigmoid()\n",
        "                fra_x = beta * fra_x + (1 - beta) * fra_h\n",
        "\n",
        "                if self.f_att:\n",
        "                    fra_x = self.feature_att(fra_x, cluster)\n",
        "\n",
        "            fra_x = global_add_pool(fra_x, cluster).relu_()\n",
        "\n",
        "            # get fragment batch\n",
        "            cluster, perm = consecutive_cluster(cluster)\n",
        "            fra_batch = pool_batch(perm, data.batch)\n",
        "\n",
        "            # molecule-fragment attention\n",
        "            row = torch.arange(fra_batch.size(0), device=batch.device)\n",
        "            mol_fra_index = torch.stack([row, fra_batch], dim=0)\n",
        "            fra_vec = self.cross_att((fra_x, mol_vec), mol_fra_index).relu_()\n",
        "\n",
        "            vectors_concat = list()\n",
        "            vectors_concat.append(mol_vec)\n",
        "            vectors_concat.append(fra_vec)\n",
        "\n",
        "            out = torch.cat(vectors_concat, 1)\n",
        "\n",
        "            # molecule-fragment contrastive\n",
        "            if self.cl:\n",
        "                out = F.dropout(out, p=self.dropout, training=self.training)\n",
        "                return torch.cat([l(out) for l in self.out], dim = 1), self.lin_project(mol_vec).relu_(), self.lin_project(fra_vec).relu_()\n",
        "            else:\n",
        "                out = F.dropout(out, p=self.dropout, training=self.training)\n",
        "                return torch.cat([l(out) for l in self.out], dim = 1)\n",
        "        else:\n",
        "            assert self.cl is False\n",
        "            out = F.dropout(mol_vec, p=self.dropout, training=self.training)\n",
        "            return torch.cat([l(out) for l in self.out], dim = 1)\n",
        "\n",
        "def build_model(in_channels=45, hidden_channels = 64, out_channels = 1, edge_dim = 10, num_layers = 3, dropout = 0.2, slices = 2,\n",
        "                  f_att = True, r = 4, brics = True, cl = False, save_path = None, load_path = None, num_outputs = 1):\n",
        "\n",
        "    model = HiGNN(in_channels,\n",
        "                  hidden_channels = hidden_channels,\n",
        "                  out_channels = out_channels,\n",
        "                  edge_dim = edge_dim,\n",
        "                  num_layers = num_layers,\n",
        "                  dropout = dropout,\n",
        "                  slices = slices,\n",
        "                  f_att = f_att,\n",
        "                  r = r,\n",
        "                  brics = brics,\n",
        "                  cl = cl,\n",
        "                  save_path = save_path,\n",
        "                  load_path = load_path,\n",
        "                  num_outputs = num_outputs )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "m1Re7EtLfB_z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(criterion, out, y):\n",
        "\n",
        "    '''\n",
        "    criterion - Loss Function\n",
        "    out - Batch Size * num_outputs\n",
        "    y - Batch Size* num_outputs\n",
        "    '''\n",
        "\n",
        "    num_outputs = out.shape[-1]\n",
        "\n",
        "    if len(y.shape) == 1:\n",
        "        y = y.unsqueeze(dim = -1)\n",
        "    assert out.shape == y.shape\n",
        "\n",
        "    loss = criterion(out[:, 0].squeeze(), y[:, 0].squeeze())\n",
        "    for i in range(1, num_outputs):\n",
        "        loss += criterion(out[:, i].squeeze(), y[:, i].squeeze())\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "j0XM349-_VCr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, train_dataloader, val_dataloader, criterion_1, optimizer, scheduler, device, is_classification = False):\n",
        "\n",
        "    total_loss_train = []\n",
        "    total_loss_val = []\n",
        "    rmse_train = []\n",
        "    rmse_valid = []\n",
        "    c = 0\n",
        "\n",
        "    # st()\n",
        "    for data in tqdm(train_dataloader):\n",
        "        try:\n",
        "\n",
        "            data = data.to(device)\n",
        "            outputs = model(data)\n",
        "            loss = calculate_loss(criterion_1, outputs, data.y)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()  # Update parameters based on gradients.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # scheduler.step()\n",
        "            total_loss_train.append(loss.item())\n",
        "\n",
        "            if is_classification:\n",
        "                # Calculate ROC_AUC\n",
        "                rmse_train.append(roc_auc(train_label[:, 0].to(torch.device('cpu').numpy()), outputs[0].squeeze().detach().to(torch.device('cpu')).numpy()))\n",
        "            else:\n",
        "                rmse_train.append(np.sqrt(loss.item()))\n",
        "\n",
        "            c += 1\n",
        "            if (c%10 == 0):\n",
        "                wandb.log({\n",
        "                  \"Train Loss Running Mean\": np.mean(total_loss_train)\n",
        "                })\n",
        "                wandb.log({\n",
        "                  \"Train RMSE Running Mean\": np.mean(rmse_train)\n",
        "                })\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        c = 0\n",
        "        for data in val_dataloader:\n",
        "            try:\n",
        "                data = data.to(device)\n",
        "                outputs = model(data)\n",
        "\n",
        "                # loss = criterion_1(outputs.squeeze(), data.y.squeeze())\n",
        "                loss = calculate_loss(criterion_1, outputs, data.y)\n",
        "\n",
        "                c += 1\n",
        "                total_loss_val.append(loss.item())\n",
        "\n",
        "                if is_classification:\n",
        "                    # Calculate ROC_AUC\n",
        "                    rmse_valid.append(roc_auc(val_label[:, 0].to(torch.device('cpu').numpy()), outputs[0].squeeze().detach().to(torch.device('cpu')).numpy()))\n",
        "                else:\n",
        "                    rmse_valid.append(np.sqrt(loss.item()))\n",
        "                if (c%3 == 0):\n",
        "                    wandb.log({\n",
        "                      \"Validation Loss Running Mean\": np.mean(total_loss_val)\n",
        "                    })\n",
        "                    wandb.log({\n",
        "                      \"Validation RMSE Running Mean\": np.mean(rmse_valid)\n",
        "                    })\n",
        "\n",
        "                scheduler.step(np.mean(total_loss_val))\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "\n",
        "    return np.mean(total_loss_train), np.mean(total_loss_val), np.mean(rmse_train), np.mean(rmse_valid)\n",
        "\n",
        "def train_regression(model, train_dataloader, val_dataloader, learning_rate = 1e-03, min_lr = 1e-05, epochs = 50, wd = 1e-02):\n",
        "\n",
        "    hyperparameters = {\n",
        "        \"batch_size\": train_dataloader.batch_size,\n",
        "        \"num_epochs\": epochs,\n",
        "    }\n",
        "    wandb.config.update(hyperparameters)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = wd)\n",
        "    criterion_1 = nn.MSELoss()\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                            optimizer,\n",
        "                            mode = 'min',\n",
        "                            factor = 0.7,\n",
        "                            patience = 10,\n",
        "                            min_lr = min_lr\n",
        "                )\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "        train_loss, valid_loss, train_rmse, valid_rmse = train_one_epoch(model, train_dataloader, val_dataloader, criterion_1, optimizer, scheduler, device)\n",
        "        print(\n",
        "            f'Epochs: {epoch_num + 1} | Train Loss: {train_loss: .3f} \\\n",
        "            | Val Loss: {valid_loss: .3f} \\\n",
        "            | Train RMSE: {train_rmse: .3f} \\\n",
        "            | Val RMSE: {valid_rmse: .3f}')\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "HFSybyXH4i-c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section - 2: Train a Model"
      ],
      "metadata": {
        "id": "p4Y3P71RJh7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Data Loaders\n",
        "# train_loader, val_loader, test_loader = get_loaders('./root/', \"./chem_datasets/dataset-delaney.csv\", 'SMILES', 'measured log(solubility:mol/L)', 'esol_1')\n",
        "train_loader, val_loader, test_loader = get_loaders(root = './root/',\n",
        "                                                    fpath = \"./chem_datasets/dataset-delaney.csv\",\n",
        "                                                    dataset = \"esol\",\n",
        "                                                    task_type = 'regression',\n",
        "                                                    tasks = ['measured log(solubility:mol/L)'],\n",
        "                                                    smiles_col = 'SMILES')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOFvLC380SqP",
        "outputId": "1f90c395-1661-4ee4-fe02-c6f4ecaebffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total smiles = 1,144 | train smiles = 915 | val smiles = 114 | test smiles = 115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/ec2-user/virtenv/lib64/python3.7/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n",
            "/home/ec2-user/virtenv/lib64/python3.7/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "12RTe1fmZ9c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepapre Model\n",
        "hi_gnn = build_model()"
      ],
      "metadata": {
        "id": "JtYDFbaj4gsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre trained model if available. This cell is completely optional\n",
        "hi_gnn.load_model(\"./models/hignn_test_sol_pretrained.pth\")"
      ],
      "metadata": {
        "id": "4UnrCYGKB-rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train_regression(hi_gnn, train_loader, val_loader, learning_rate = 1e-03, min_lr = 1e-04, epochs = 250, wd = 1e-03)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIxkd5EL8cGp",
        "outputId": "c5ae5e45-dd0e-495c-f4a7-71efab01de01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  25.534             | Val Loss:  8.352             | Train RMSE:  4.935             | Val RMSE:  2.881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 35.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  8.989             | Val Loss:  4.708             | Train RMSE:  2.947             | Val RMSE:  2.139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  6.561             | Val Loss:  4.064             | Train RMSE:  2.498             | Val RMSE:  2.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 35.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  3.238             | Val Loss:  2.770             | Train RMSE:  1.755             | Val RMSE:  1.646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 35.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  2.124             | Val Loss:  1.757             | Train RMSE:  1.442             | Val RMSE:  1.319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 35.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 6 | Train Loss:  1.962             | Val Loss:  1.563             | Train RMSE:  1.386             | Val RMSE:  1.244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 35.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 7 | Train Loss:  1.634             | Val Loss:  1.305             | Train RMSE:  1.271             | Val RMSE:  1.130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 35.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 8 | Train Loss:  1.485             | Val Loss:  1.249             | Train RMSE:  1.203             | Val RMSE:  1.102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 9 | Train Loss:  1.297             | Val Loss:  1.154             | Train RMSE:  1.127             | Val RMSE:  1.063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 10 | Train Loss:  1.206             | Val Loss:  1.155             | Train RMSE:  1.082             | Val RMSE:  1.068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 11 | Train Loss:  1.051             | Val Loss:  0.876             | Train RMSE:  1.009             | Val RMSE:  0.927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 12 | Train Loss:  1.104             | Val Loss:  0.917             | Train RMSE:  1.034             | Val RMSE:  0.951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 13 | Train Loss:  0.994             | Val Loss:  0.905             | Train RMSE:  0.990             | Val RMSE:  0.936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 14 | Train Loss:  0.954             | Val Loss:  0.766             | Train RMSE:  0.970             | Val RMSE:  0.868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 15 | Train Loss:  0.948             | Val Loss:  0.926             | Train RMSE:  0.964             | Val RMSE:  0.937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 16 | Train Loss:  0.995             | Val Loss:  0.950             | Train RMSE:  0.982             | Val RMSE:  0.960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 17 | Train Loss:  0.905             | Val Loss:  0.848             | Train RMSE:  0.941             | Val RMSE:  0.906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 18 | Train Loss:  0.826             | Val Loss:  0.767             | Train RMSE:  0.898             | Val RMSE:  0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 19 | Train Loss:  0.828             | Val Loss:  0.872             | Train RMSE:  0.901             | Val RMSE:  0.932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 20 | Train Loss:  0.811             | Val Loss:  0.675             | Train RMSE:  0.892             | Val RMSE:  0.821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 21 | Train Loss:  0.772             | Val Loss:  0.918             | Train RMSE:  0.869             | Val RMSE:  0.942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 22 | Train Loss:  0.749             | Val Loss:  0.792             | Train RMSE:  0.857             | Val RMSE:  0.851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 23 | Train Loss:  0.711             | Val Loss:  0.716             | Train RMSE:  0.831             | Val RMSE:  0.841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 24 | Train Loss:  0.734             | Val Loss:  0.708             | Train RMSE:  0.846             | Val RMSE:  0.841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 25 | Train Loss:  0.756             | Val Loss:  0.636             | Train RMSE:  0.859             | Val RMSE:  0.792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 26 | Train Loss:  0.700             | Val Loss:  0.667             | Train RMSE:  0.828             | Val RMSE:  0.804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 27 | Train Loss:  0.718             | Val Loss:  0.715             | Train RMSE:  0.834             | Val RMSE:  0.835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 28 | Train Loss:  0.632             | Val Loss:  0.546             | Train RMSE:  0.786             | Val RMSE:  0.726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 29 | Train Loss:  0.621             | Val Loss:  0.572             | Train RMSE:  0.781             | Val RMSE:  0.749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 30 | Train Loss:  0.674             | Val Loss:  0.589             | Train RMSE:  0.810             | Val RMSE:  0.762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 31 | Train Loss:  0.603             | Val Loss:  0.584             | Train RMSE:  0.770             | Val RMSE:  0.757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 32 | Train Loss:  0.627             | Val Loss:  0.680             | Train RMSE:  0.782             | Val RMSE:  0.818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 33 | Train Loss:  0.632             | Val Loss:  0.444             | Train RMSE:  0.786             | Val RMSE:  0.644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 34 | Train Loss:  0.665             | Val Loss:  0.581             | Train RMSE:  0.805             | Val RMSE:  0.751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 35 | Train Loss:  0.630             | Val Loss:  0.600             | Train RMSE:  0.781             | Val RMSE:  0.757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 36 | Train Loss:  0.640             | Val Loss:  0.454             | Train RMSE:  0.791             | Val RMSE:  0.663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 37 | Train Loss:  0.614             | Val Loss:  0.745             | Train RMSE:  0.774             | Val RMSE:  0.850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 38 | Train Loss:  0.579             | Val Loss:  0.678             | Train RMSE:  0.751             | Val RMSE:  0.802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 39 | Train Loss:  0.578             | Val Loss:  0.526             | Train RMSE:  0.753             | Val RMSE:  0.710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 40 | Train Loss:  0.587             | Val Loss:  0.634             | Train RMSE:  0.760             | Val RMSE:  0.777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 41 | Train Loss:  0.549             | Val Loss:  0.566             | Train RMSE:  0.730             | Val RMSE:  0.741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 42 | Train Loss:  0.556             | Val Loss:  0.603             | Train RMSE:  0.739             | Val RMSE:  0.764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 43 | Train Loss:  0.584             | Val Loss:  0.639             | Train RMSE:  0.757             | Val RMSE:  0.797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 44 | Train Loss:  0.622             | Val Loss:  0.683             | Train RMSE:  0.782             | Val RMSE:  0.820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 45 | Train Loss:  0.588             | Val Loss:  0.616             | Train RMSE:  0.756             | Val RMSE:  0.769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 46 | Train Loss:  0.587             | Val Loss:  0.543             | Train RMSE:  0.758             | Val RMSE:  0.735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 47 | Train Loss:  0.596             | Val Loss:  0.479             | Train RMSE:  0.758             | Val RMSE:  0.673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 48 | Train Loss:  0.576             | Val Loss:  0.590             | Train RMSE:  0.750             | Val RMSE:  0.767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 49 | Train Loss:  0.583             | Val Loss:  0.708             | Train RMSE:  0.754             | Val RMSE:  0.833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 50 | Train Loss:  0.609             | Val Loss:  0.566             | Train RMSE:  0.772             | Val RMSE:  0.746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 51 | Train Loss:  0.580             | Val Loss:  0.561             | Train RMSE:  0.753             | Val RMSE:  0.743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 52 | Train Loss:  0.544             | Val Loss:  0.515             | Train RMSE:  0.731             | Val RMSE:  0.703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 53 | Train Loss:  0.537             | Val Loss:  0.556             | Train RMSE:  0.726             | Val RMSE:  0.744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 54 | Train Loss:  0.538             | Val Loss:  0.631             | Train RMSE:  0.719             | Val RMSE:  0.790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 55 | Train Loss:  0.582             | Val Loss:  0.634             | Train RMSE:  0.756             | Val RMSE:  0.792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 56 | Train Loss:  0.590             | Val Loss:  0.641             | Train RMSE:  0.761             | Val RMSE:  0.799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 57 | Train Loss:  0.560             | Val Loss:  0.576             | Train RMSE:  0.742             | Val RMSE:  0.756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 58 | Train Loss:  0.586             | Val Loss:  0.524             | Train RMSE:  0.758             | Val RMSE:  0.710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 59 | Train Loss:  0.584             | Val Loss:  0.711             | Train RMSE:  0.755             | Val RMSE:  0.840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 60 | Train Loss:  0.578             | Val Loss:  0.547             | Train RMSE:  0.754             | Val RMSE:  0.727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 61 | Train Loss:  0.542             | Val Loss:  0.553             | Train RMSE:  0.729             | Val RMSE:  0.740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 62 | Train Loss:  0.553             | Val Loss:  0.609             | Train RMSE:  0.737             | Val RMSE:  0.776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 63 | Train Loss:  0.551             | Val Loss:  0.614             | Train RMSE:  0.736             | Val RMSE:  0.772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 64 | Train Loss:  0.568             | Val Loss:  0.493             | Train RMSE:  0.748             | Val RMSE:  0.696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 65 | Train Loss:  0.550             | Val Loss:  0.656             | Train RMSE:  0.736             | Val RMSE:  0.801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 66 | Train Loss:  0.531             | Val Loss:  0.520             | Train RMSE:  0.717             | Val RMSE:  0.711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 67 | Train Loss:  0.575             | Val Loss:  0.510             | Train RMSE:  0.749             | Val RMSE:  0.703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 68 | Train Loss:  0.543             | Val Loss:  0.609             | Train RMSE:  0.727             | Val RMSE:  0.765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 69 | Train Loss:  0.567             | Val Loss:  0.603             | Train RMSE:  0.745             | Val RMSE:  0.759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 70 | Train Loss:  0.556             | Val Loss:  0.518             | Train RMSE:  0.738             | Val RMSE:  0.716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 71 | Train Loss:  0.546             | Val Loss:  0.550             | Train RMSE:  0.730             | Val RMSE:  0.730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 35.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 72 | Train Loss:  0.548             | Val Loss:  0.510             | Train RMSE:  0.731             | Val RMSE:  0.707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 35.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 73 | Train Loss:  0.563             | Val Loss:  0.456             | Train RMSE:  0.741             | Val RMSE:  0.658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 35.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 74 | Train Loss:  0.560             | Val Loss:  0.591             | Train RMSE:  0.740             | Val RMSE:  0.763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 35.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 75 | Train Loss:  0.534             | Val Loss:  0.521             | Train RMSE:  0.723             | Val RMSE:  0.716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 35.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 76 | Train Loss:  0.517             | Val Loss:  0.403             | Train RMSE:  0.708             | Val RMSE:  0.631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 77 | Train Loss:  0.521             | Val Loss:  0.635             | Train RMSE:  0.715             | Val RMSE:  0.794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 35.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 78 | Train Loss:  0.542             | Val Loss:  0.590             | Train RMSE:  0.728             | Val RMSE:  0.767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 35.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 79 | Train Loss:  0.498             | Val Loss:  0.624             | Train RMSE:  0.699             | Val RMSE:  0.782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 35.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 80 | Train Loss:  0.563             | Val Loss:  0.607             | Train RMSE:  0.743             | Val RMSE:  0.771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 81 | Train Loss:  0.557             | Val Loss:  0.539             | Train RMSE:  0.741             | Val RMSE:  0.723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 82 | Train Loss:  0.524             | Val Loss:  0.643             | Train RMSE:  0.718             | Val RMSE:  0.800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 83 | Train Loss:  0.506             | Val Loss:  0.679             | Train RMSE:  0.704             | Val RMSE:  0.823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 84 | Train Loss:  0.537             | Val Loss:  0.408             | Train RMSE:  0.728             | Val RMSE:  0.632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 85 | Train Loss:  0.574             | Val Loss:  0.538             | Train RMSE:  0.745             | Val RMSE:  0.724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 86 | Train Loss:  0.515             | Val Loss:  0.471             | Train RMSE:  0.710             | Val RMSE:  0.668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 87 | Train Loss:  0.574             | Val Loss:  0.486             | Train RMSE:  0.745             | Val RMSE:  0.695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 88 | Train Loss:  0.501             | Val Loss:  0.479             | Train RMSE:  0.699             | Val RMSE:  0.685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 89 | Train Loss:  0.517             | Val Loss:  0.590             | Train RMSE:  0.712             | Val RMSE:  0.750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 90 | Train Loss:  0.559             | Val Loss:  0.539             | Train RMSE:  0.738             | Val RMSE:  0.721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 91 | Train Loss:  0.546             | Val Loss:  0.494             | Train RMSE:  0.729             | Val RMSE:  0.689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 92 | Train Loss:  0.476             | Val Loss:  0.485             | Train RMSE:  0.679             | Val RMSE:  0.680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 93 | Train Loss:  0.497             | Val Loss:  0.603             | Train RMSE:  0.699             | Val RMSE:  0.775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 94 | Train Loss:  0.503             | Val Loss:  0.527             | Train RMSE:  0.702             | Val RMSE:  0.719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 95 | Train Loss:  0.520             | Val Loss:  0.546             | Train RMSE:  0.714             | Val RMSE:  0.738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 96 | Train Loss:  0.469             | Val Loss:  0.393             | Train RMSE:  0.679             | Val RMSE:  0.621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 97 | Train Loss:  0.504             | Val Loss:  0.538             | Train RMSE:  0.704             | Val RMSE:  0.726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 98 | Train Loss:  0.495             | Val Loss:  0.567             | Train RMSE:  0.694             | Val RMSE:  0.741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 99 | Train Loss:  0.510             | Val Loss:  0.464             | Train RMSE:  0.705             | Val RMSE:  0.674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 100 | Train Loss:  0.553             | Val Loss:  0.533             | Train RMSE:  0.737             | Val RMSE:  0.723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 101 | Train Loss:  0.540             | Val Loss:  0.422             | Train RMSE:  0.724             | Val RMSE:  0.635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 102 | Train Loss:  0.490             | Val Loss:  0.490             | Train RMSE:  0.693             | Val RMSE:  0.696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 103 | Train Loss:  0.477             | Val Loss:  0.545             | Train RMSE:  0.686             | Val RMSE:  0.737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 104 | Train Loss:  0.490             | Val Loss:  0.458             | Train RMSE:  0.694             | Val RMSE:  0.675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 105 | Train Loss:  0.479             | Val Loss:  0.534             | Train RMSE:  0.686             | Val RMSE:  0.724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 106 | Train Loss:  0.505             | Val Loss:  0.503             | Train RMSE:  0.700             | Val RMSE:  0.695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 107 | Train Loss:  0.495             | Val Loss:  0.413             | Train RMSE:  0.693             | Val RMSE:  0.629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 108 | Train Loss:  0.484             | Val Loss:  0.439             | Train RMSE:  0.683             | Val RMSE:  0.660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 109 | Train Loss:  0.511             | Val Loss:  0.507             | Train RMSE:  0.709             | Val RMSE:  0.704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 110 | Train Loss:  0.498             | Val Loss:  0.644             | Train RMSE:  0.699             | Val RMSE:  0.791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 111 | Train Loss:  0.517             | Val Loss:  0.604             | Train RMSE:  0.713             | Val RMSE:  0.769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 112 | Train Loss:  0.473             | Val Loss:  0.526             | Train RMSE:  0.679             | Val RMSE:  0.714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 113 | Train Loss:  0.522             | Val Loss:  0.503             | Train RMSE:  0.719             | Val RMSE:  0.698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 114 | Train Loss:  0.472             | Val Loss:  0.470             | Train RMSE:  0.679             | Val RMSE:  0.680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 115 | Train Loss:  0.478             | Val Loss:  0.440             | Train RMSE:  0.686             | Val RMSE:  0.662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 116 | Train Loss:  0.490             | Val Loss:  0.446             | Train RMSE:  0.692             | Val RMSE:  0.650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 117 | Train Loss:  0.457             | Val Loss:  0.508             | Train RMSE:  0.672             | Val RMSE:  0.692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 118 | Train Loss:  0.466             | Val Loss:  0.560             | Train RMSE:  0.674             | Val RMSE:  0.740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 119 | Train Loss:  0.472             | Val Loss:  0.462             | Train RMSE:  0.676             | Val RMSE:  0.676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 120 | Train Loss:  0.519             | Val Loss:  0.559             | Train RMSE:  0.705             | Val RMSE:  0.730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 121 | Train Loss:  0.543             | Val Loss:  0.525             | Train RMSE:  0.726             | Val RMSE:  0.718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 122 | Train Loss:  0.478             | Val Loss:  0.491             | Train RMSE:  0.686             | Val RMSE:  0.692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 123 | Train Loss:  0.550             | Val Loss:  0.541             | Train RMSE:  0.733             | Val RMSE:  0.723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 124 | Train Loss:  0.465             | Val Loss:  0.565             | Train RMSE:  0.676             | Val RMSE:  0.750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 125 | Train Loss:  0.482             | Val Loss:  0.517             | Train RMSE:  0.687             | Val RMSE:  0.708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 126 | Train Loss:  0.511             | Val Loss:  0.602             | Train RMSE:  0.709             | Val RMSE:  0.774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 127 | Train Loss:  0.491             | Val Loss:  0.391             | Train RMSE:  0.692             | Val RMSE:  0.619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 128 | Train Loss:  0.456             | Val Loss:  0.497             | Train RMSE:  0.667             | Val RMSE:  0.703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 129 | Train Loss:  0.463             | Val Loss:  0.468             | Train RMSE:  0.674             | Val RMSE:  0.675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 130 | Train Loss:  0.456             | Val Loss:  0.438             | Train RMSE:  0.670             | Val RMSE:  0.638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 131 | Train Loss:  0.460             | Val Loss:  0.455             | Train RMSE:  0.671             | Val RMSE:  0.669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 132 | Train Loss:  0.489             | Val Loss:  0.490             | Train RMSE:  0.692             | Val RMSE:  0.684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 133 | Train Loss:  0.483             | Val Loss:  0.563             | Train RMSE:  0.687             | Val RMSE:  0.747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 134 | Train Loss:  0.428             | Val Loss:  0.457             | Train RMSE:  0.648             | Val RMSE:  0.672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 135 | Train Loss:  0.474             | Val Loss:  0.439             | Train RMSE:  0.680             | Val RMSE:  0.658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 136 | Train Loss:  0.480             | Val Loss:  0.512             | Train RMSE:  0.679             | Val RMSE:  0.712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 137 | Train Loss:  0.476             | Val Loss:  0.471             | Train RMSE:  0.685             | Val RMSE:  0.684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 138 | Train Loss:  0.473             | Val Loss:  0.472             | Train RMSE:  0.679             | Val RMSE:  0.678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 139 | Train Loss:  0.467             | Val Loss:  0.449             | Train RMSE:  0.676             | Val RMSE:  0.657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 140 | Train Loss:  0.427             | Val Loss:  0.566             | Train RMSE:  0.644             | Val RMSE:  0.747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 141 | Train Loss:  0.479             | Val Loss:  0.346             | Train RMSE:  0.685             | Val RMSE:  0.582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 142 | Train Loss:  0.475             | Val Loss:  0.512             | Train RMSE:  0.683             | Val RMSE:  0.708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 143 | Train Loss:  0.454             | Val Loss:  0.464             | Train RMSE:  0.668             | Val RMSE:  0.677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 144 | Train Loss:  0.489             | Val Loss:  0.415             | Train RMSE:  0.694             | Val RMSE:  0.642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 145 | Train Loss:  0.462             | Val Loss:  0.541             | Train RMSE:  0.670             | Val RMSE:  0.734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 146 | Train Loss:  0.450             | Val Loss:  0.441             | Train RMSE:  0.665             | Val RMSE:  0.642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 147 | Train Loss:  0.444             | Val Loss:  0.434             | Train RMSE:  0.658             | Val RMSE:  0.657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 148 | Train Loss:  0.447             | Val Loss:  0.514             | Train RMSE:  0.661             | Val RMSE:  0.716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 149 | Train Loss:  0.456             | Val Loss:  0.499             | Train RMSE:  0.669             | Val RMSE:  0.704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 150 | Train Loss:  0.458             | Val Loss:  0.434             | Train RMSE:  0.665             | Val RMSE:  0.656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 151 | Train Loss:  0.479             | Val Loss:  0.386             | Train RMSE:  0.683             | Val RMSE:  0.617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 152 | Train Loss:  0.437             | Val Loss:  0.478             | Train RMSE:  0.655             | Val RMSE:  0.689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 153 | Train Loss:  0.467             | Val Loss:  0.461             | Train RMSE:  0.678             | Val RMSE:  0.675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 154 | Train Loss:  0.438             | Val Loss:  0.460             | Train RMSE:  0.654             | Val RMSE:  0.672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 155 | Train Loss:  0.452             | Val Loss:  0.517             | Train RMSE:  0.663             | Val RMSE:  0.715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 156 | Train Loss:  0.436             | Val Loss:  0.536             | Train RMSE:  0.654             | Val RMSE:  0.730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 157 | Train Loss:  0.435             | Val Loss:  0.485             | Train RMSE:  0.655             | Val RMSE:  0.684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 158 | Train Loss:  0.433             | Val Loss:  0.495             | Train RMSE:  0.651             | Val RMSE:  0.701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 159 | Train Loss:  0.481             | Val Loss:  0.522             | Train RMSE:  0.686             | Val RMSE:  0.719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 160 | Train Loss:  0.440             | Val Loss:  0.417             | Train RMSE:  0.656             | Val RMSE:  0.642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 161 | Train Loss:  0.407             | Val Loss:  0.426             | Train RMSE:  0.627             | Val RMSE:  0.629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 162 | Train Loss:  0.417             | Val Loss:  0.549             | Train RMSE:  0.639             | Val RMSE:  0.739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 163 | Train Loss:  0.493             | Val Loss:  0.393             | Train RMSE:  0.694             | Val RMSE:  0.626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 164 | Train Loss:  0.517             | Val Loss:  0.432             | Train RMSE:  0.711             | Val RMSE:  0.653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 165 | Train Loss:  0.441             | Val Loss:  0.490             | Train RMSE:  0.659             | Val RMSE:  0.700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 166 | Train Loss:  0.476             | Val Loss:  0.551             | Train RMSE:  0.679             | Val RMSE:  0.741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 167 | Train Loss:  0.461             | Val Loss:  0.506             | Train RMSE:  0.671             | Val RMSE:  0.698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 168 | Train Loss:  0.442             | Val Loss:  0.467             | Train RMSE:  0.659             | Val RMSE:  0.674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 169 | Train Loss:  0.448             | Val Loss:  0.563             | Train RMSE:  0.664             | Val RMSE:  0.750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 170 | Train Loss:  0.417             | Val Loss:  0.491             | Train RMSE:  0.638             | Val RMSE:  0.692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 171 | Train Loss:  0.448             | Val Loss:  0.407             | Train RMSE:  0.663             | Val RMSE:  0.636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 172 | Train Loss:  0.438             | Val Loss:  0.491             | Train RMSE:  0.654             | Val RMSE:  0.700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 173 | Train Loss:  0.425             | Val Loss:  0.527             | Train RMSE:  0.645             | Val RMSE:  0.723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 174 | Train Loss:  0.440             | Val Loss:  0.592             | Train RMSE:  0.653             | Val RMSE:  0.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 175 | Train Loss:  0.441             | Val Loss:  0.508             | Train RMSE:  0.657             | Val RMSE:  0.709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 176 | Train Loss:  0.467             | Val Loss:  0.441             | Train RMSE:  0.676             | Val RMSE:  0.659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 177 | Train Loss:  0.454             | Val Loss:  0.469             | Train RMSE:  0.669             | Val RMSE:  0.680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 178 | Train Loss:  0.464             | Val Loss:  0.435             | Train RMSE:  0.673             | Val RMSE:  0.658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 179 | Train Loss:  0.459             | Val Loss:  0.472             | Train RMSE:  0.673             | Val RMSE:  0.673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 180 | Train Loss:  0.437             | Val Loss:  0.464             | Train RMSE:  0.654             | Val RMSE:  0.679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 181 | Train Loss:  0.449             | Val Loss:  0.579             | Train RMSE:  0.662             | Val RMSE:  0.746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 182 | Train Loss:  0.444             | Val Loss:  0.508             | Train RMSE:  0.661             | Val RMSE:  0.701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 183 | Train Loss:  0.446             | Val Loss:  0.542             | Train RMSE:  0.660             | Val RMSE:  0.726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 184 | Train Loss:  0.421             | Val Loss:  0.492             | Train RMSE:  0.644             | Val RMSE:  0.694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 185 | Train Loss:  0.446             | Val Loss:  0.447             | Train RMSE:  0.662             | Val RMSE:  0.658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 186 | Train Loss:  0.427             | Val Loss:  0.473             | Train RMSE:  0.646             | Val RMSE:  0.679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 187 | Train Loss:  0.425             | Val Loss:  0.538             | Train RMSE:  0.646             | Val RMSE:  0.724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 188 | Train Loss:  0.414             | Val Loss:  0.451             | Train RMSE:  0.634             | Val RMSE:  0.663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 189 | Train Loss:  0.430             | Val Loss:  0.405             | Train RMSE:  0.645             | Val RMSE:  0.631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 190 | Train Loss:  0.434             | Val Loss:  0.525             | Train RMSE:  0.651             | Val RMSE:  0.716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 191 | Train Loss:  0.394             | Val Loss:  0.464             | Train RMSE:  0.619             | Val RMSE:  0.672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 192 | Train Loss:  0.442             | Val Loss:  0.423             | Train RMSE:  0.654             | Val RMSE:  0.636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 193 | Train Loss:  0.450             | Val Loss:  0.529             | Train RMSE:  0.666             | Val RMSE:  0.708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 194 | Train Loss:  0.405             | Val Loss:  0.355             | Train RMSE:  0.632             | Val RMSE:  0.582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 195 | Train Loss:  0.444             | Val Loss:  0.531             | Train RMSE:  0.659             | Val RMSE:  0.728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 196 | Train Loss:  0.435             | Val Loss:  0.418             | Train RMSE:  0.648             | Val RMSE:  0.639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 197 | Train Loss:  0.412             | Val Loss:  0.419             | Train RMSE:  0.634             | Val RMSE:  0.636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 198 | Train Loss:  0.429             | Val Loss:  0.551             | Train RMSE:  0.647             | Val RMSE:  0.732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 199 | Train Loss:  0.425             | Val Loss:  0.457             | Train RMSE:  0.647             | Val RMSE:  0.675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 200 | Train Loss:  0.405             | Val Loss:  0.505             | Train RMSE:  0.629             | Val RMSE:  0.705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 201 | Train Loss:  0.428             | Val Loss:  0.541             | Train RMSE:  0.650             | Val RMSE:  0.732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 202 | Train Loss:  0.396             | Val Loss:  0.524             | Train RMSE:  0.623             | Val RMSE:  0.719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 203 | Train Loss:  0.432             | Val Loss:  0.483             | Train RMSE:  0.651             | Val RMSE:  0.691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 204 | Train Loss:  0.456             | Val Loss:  0.507             | Train RMSE:  0.668             | Val RMSE:  0.699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 205 | Train Loss:  0.412             | Val Loss:  0.423             | Train RMSE:  0.637             | Val RMSE:  0.648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 206 | Train Loss:  0.418             | Val Loss:  0.403             | Train RMSE:  0.638             | Val RMSE:  0.633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 207 | Train Loss:  0.421             | Val Loss:  0.430             | Train RMSE:  0.644             | Val RMSE:  0.654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 208 | Train Loss:  0.431             | Val Loss:  0.484             | Train RMSE:  0.648             | Val RMSE:  0.689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 209 | Train Loss:  0.423             | Val Loss:  0.385             | Train RMSE:  0.639             | Val RMSE:  0.616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 210 | Train Loss:  0.402             | Val Loss:  0.414             | Train RMSE:  0.628             | Val RMSE:  0.643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 211 | Train Loss:  0.457             | Val Loss:  0.503             | Train RMSE:  0.666             | Val RMSE:  0.701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 212 | Train Loss:  0.419             | Val Loss:  0.448             | Train RMSE:  0.640             | Val RMSE:  0.660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 213 | Train Loss:  0.399             | Val Loss:  0.467             | Train RMSE:  0.625             | Val RMSE:  0.680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 214 | Train Loss:  0.396             | Val Loss:  0.373             | Train RMSE:  0.622             | Val RMSE:  0.610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 215 | Train Loss:  0.424             | Val Loss:  0.431             | Train RMSE:  0.647             | Val RMSE:  0.634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 216 | Train Loss:  0.374             | Val Loss:  0.439             | Train RMSE:  0.605             | Val RMSE:  0.653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 217 | Train Loss:  0.383             | Val Loss:  0.433             | Train RMSE:  0.612             | Val RMSE:  0.644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 218 | Train Loss:  0.408             | Val Loss:  0.376             | Train RMSE:  0.627             | Val RMSE:  0.612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 219 | Train Loss:  0.399             | Val Loss:  0.427             | Train RMSE:  0.623             | Val RMSE:  0.651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 220 | Train Loss:  0.417             | Val Loss:  0.575             | Train RMSE:  0.640             | Val RMSE:  0.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 221 | Train Loss:  0.429             | Val Loss:  0.356             | Train RMSE:  0.650             | Val RMSE:  0.584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 222 | Train Loss:  0.412             | Val Loss:  0.411             | Train RMSE:  0.634             | Val RMSE:  0.632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 223 | Train Loss:  0.414             | Val Loss:  0.416             | Train RMSE:  0.638             | Val RMSE:  0.639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 224 | Train Loss:  0.421             | Val Loss:  0.474             | Train RMSE:  0.641             | Val RMSE:  0.684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 225 | Train Loss:  0.417             | Val Loss:  0.435             | Train RMSE:  0.639             | Val RMSE:  0.644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 226 | Train Loss:  0.389             | Val Loss:  0.391             | Train RMSE:  0.618             | Val RMSE:  0.624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 227 | Train Loss:  0.395             | Val Loss:  0.340             | Train RMSE:  0.622             | Val RMSE:  0.578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 228 | Train Loss:  0.395             | Val Loss:  0.533             | Train RMSE:  0.622             | Val RMSE:  0.726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 229 | Train Loss:  0.404             | Val Loss:  0.398             | Train RMSE:  0.631             | Val RMSE:  0.628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 230 | Train Loss:  0.435             | Val Loss:  0.370             | Train RMSE:  0.652             | Val RMSE:  0.583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 231 | Train Loss:  0.406             | Val Loss:  0.398             | Train RMSE:  0.633             | Val RMSE:  0.628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 232 | Train Loss:  0.418             | Val Loss:  0.362             | Train RMSE:  0.640             | Val RMSE:  0.582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 233 | Train Loss:  0.424             | Val Loss:  0.452             | Train RMSE:  0.645             | Val RMSE:  0.660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 234 | Train Loss:  0.419             | Val Loss:  0.413             | Train RMSE:  0.639             | Val RMSE:  0.640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 235 | Train Loss:  0.408             | Val Loss:  0.360             | Train RMSE:  0.632             | Val RMSE:  0.592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 236 | Train Loss:  0.412             | Val Loss:  0.475             | Train RMSE:  0.636             | Val RMSE:  0.677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 237 | Train Loss:  0.401             | Val Loss:  0.453             | Train RMSE:  0.628             | Val RMSE:  0.672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 238 | Train Loss:  0.404             | Val Loss:  0.488             | Train RMSE:  0.631             | Val RMSE:  0.689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 239 | Train Loss:  0.405             | Val Loss:  0.366             | Train RMSE:  0.627             | Val RMSE:  0.600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 240 | Train Loss:  0.404             | Val Loss:  0.438             | Train RMSE:  0.628             | Val RMSE:  0.661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 241 | Train Loss:  0.419             | Val Loss:  0.410             | Train RMSE:  0.637             | Val RMSE:  0.640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 242 | Train Loss:  0.420             | Val Loss:  0.327             | Train RMSE:  0.642             | Val RMSE:  0.566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 243 | Train Loss:  0.404             | Val Loss:  0.381             | Train RMSE:  0.629             | Val RMSE:  0.614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 244 | Train Loss:  0.427             | Val Loss:  0.381             | Train RMSE:  0.645             | Val RMSE:  0.612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 245 | Train Loss:  0.394             | Val Loss:  0.336             | Train RMSE:  0.622             | Val RMSE:  0.571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 246 | Train Loss:  0.403             | Val Loss:  0.386             | Train RMSE:  0.623             | Val RMSE:  0.617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 247 | Train Loss:  0.370             | Val Loss:  0.399             | Train RMSE:  0.598             | Val RMSE:  0.631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 248 | Train Loss:  0.447             | Val Loss:  0.408             | Train RMSE:  0.658             | Val RMSE:  0.634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 249 | Train Loss:  0.378             | Val Loss:  0.439             | Train RMSE:  0.607             | Val RMSE:  0.654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 36.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 250 | Train Loss:  0.413             | Val Loss:  0.383             | Train RMSE:  0.635             | Val RMSE:  0.603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HiGNN(\n",
              "  (lin_a): Linear(in_features=45, out_features=64, bias=True)\n",
              "  (lin_b): Linear(in_features=10, out_features=64, bias=True)\n",
              "  (atom_convs): ModuleList(\n",
              "    (0): NTNConv(64, 64, slices=2)\n",
              "    (1): NTNConv(64, 64, slices=2)\n",
              "    (2): NTNConv(64, 64, slices=2)\n",
              "  )\n",
              "  (lin_gate): Linear(in_features=192, out_features=64, bias=True)\n",
              "  (feature_att): FeatureAttention(\n",
              "    (mlp): Sequential(\n",
              "      (0): Linear(in_features=64, out_features=16, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Linear(in_features=16, out_features=64, bias=False)\n",
              "    )\n",
              "  )\n",
              "  (cross_att): GATConv(64, 64, heads=4)\n",
              "  (out): ModuleList(\n",
              "    (0): Linear(in_features=128, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section - 3: Code for pretraining a model."
      ],
      "metadata": {
        "id": "oaQ9KTDD4j2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepapre the Data Loaders.\n",
        "train_loader, valid_loader, test_loader = get_loaders(root = './root/',\n",
        "                                                      fpath = \"./chem_datasets/deleney_assistant_ds_descriptors.csv\",\n",
        "                                                      dataset = \"deleney_assistant_ds_descriptors\",\n",
        "                                                      task_type = 'regression',\n",
        "                                                      tasks = ['MolWt', 'HeavyAtomMolWt', 'ExactMolWt', 'FpDensityMorgan1', 'Chi0v', 'Chi1v', 'LabuteASA', 'PEOE_VSA6', 'MolLogP', 'MolMR'],\n",
        "                                                      smiles_col = 'smiles'\n",
        "                                                  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6B-gqAREhQ7",
        "outputId": "70f63480-8a45-4dc4-928d-9208d300f232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total smiles = 89,051 | train smiles = 71,240 | val smiles = 8,905 | test smiles = 8,906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/ec2-user/virtenv/lib64/python3.7/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n",
            "/home/ec2-user/virtenv/lib64/python3.7/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a Model - Make Sure that num_outputs is the number of outputs that we are trying to predict, in this case 10\n",
        "hi_gnn = build_model(num_outputs = 10)"
      ],
      "metadata": {
        "id": "TGJVBIs15LkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get The device object\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "9JCFN8sY5rtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model by passing in data loaders model object\n",
        "hi_gnn = train_regression(hi_gnn, train_loader, valid_loader, learning_rate = 1e-03, min_lr = 1e-04, epochs = 3, wd = 1e-03)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U_q3faA5xNo",
        "outputId": "ac314060-a6d1-436a-9657-9fbb3a384708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2227/2227 [01:11<00:00, 31.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  1471.696             | Val Loss:  1486.437             | Train RMSE:  37.937             | Val RMSE:  38.152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2227/2227 [01:10<00:00, 31.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  1294.425             | Val Loss:  1277.298             | Train RMSE:  35.622             | Val RMSE:  35.341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2227/2227 [01:10<00:00, 31.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  1259.048             | Val Loss:  1276.295             | Train RMSE:  35.097             | Val RMSE:  35.398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "hi_gnn.save_model(\"./models/hignn_test_sol_pretrained.pth\")"
      ],
      "metadata": {
        "id": "lvJT6IyTAGT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code for prediction**"
      ],
      "metadata": {
        "id": "CkuZpDhWAsx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, dl, device = device):\n",
        "\n",
        "  '''\n",
        "  This model takes in model and dataloader and gives out predicted values for all the samples in the dataloader.\n",
        "\n",
        "  Args:\n",
        "    model {nn.module}: Model Object (HiGNN)\n",
        "    dl {DataLoader}: DataLoader object.\n",
        "    device {torch.device}: cuda if GPU available else cpu\n",
        "  '''\n",
        "  out = torch.Tensor([])\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for x in dl:\n",
        "      x = x.to(device)\n",
        "      outputs = model(x)\n",
        "      yhat = outputs.squeeze()\n",
        "      yhat = yhat.to(torch.device('cpu'))\n",
        "      out = torch.cat([out, yhat], dim = -1)\n",
        "  return out.numpy()"
      ],
      "metadata": {
        "id": "e5Lq44J6kF9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of Predicted values and real values.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y = torch.Tensor([])\n",
        "for x in test_loader:\n",
        "  y = torch.cat([y, x.y.squeeze()], dim = 0)\n",
        "\n",
        "y = y.numpy()\n",
        "y_hat = predict(hi_gnn, test_loader)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "# Plotting y\n",
        "plt.plot(y, label='True values')\n",
        "\n",
        "# Plotting yhat\n",
        "plt.plot(y_hat, label='Predicted values')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPebRT5zkoKu",
        "outputId": "0a633b7e-60f7-4675-8a7a-fba7541527cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u06mBUqblUBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section - 4 - input_PBS_final"
      ],
      "metadata": {
        "id": "hqB5hZWb-U07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./chem_datasets/input_PBS_final.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_iB7Qmq3-d8l",
        "outputId": "473a1699-1720-4e22-e3b6-63a97e10c9ae"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              SMILES  Average logS PBS\n",
              "0  [C@@H]1(CO)[C@@H](O)[C@@H](OCCOCCOCCOCCOCC#C)[...         -4.011887\n",
              "1  [C@@H]1(CO)[C@@H](O)[C@@H](OS(=O)(=O)NC(COCCOC...         -4.032920\n",
              "2  [C@@H]1(CO)[C@@H](OS(NC(COCCOCCOCCOCC#C)=O)(=O...         -3.962574\n",
              "3  [C@@H]1(COCCOCCOCCOCCOCC#C)[C@@H](O)[C@@H](O)[...         -4.007889\n",
              "4  [C@@H]1(COP(=O)(NCCOCCOCCOCCOCC#C)O)[C@@H](O)[...         -4.004365"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>Average logS PBS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[C@@H]1(CO)[C@@H](O)[C@@H](OCCOCCOCCOCCOCC#C)[...</td>\n",
              "      <td>-4.011887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[C@@H]1(CO)[C@@H](O)[C@@H](OS(=O)(=O)NC(COCCOC...</td>\n",
              "      <td>-4.032920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[C@@H]1(CO)[C@@H](OS(NC(COCCOCCOCCOCC#C)=O)(=O...</td>\n",
              "      <td>-3.962574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[C@@H]1(COCCOCCOCCOCCOCC#C)[C@@H](O)[C@@H](O)[...</td>\n",
              "      <td>-4.007889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[C@@H]1(COP(=O)(NCCOCCOCCOCCOCC#C)O)[C@@H](O)[...</td>\n",
              "      <td>-4.004365</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mlkMa-xG-TVn",
        "outputId": "cf9aa078-7e0d-4c3d-9ca5-c4312ad6a27b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Average logS PBS\n",
              "count       3719.000000\n",
              "mean          -5.443525\n",
              "std            1.347607\n",
              "min           -9.924453\n",
              "25%           -6.259637\n",
              "50%           -5.204120\n",
              "75%           -4.230992\n",
              "max           -3.581699"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Average logS PBS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3719.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-5.443525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.347607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-9.924453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-6.259637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-5.204120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>-4.230992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>-3.581699</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.to_csv('./chem_datasets/input_PBS_final_random.csv', index= None)"
      ],
      "metadata": {
        "id": "VfFVh6lIA4t-"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./chem_datasets/input_PBS_final_random.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DbZ-APUjBIc9",
        "outputId": "100076b1-da4c-48e8-db4d-13ca6e5b9b1e"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              SMILES  Average logS PBS\n",
              "0  N1(C(C2=CC=CC(NC(NC3=NN=C(SCCN(C)C)S3)=O)=C2)=...         -4.081970\n",
              "1  C1(F)=C(OCC2CCN2S(=O)(F)=O)C=CC(NC(=O)NC2=NN=C...         -5.416801\n",
              "2  C1(N(C(C2=CC=C(Br)S2)=O)CCCN2CCOCC2)=NC2=C(S1)...         -5.588380\n",
              "3  O=C1N(CCC2=CC3=C(NC(=O)N3)C=C2)C(CCN2C(=O)N3C=...         -5.193142\n",
              "4  C12=C(C(=O)N(CCC3=CC=C(OC)C(OC)=C3)C(CCN3C(=O)...         -6.879426"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>Average logS PBS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>N1(C(C2=CC=CC(NC(NC3=NN=C(SCCN(C)C)S3)=O)=C2)=...</td>\n",
              "      <td>-4.081970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C1(F)=C(OCC2CCN2S(=O)(F)=O)C=CC(NC(=O)NC2=NN=C...</td>\n",
              "      <td>-5.416801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C1(N(C(C2=CC=C(Br)S2)=O)CCCN2CCOCC2)=NC2=C(S1)...</td>\n",
              "      <td>-5.588380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>O=C1N(CCC2=CC3=C(NC(=O)N3)C=C2)C(CCN2C(=O)N3C=...</td>\n",
              "      <td>-5.193142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C12=C(C(=O)N(CCC3=CC=C(OC)C(OC)=C3)C(CCN3C(=O)...</td>\n",
              "      <td>-6.879426</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepapre the Data Loaders.\n",
        "train_loader, valid_loader, test_loader = get_loaders(root = './root/',\n",
        "                                                      fpath = \"./chem_datasets/input_PBS_final_random.csv\",\n",
        "                                                      dataset = \"input_PBS_final_random_iter_3\",\n",
        "                                                      task_type = 'regression',\n",
        "                                                      tasks = ['Average logS PBS'],\n",
        "                                                      smiles_col = 'SMILES'\n",
        "                                                  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GCsG5Fu-xni",
        "outputId": "80c4efd7-f5b2-4c46-aa7e-08f625fe318c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total smiles = 3,719 | train smiles = 2,975 | val smiles = 371 | test smiles = 373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/ec2-user/virtenv/lib64/python3.7/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n",
            "/home/ec2-user/virtenv/lib64/python3.7/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Build Model\n",
        "hi_gnn = build_model()"
      ],
      "metadata": {
        "id": "OJZ55UIe-7Cb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train_regression(hi_gnn, train_loader, valid_loader, learning_rate = 1e-03, min_lr = 1e-04, epochs = 250, wd = 1e-03)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXfSmjq6-uZM",
        "outputId": "a74dee10-9a17-4613-c0e7-12a8a6e2aecb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:03<00:00, 24.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  4.668             | Val Loss:  1.974             | Train RMSE:  1.977             | Val RMSE:  1.390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  1.881             | Val Loss:  1.757             | Train RMSE:  1.354             | Val RMSE:  1.313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  1.746             | Val Loss:  1.985             | Train RMSE:  1.307             | Val RMSE:  1.398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  1.560             | Val Loss:  1.465             | Train RMSE:  1.236             | Val RMSE:  1.204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  1.482             | Val Loss:  1.542             | Train RMSE:  1.205             | Val RMSE:  1.238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 6 | Train Loss:  1.444             | Val Loss:  1.479             | Train RMSE:  1.186             | Val RMSE:  1.202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 7 | Train Loss:  1.357             | Val Loss:  1.419             | Train RMSE:  1.151             | Val RMSE:  1.183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 8 | Train Loss:  1.352             | Val Loss:  1.477             | Train RMSE:  1.152             | Val RMSE:  1.209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 9 | Train Loss:  1.359             | Val Loss:  1.551             | Train RMSE:  1.157             | Val RMSE:  1.240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 10 | Train Loss:  1.334             | Val Loss:  1.410             | Train RMSE:  1.142             | Val RMSE:  1.177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 11 | Train Loss:  1.347             | Val Loss:  1.345             | Train RMSE:  1.143             | Val RMSE:  1.148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 12 | Train Loss:  1.319             | Val Loss:  1.415             | Train RMSE:  1.138             | Val RMSE:  1.186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 13 | Train Loss:  1.308             | Val Loss:  1.276             | Train RMSE:  1.130             | Val RMSE:  1.121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 14 | Train Loss:  1.332             | Val Loss:  1.302             | Train RMSE:  1.142             | Val RMSE:  1.132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 15 | Train Loss:  1.282             | Val Loss:  1.338             | Train RMSE:  1.121             | Val RMSE:  1.151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 16 | Train Loss:  1.259             | Val Loss:  1.299             | Train RMSE:  1.110             | Val RMSE:  1.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 17 | Train Loss:  1.276             | Val Loss:  1.310             | Train RMSE:  1.121             | Val RMSE:  1.140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 18 | Train Loss:  1.219             | Val Loss:  1.246             | Train RMSE:  1.090             | Val RMSE:  1.102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 19 | Train Loss:  1.255             | Val Loss:  1.222             | Train RMSE:  1.107             | Val RMSE:  1.100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 20 | Train Loss:  1.285             | Val Loss:  1.309             | Train RMSE:  1.124             | Val RMSE:  1.136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 21 | Train Loss:  1.257             | Val Loss:  1.244             | Train RMSE:  1.107             | Val RMSE:  1.106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 22 | Train Loss:  1.221             | Val Loss:  1.293             | Train RMSE:  1.089             | Val RMSE:  1.127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 23 | Train Loss:  1.199             | Val Loss:  1.273             | Train RMSE:  1.084             | Val RMSE:  1.115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 24 | Train Loss:  1.199             | Val Loss:  1.253             | Train RMSE:  1.085             | Val RMSE:  1.110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 25 | Train Loss:  1.186             | Val Loss:  1.231             | Train RMSE:  1.077             | Val RMSE:  1.102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 26 | Train Loss:  1.225             | Val Loss:  1.194             | Train RMSE:  1.095             | Val RMSE:  1.088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 27 | Train Loss:  1.212             | Val Loss:  1.222             | Train RMSE:  1.089             | Val RMSE:  1.096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 28 | Train Loss:  1.177             | Val Loss:  1.307             | Train RMSE:  1.074             | Val RMSE:  1.132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 29 | Train Loss:  1.148             | Val Loss:  1.199             | Train RMSE:  1.061             | Val RMSE:  1.082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 30 | Train Loss:  1.163             | Val Loss:  1.268             | Train RMSE:  1.066             | Val RMSE:  1.118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 31 | Train Loss:  1.147             | Val Loss:  1.139             | Train RMSE:  1.058             | Val RMSE:  1.056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 32 | Train Loss:  1.153             | Val Loss:  1.302             | Train RMSE:  1.064             | Val RMSE:  1.132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 33 | Train Loss:  1.151             | Val Loss:  1.134             | Train RMSE:  1.060             | Val RMSE:  1.058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 34 | Train Loss:  1.142             | Val Loss:  1.233             | Train RMSE:  1.058             | Val RMSE:  1.095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 35 | Train Loss:  1.153             | Val Loss:  1.237             | Train RMSE:  1.061             | Val RMSE:  1.103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 36 | Train Loss:  1.134             | Val Loss:  1.172             | Train RMSE:  1.053             | Val RMSE:  1.069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 37 | Train Loss:  1.163             | Val Loss:  1.146             | Train RMSE:  1.065             | Val RMSE:  1.064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 38 | Train Loss:  1.137             | Val Loss:  1.195             | Train RMSE:  1.051             | Val RMSE:  1.088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 39 | Train Loss:  1.135             | Val Loss:  1.142             | Train RMSE:  1.056             | Val RMSE:  1.060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 40 | Train Loss:  1.113             | Val Loss:  1.191             | Train RMSE:  1.042             | Val RMSE:  1.084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 41 | Train Loss:  1.130             | Val Loss:  1.286             | Train RMSE:  1.049             | Val RMSE:  1.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 42 | Train Loss:  1.086             | Val Loss:  1.274             | Train RMSE:  1.027             | Val RMSE:  1.117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 43 | Train Loss:  1.124             | Val Loss:  1.192             | Train RMSE:  1.048             | Val RMSE:  1.084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 44 | Train Loss:  1.085             | Val Loss:  1.228             | Train RMSE:  1.028             | Val RMSE:  1.098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 45 | Train Loss:  1.101             | Val Loss:  1.153             | Train RMSE:  1.038             | Val RMSE:  1.066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 46 | Train Loss:  1.102             | Val Loss:  1.172             | Train RMSE:  1.035             | Val RMSE:  1.067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 47 | Train Loss:  1.074             | Val Loss:  1.082             | Train RMSE:  1.021             | Val RMSE:  1.031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 48 | Train Loss:  1.130             | Val Loss:  1.157             | Train RMSE:  1.050             | Val RMSE:  1.062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 49 | Train Loss:  1.081             | Val Loss:  1.110             | Train RMSE:  1.027             | Val RMSE:  1.043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 50 | Train Loss:  1.073             | Val Loss:  1.009             | Train RMSE:  1.025             | Val RMSE:  0.998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 51 | Train Loss:  1.076             | Val Loss:  1.131             | Train RMSE:  1.023             | Val RMSE:  1.057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 52 | Train Loss:  1.046             | Val Loss:  1.242             | Train RMSE:  1.010             | Val RMSE:  1.097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 53 | Train Loss:  1.080             | Val Loss:  1.026             | Train RMSE:  1.026             | Val RMSE:  1.002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 54 | Train Loss:  1.067             | Val Loss:  1.014             | Train RMSE:  1.020             | Val RMSE:  0.997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 55 | Train Loss:  1.062             | Val Loss:  1.053             | Train RMSE:  1.018             | Val RMSE:  1.018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 56 | Train Loss:  1.055             | Val Loss:  1.062             | Train RMSE:  1.014             | Val RMSE:  1.023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 57 | Train Loss:  1.071             | Val Loss:  1.042             | Train RMSE:  1.022             | Val RMSE:  1.016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 58 | Train Loss:  1.039             | Val Loss:  1.115             | Train RMSE:  1.007             | Val RMSE:  1.044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 59 | Train Loss:  1.015             | Val Loss:  1.227             | Train RMSE:  0.996             | Val RMSE:  1.096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 60 | Train Loss:  1.029             | Val Loss:  1.046             | Train RMSE:  1.004             | Val RMSE:  1.014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 61 | Train Loss:  1.036             | Val Loss:  1.092             | Train RMSE:  1.007             | Val RMSE:  1.036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 62 | Train Loss:  1.022             | Val Loss:  1.084             | Train RMSE:  1.000             | Val RMSE:  1.030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 63 | Train Loss:  1.028             | Val Loss:  0.995             | Train RMSE:  1.001             | Val RMSE:  0.989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 64 | Train Loss:  1.040             | Val Loss:  1.142             | Train RMSE:  1.006             | Val RMSE:  1.057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 65 | Train Loss:  1.030             | Val Loss:  1.113             | Train RMSE:  1.003             | Val RMSE:  1.040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 66 | Train Loss:  1.028             | Val Loss:  1.137             | Train RMSE:  1.003             | Val RMSE:  1.055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 67 | Train Loss:  1.033             | Val Loss:  1.032             | Train RMSE:  1.004             | Val RMSE:  1.008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 68 | Train Loss:  0.978             | Val Loss:  1.043             | Train RMSE:  0.977             | Val RMSE:  1.006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 69 | Train Loss:  0.993             | Val Loss:  1.123             | Train RMSE:  0.985             | Val RMSE:  1.052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 70 | Train Loss:  1.030             | Val Loss:  1.144             | Train RMSE:  1.002             | Val RMSE:  1.060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 71 | Train Loss:  1.012             | Val Loss:  1.013             | Train RMSE:  0.995             | Val RMSE:  0.991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 72 | Train Loss:  1.005             | Val Loss:  1.069             | Train RMSE:  0.989             | Val RMSE:  1.021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 73 | Train Loss:  0.967             | Val Loss:  0.965             | Train RMSE:  0.970             | Val RMSE:  0.975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 74 | Train Loss:  0.988             | Val Loss:  0.983             | Train RMSE:  0.985             | Val RMSE:  0.980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 75 | Train Loss:  1.006             | Val Loss:  0.958             | Train RMSE:  0.993             | Val RMSE:  0.971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 76 | Train Loss:  1.024             | Val Loss:  1.117             | Train RMSE:  1.002             | Val RMSE:  1.049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 77 | Train Loss:  1.007             | Val Loss:  1.010             | Train RMSE:  0.993             | Val RMSE:  0.997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 78 | Train Loss:  1.021             | Val Loss:  1.076             | Train RMSE:  0.998             | Val RMSE:  1.029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 79 | Train Loss:  0.981             | Val Loss:  1.117             | Train RMSE:  0.981             | Val RMSE:  1.046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 80 | Train Loss:  0.990             | Val Loss:  0.941             | Train RMSE:  0.984             | Val RMSE:  0.961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 81 | Train Loss:  0.954             | Val Loss:  1.055             | Train RMSE:  0.965             | Val RMSE:  1.018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 82 | Train Loss:  0.949             | Val Loss:  1.042             | Train RMSE:  0.964             | Val RMSE:  1.015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 83 | Train Loss:  0.975             | Val Loss:  1.046             | Train RMSE:  0.976             | Val RMSE:  1.018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 84 | Train Loss:  0.949             | Val Loss:  1.039             | Train RMSE:  0.965             | Val RMSE:  1.012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 85 | Train Loss:  0.992             | Val Loss:  1.052             | Train RMSE:  0.985             | Val RMSE:  1.019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 86 | Train Loss:  0.975             | Val Loss:  0.924             | Train RMSE:  0.974             | Val RMSE:  0.951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 87 | Train Loss:  0.966             | Val Loss:  1.099             | Train RMSE:  0.971             | Val RMSE:  1.039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 88 | Train Loss:  0.949             | Val Loss:  1.133             | Train RMSE:  0.960             | Val RMSE:  1.052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 89 | Train Loss:  0.952             | Val Loss:  1.084             | Train RMSE:  0.963             | Val RMSE:  1.025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 90 | Train Loss:  0.960             | Val Loss:  1.070             | Train RMSE:  0.966             | Val RMSE:  1.027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 91 | Train Loss:  0.977             | Val Loss:  0.917             | Train RMSE:  0.979             | Val RMSE:  0.953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 92 | Train Loss:  0.978             | Val Loss:  1.038             | Train RMSE:  0.976             | Val RMSE:  1.007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 93 | Train Loss:  0.968             | Val Loss:  0.988             | Train RMSE:  0.973             | Val RMSE:  0.987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 94 | Train Loss:  0.913             | Val Loss:  1.016             | Train RMSE:  0.944             | Val RMSE:  0.997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 95 | Train Loss:  0.938             | Val Loss:  1.068             | Train RMSE:  0.955             | Val RMSE:  1.027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 96 | Train Loss:  0.934             | Val Loss:  1.003             | Train RMSE:  0.953             | Val RMSE:  0.994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 97 | Train Loss:  0.977             | Val Loss:  0.953             | Train RMSE:  0.975             | Val RMSE:  0.968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 98 | Train Loss:  0.932             | Val Loss:  1.077             | Train RMSE:  0.952             | Val RMSE:  1.028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 99 | Train Loss:  0.933             | Val Loss:  1.050             | Train RMSE:  0.954             | Val RMSE:  1.015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 100 | Train Loss:  0.951             | Val Loss:  1.046             | Train RMSE:  0.964             | Val RMSE:  1.012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 101 | Train Loss:  0.946             | Val Loss:  0.969             | Train RMSE:  0.959             | Val RMSE:  0.976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 102 | Train Loss:  0.932             | Val Loss:  1.050             | Train RMSE:  0.954             | Val RMSE:  1.012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 103 | Train Loss:  0.917             | Val Loss:  0.906             | Train RMSE:  0.947             | Val RMSE:  0.948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 104 | Train Loss:  0.928             | Val Loss:  0.951             | Train RMSE:  0.951             | Val RMSE:  0.966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 105 | Train Loss:  0.946             | Val Loss:  0.943             | Train RMSE:  0.962             | Val RMSE:  0.960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 106 | Train Loss:  0.908             | Val Loss:  0.994             | Train RMSE:  0.939             | Val RMSE:  0.986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 107 | Train Loss:  0.905             | Val Loss:  0.934             | Train RMSE:  0.938             | Val RMSE:  0.958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 108 | Train Loss:  0.916             | Val Loss:  0.902             | Train RMSE:  0.945             | Val RMSE:  0.943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 109 | Train Loss:  0.901             | Val Loss:  0.976             | Train RMSE:  0.939             | Val RMSE:  0.978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 110 | Train Loss:  0.897             | Val Loss:  0.964             | Train RMSE:  0.938             | Val RMSE:  0.967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 111 | Train Loss:  0.907             | Val Loss:  0.873             | Train RMSE:  0.943             | Val RMSE:  0.929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 112 | Train Loss:  0.909             | Val Loss:  0.953             | Train RMSE:  0.939             | Val RMSE:  0.969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 113 | Train Loss:  0.889             | Val Loss:  0.982             | Train RMSE:  0.928             | Val RMSE:  0.983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 114 | Train Loss:  0.866             | Val Loss:  0.917             | Train RMSE:  0.920             | Val RMSE:  0.947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 115 | Train Loss:  0.893             | Val Loss:  1.013             | Train RMSE:  0.931             | Val RMSE:  1.003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 116 | Train Loss:  0.935             | Val Loss:  0.854             | Train RMSE:  0.957             | Val RMSE:  0.917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 117 | Train Loss:  0.878             | Val Loss:  0.967             | Train RMSE:  0.925             | Val RMSE:  0.977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 118 | Train Loss:  0.909             | Val Loss:  0.939             | Train RMSE:  0.941             | Val RMSE:  0.963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 119 | Train Loss:  0.874             | Val Loss:  0.959             | Train RMSE:  0.922             | Val RMSE:  0.970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 120 | Train Loss:  0.882             | Val Loss:  0.954             | Train RMSE:  0.926             | Val RMSE:  0.966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 121 | Train Loss:  0.893             | Val Loss:  0.933             | Train RMSE:  0.933             | Val RMSE:  0.960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 122 | Train Loss:  0.868             | Val Loss:  0.934             | Train RMSE:  0.916             | Val RMSE:  0.956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 123 | Train Loss:  0.865             | Val Loss:  0.929             | Train RMSE:  0.919             | Val RMSE:  0.955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 124 | Train Loss:  0.857             | Val Loss:  0.963             | Train RMSE:  0.915             | Val RMSE:  0.977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 125 | Train Loss:  0.881             | Val Loss:  0.945             | Train RMSE:  0.926             | Val RMSE:  0.962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 126 | Train Loss:  0.863             | Val Loss:  0.932             | Train RMSE:  0.916             | Val RMSE:  0.960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 127 | Train Loss:  0.908             | Val Loss:  0.918             | Train RMSE:  0.942             | Val RMSE:  0.946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 128 | Train Loss:  0.867             | Val Loss:  0.922             | Train RMSE:  0.919             | Val RMSE:  0.953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 129 | Train Loss:  0.877             | Val Loss:  0.835             | Train RMSE:  0.926             | Val RMSE:  0.907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 130 | Train Loss:  0.855             | Val Loss:  0.894             | Train RMSE:  0.912             | Val RMSE:  0.938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 131 | Train Loss:  0.902             | Val Loss:  0.892             | Train RMSE:  0.938             | Val RMSE:  0.937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 132 | Train Loss:  0.891             | Val Loss:  0.911             | Train RMSE:  0.931             | Val RMSE:  0.946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 133 | Train Loss:  0.839             | Val Loss:  0.919             | Train RMSE:  0.903             | Val RMSE:  0.948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 134 | Train Loss:  0.840             | Val Loss:  0.864             | Train RMSE:  0.901             | Val RMSE:  0.918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 135 | Train Loss:  0.873             | Val Loss:  0.912             | Train RMSE:  0.920             | Val RMSE:  0.943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 136 | Train Loss:  0.857             | Val Loss:  0.839             | Train RMSE:  0.914             | Val RMSE:  0.906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 137 | Train Loss:  0.886             | Val Loss:  0.930             | Train RMSE:  0.927             | Val RMSE:  0.958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 138 | Train Loss:  0.863             | Val Loss:  0.837             | Train RMSE:  0.920             | Val RMSE:  0.908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 139 | Train Loss:  0.848             | Val Loss:  0.873             | Train RMSE:  0.912             | Val RMSE:  0.922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 140 | Train Loss:  0.861             | Val Loss:  0.983             | Train RMSE:  0.915             | Val RMSE:  0.985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 141 | Train Loss:  0.844             | Val Loss:  0.994             | Train RMSE:  0.910             | Val RMSE:  0.991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 142 | Train Loss:  0.828             | Val Loss:  0.917             | Train RMSE:  0.897             | Val RMSE:  0.950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 143 | Train Loss:  0.829             | Val Loss:  0.926             | Train RMSE:  0.897             | Val RMSE:  0.952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 144 | Train Loss:  0.884             | Val Loss:  0.834             | Train RMSE:  0.924             | Val RMSE:  0.904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 145 | Train Loss:  0.826             | Val Loss:  0.988             | Train RMSE:  0.899             | Val RMSE:  0.986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 146 | Train Loss:  0.853             | Val Loss:  0.867             | Train RMSE:  0.912             | Val RMSE:  0.915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 147 | Train Loss:  0.847             | Val Loss:  0.849             | Train RMSE:  0.908             | Val RMSE:  0.916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 148 | Train Loss:  0.833             | Val Loss:  0.844             | Train RMSE:  0.903             | Val RMSE:  0.913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 149 | Train Loss:  0.827             | Val Loss:  0.900             | Train RMSE:  0.897             | Val RMSE:  0.942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 150 | Train Loss:  0.844             | Val Loss:  0.897             | Train RMSE:  0.907             | Val RMSE:  0.937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 151 | Train Loss:  0.855             | Val Loss:  0.952             | Train RMSE:  0.914             | Val RMSE:  0.966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 152 | Train Loss:  0.868             | Val Loss:  0.887             | Train RMSE:  0.919             | Val RMSE:  0.935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 153 | Train Loss:  0.840             | Val Loss:  0.965             | Train RMSE:  0.906             | Val RMSE:  0.973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 154 | Train Loss:  0.842             | Val Loss:  0.840             | Train RMSE:  0.908             | Val RMSE:  0.909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 155 | Train Loss:  0.843             | Val Loss:  0.945             | Train RMSE:  0.907             | Val RMSE:  0.959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 156 | Train Loss:  0.863             | Val Loss:  0.836             | Train RMSE:  0.917             | Val RMSE:  0.906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 157 | Train Loss:  0.833             | Val Loss:  0.902             | Train RMSE:  0.901             | Val RMSE:  0.943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 158 | Train Loss:  0.856             | Val Loss:  0.908             | Train RMSE:  0.913             | Val RMSE:  0.940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 159 | Train Loss:  0.844             | Val Loss:  0.887             | Train RMSE:  0.908             | Val RMSE:  0.934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 160 | Train Loss:  0.817             | Val Loss:  0.867             | Train RMSE:  0.893             | Val RMSE:  0.927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 161 | Train Loss:  0.832             | Val Loss:  0.939             | Train RMSE:  0.899             | Val RMSE:  0.961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 162 | Train Loss:  0.814             | Val Loss:  0.839             | Train RMSE:  0.892             | Val RMSE:  0.911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 163 | Train Loss:  0.829             | Val Loss:  0.812             | Train RMSE:  0.897             | Val RMSE:  0.894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 164 | Train Loss:  0.811             | Val Loss:  0.847             | Train RMSE:  0.890             | Val RMSE:  0.913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 165 | Train Loss:  0.836             | Val Loss:  0.948             | Train RMSE:  0.906             | Val RMSE:  0.966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 166 | Train Loss:  0.791             | Val Loss:  0.867             | Train RMSE:  0.877             | Val RMSE:  0.921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 167 | Train Loss:  0.826             | Val Loss:  0.959             | Train RMSE:  0.894             | Val RMSE:  0.963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 168 | Train Loss:  0.810             | Val Loss:  0.906             | Train RMSE:  0.887             | Val RMSE:  0.941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 169 | Train Loss:  0.819             | Val Loss:  0.857             | Train RMSE:  0.897             | Val RMSE:  0.918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 170 | Train Loss:  0.787             | Val Loss:  0.998             | Train RMSE:  0.877             | Val RMSE:  0.987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 171 | Train Loss:  0.800             | Val Loss:  0.871             | Train RMSE:  0.883             | Val RMSE:  0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 172 | Train Loss:  0.834             | Val Loss:  0.943             | Train RMSE:  0.902             | Val RMSE:  0.961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 173 | Train Loss:  0.793             | Val Loss:  0.900             | Train RMSE:  0.879             | Val RMSE:  0.939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 174 | Train Loss:  0.831             | Val Loss:  0.883             | Train RMSE:  0.900             | Val RMSE:  0.928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 175 | Train Loss:  0.807             | Val Loss:  0.916             | Train RMSE:  0.890             | Val RMSE:  0.948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 176 | Train Loss:  0.811             | Val Loss:  0.891             | Train RMSE:  0.889             | Val RMSE:  0.937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 177 | Train Loss:  0.807             | Val Loss:  0.814             | Train RMSE:  0.887             | Val RMSE:  0.894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 178 | Train Loss:  0.800             | Val Loss:  0.929             | Train RMSE:  0.885             | Val RMSE:  0.952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 179 | Train Loss:  0.802             | Val Loss:  0.848             | Train RMSE:  0.884             | Val RMSE:  0.915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 180 | Train Loss:  0.782             | Val Loss:  0.941             | Train RMSE:  0.871             | Val RMSE:  0.965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 181 | Train Loss:  0.814             | Val Loss:  0.807             | Train RMSE:  0.891             | Val RMSE:  0.893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 182 | Train Loss:  0.793             | Val Loss:  0.828             | Train RMSE:  0.879             | Val RMSE:  0.897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 183 | Train Loss:  0.846             | Val Loss:  0.842             | Train RMSE:  0.908             | Val RMSE:  0.906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 184 | Train Loss:  0.794             | Val Loss:  0.835             | Train RMSE:  0.879             | Val RMSE:  0.899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 185 | Train Loss:  0.811             | Val Loss:  0.836             | Train RMSE:  0.890             | Val RMSE:  0.910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 186 | Train Loss:  0.820             | Val Loss:  0.898             | Train RMSE:  0.893             | Val RMSE:  0.938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 187 | Train Loss:  0.814             | Val Loss:  0.913             | Train RMSE:  0.890             | Val RMSE:  0.947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 188 | Train Loss:  0.787             | Val Loss:  0.841             | Train RMSE:  0.876             | Val RMSE:  0.908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 189 | Train Loss:  0.830             | Val Loss:  0.888             | Train RMSE:  0.903             | Val RMSE:  0.934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 190 | Train Loss:  0.786             | Val Loss:  0.797             | Train RMSE:  0.877             | Val RMSE:  0.888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 191 | Train Loss:  0.794             | Val Loss:  0.867             | Train RMSE:  0.880             | Val RMSE:  0.916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 192 | Train Loss:  0.789             | Val Loss:  0.800             | Train RMSE:  0.880             | Val RMSE:  0.888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 193 | Train Loss:  0.760             | Val Loss:  0.860             | Train RMSE:  0.861             | Val RMSE:  0.916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 194 | Train Loss:  0.772             | Val Loss:  0.865             | Train RMSE:  0.869             | Val RMSE:  0.922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 195 | Train Loss:  0.787             | Val Loss:  0.876             | Train RMSE:  0.879             | Val RMSE:  0.925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 196 | Train Loss:  0.818             | Val Loss:  0.848             | Train RMSE:  0.893             | Val RMSE:  0.916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 197 | Train Loss:  0.794             | Val Loss:  0.811             | Train RMSE:  0.878             | Val RMSE:  0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 198 | Train Loss:  0.804             | Val Loss:  0.870             | Train RMSE:  0.885             | Val RMSE:  0.925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 199 | Train Loss:  0.764             | Val Loss:  0.935             | Train RMSE:  0.862             | Val RMSE:  0.954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 200 | Train Loss:  0.781             | Val Loss:  0.796             | Train RMSE:  0.874             | Val RMSE:  0.886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 201 | Train Loss:  0.800             | Val Loss:  0.925             | Train RMSE:  0.882             | Val RMSE:  0.954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 202 | Train Loss:  0.790             | Val Loss:  0.843             | Train RMSE:  0.878             | Val RMSE:  0.912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 203 | Train Loss:  0.780             | Val Loss:  0.802             | Train RMSE:  0.874             | Val RMSE:  0.888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 204 | Train Loss:  0.783             | Val Loss:  0.777             | Train RMSE:  0.873             | Val RMSE:  0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 205 | Train Loss:  0.774             | Val Loss:  0.844             | Train RMSE:  0.869             | Val RMSE:  0.912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 206 | Train Loss:  0.794             | Val Loss:  0.838             | Train RMSE:  0.880             | Val RMSE:  0.911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 207 | Train Loss:  0.759             | Val Loss:  1.025             | Train RMSE:  0.860             | Val RMSE:  1.008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 208 | Train Loss:  0.777             | Val Loss:  0.826             | Train RMSE:  0.868             | Val RMSE:  0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 209 | Train Loss:  0.779             | Val Loss:  0.908             | Train RMSE:  0.871             | Val RMSE:  0.948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 210 | Train Loss:  0.759             | Val Loss:  0.959             | Train RMSE:  0.861             | Val RMSE:  0.969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 211 | Train Loss:  0.771             | Val Loss:  0.877             | Train RMSE:  0.865             | Val RMSE:  0.929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 212 | Train Loss:  0.795             | Val Loss:  0.941             | Train RMSE:  0.882             | Val RMSE:  0.962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 213 | Train Loss:  0.767             | Val Loss:  0.807             | Train RMSE:  0.866             | Val RMSE:  0.886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 214 | Train Loss:  0.779             | Val Loss:  0.811             | Train RMSE:  0.873             | Val RMSE:  0.890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 215 | Train Loss:  0.754             | Val Loss:  0.821             | Train RMSE:  0.859             | Val RMSE:  0.895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 216 | Train Loss:  0.794             | Val Loss:  0.877             | Train RMSE:  0.883             | Val RMSE:  0.929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 217 | Train Loss:  0.781             | Val Loss:  0.846             | Train RMSE:  0.875             | Val RMSE:  0.912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 218 | Train Loss:  0.759             | Val Loss:  0.795             | Train RMSE:  0.862             | Val RMSE:  0.882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 219 | Train Loss:  0.754             | Val Loss:  0.787             | Train RMSE:  0.859             | Val RMSE:  0.879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 220 | Train Loss:  0.747             | Val Loss:  0.899             | Train RMSE:  0.853             | Val RMSE:  0.938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 221 | Train Loss:  0.777             | Val Loss:  0.851             | Train RMSE:  0.868             | Val RMSE:  0.916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 222 | Train Loss:  0.749             | Val Loss:  0.837             | Train RMSE:  0.856             | Val RMSE:  0.907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 223 | Train Loss:  0.732             | Val Loss:  0.809             | Train RMSE:  0.844             | Val RMSE:  0.891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 224 | Train Loss:  0.781             | Val Loss:  0.800             | Train RMSE:  0.870             | Val RMSE:  0.892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 225 | Train Loss:  0.774             | Val Loss:  0.763             | Train RMSE:  0.872             | Val RMSE:  0.867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 226 | Train Loss:  0.774             | Val Loss:  0.902             | Train RMSE:  0.869             | Val RMSE:  0.934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 227 | Train Loss:  0.762             | Val Loss:  0.893             | Train RMSE:  0.861             | Val RMSE:  0.932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 228 | Train Loss:  0.752             | Val Loss:  0.810             | Train RMSE:  0.856             | Val RMSE:  0.893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 229 | Train Loss:  0.779             | Val Loss:  0.788             | Train RMSE:  0.869             | Val RMSE:  0.878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 230 | Train Loss:  0.764             | Val Loss:  0.826             | Train RMSE:  0.863             | Val RMSE:  0.904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 231 | Train Loss:  0.770             | Val Loss:  1.006             | Train RMSE:  0.869             | Val RMSE:  0.993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 232 | Train Loss:  0.753             | Val Loss:  0.779             | Train RMSE:  0.857             | Val RMSE:  0.879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 233 | Train Loss:  0.784             | Val Loss:  0.820             | Train RMSE:  0.875             | Val RMSE:  0.896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 234 | Train Loss:  0.751             | Val Loss:  0.929             | Train RMSE:  0.856             | Val RMSE:  0.955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 235 | Train Loss:  0.776             | Val Loss:  0.780             | Train RMSE:  0.871             | Val RMSE:  0.876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 236 | Train Loss:  0.728             | Val Loss:  0.871             | Train RMSE:  0.844             | Val RMSE:  0.924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 237 | Train Loss:  0.741             | Val Loss:  0.792             | Train RMSE:  0.851             | Val RMSE:  0.883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 238 | Train Loss:  0.748             | Val Loss:  0.766             | Train RMSE:  0.853             | Val RMSE:  0.871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 239 | Train Loss:  0.734             | Val Loss:  0.845             | Train RMSE:  0.847             | Val RMSE:  0.913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 240 | Train Loss:  0.729             | Val Loss:  0.784             | Train RMSE:  0.840             | Val RMSE:  0.882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 241 | Train Loss:  0.756             | Val Loss:  0.940             | Train RMSE:  0.859             | Val RMSE:  0.961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 242 | Train Loss:  0.741             | Val Loss:  0.877             | Train RMSE:  0.851             | Val RMSE:  0.932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 243 | Train Loss:  0.773             | Val Loss:  0.800             | Train RMSE:  0.867             | Val RMSE:  0.888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 244 | Train Loss:  0.768             | Val Loss:  0.826             | Train RMSE:  0.867             | Val RMSE:  0.903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 245 | Train Loss:  0.736             | Val Loss:  0.765             | Train RMSE:  0.844             | Val RMSE:  0.868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 246 | Train Loss:  0.739             | Val Loss:  0.841             | Train RMSE:  0.848             | Val RMSE:  0.912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 247 | Train Loss:  0.763             | Val Loss:  0.891             | Train RMSE:  0.864             | Val RMSE:  0.935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 37.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 248 | Train Loss:  0.747             | Val Loss:  0.827             | Train RMSE:  0.851             | Val RMSE:  0.904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 249 | Train Loss:  0.767             | Val Loss:  0.870             | Train RMSE:  0.866             | Val RMSE:  0.930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:02<00:00, 36.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 250 | Train Loss:  0.743             | Val Loss:  0.830             | Train RMSE:  0.851             | Val RMSE:  0.903\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HiGNN(\n",
              "  (lin_a): Linear(in_features=45, out_features=64, bias=True)\n",
              "  (lin_b): Linear(in_features=10, out_features=64, bias=True)\n",
              "  (atom_convs): ModuleList(\n",
              "    (0): NTNConv(64, 64, slices=2)\n",
              "    (1): NTNConv(64, 64, slices=2)\n",
              "    (2): NTNConv(64, 64, slices=2)\n",
              "  )\n",
              "  (lin_gate): Linear(in_features=192, out_features=64, bias=True)\n",
              "  (feature_att): FeatureAttention(\n",
              "    (mlp): Sequential(\n",
              "      (0): Linear(in_features=64, out_features=16, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Linear(in_features=16, out_features=64, bias=False)\n",
              "    )\n",
              "  )\n",
              "  (cross_att): GATConv(64, 64, heads=4)\n",
              "  (out): ModuleList(\n",
              "    (0): Linear(in_features=128, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input SPR"
      ],
      "metadata": {
        "id": "swAPp-eVMwdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./chem_datasets/input_SPR_final.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Spy33DrsMzuE",
        "outputId": "ea943f7b-e578-4c87-d757-1cb3525e4c2a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              SMILES  Average logS SPR\n",
              "0  [C@@H]1(C)N[C@H](C)C2=C(C1)C(C(=O)NCCC1=CC=C(F...         -5.125518\n",
              "1  [C@@H]1(O)[C@@H](N)[C@H](OC2=CN=CC(C3=CC=C4C(=...         -3.730487\n",
              "2  [C@H]1(C)N[C@@H](C)C2=C(C1)C(C(OCC)=O)=C(NC(C1...         -4.434152\n",
              "3  [C@H]1(NC(CSC2=NC(=O)NC=C2Cl)=O)C2=C(CC1)C=C(O...         -4.709965\n",
              "4    [C@H]1(NC(NC2=NN=C(SCCN(C)C)S2)=O)CC[C@H](C)CC1         -4.003488"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>Average logS SPR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[C@@H]1(C)N[C@H](C)C2=C(C1)C(C(=O)NCCC1=CC=C(F...</td>\n",
              "      <td>-5.125518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[C@@H]1(O)[C@@H](N)[C@H](OC2=CN=CC(C3=CC=C4C(=...</td>\n",
              "      <td>-3.730487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[C@H]1(C)N[C@@H](C)C2=C(C1)C(C(OCC)=O)=C(NC(C1...</td>\n",
              "      <td>-4.434152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[C@H]1(NC(CSC2=NC(=O)NC=C2Cl)=O)C2=C(CC1)C=C(O...</td>\n",
              "      <td>-4.709965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[C@H]1(NC(NC2=NN=C(SCCN(C)C)S2)=O)CC[C@H](C)CC1</td>\n",
              "      <td>-4.003488</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.to_csv('./chem_datasets/input_SPR_final_random.csv', index = False)"
      ],
      "metadata": {
        "id": "T_yUv_q-Mzmv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./chem_datasets/input_SPR_final_random.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "N1rSNOnWNGcv",
        "outputId": "99a54707-c588-44dd-8433-a504b42e52de"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              SMILES  Average logS SPR\n",
              "0         C12=C(N=C(C3=CC=C(Br)C=C3)N1)C(=O)NC(N)=N2         -4.856985\n",
              "1   O=C(NC1=NC2=C(C=C3OCCOC3=C2)S1)C1=CC=C2CCCNC2=C1         -5.832683\n",
              "2  OC(C1=NN(C2=C(C(NC3=NC4=C(C=C5C(=C4)OCCO5)S3)=...         -4.013676\n",
              "3  FC1=CC2=C(C=C1)N=C(N(CCCN1CCOCC1)C(=O)C1=CC=C(...         -6.163043\n",
              "4  N1(CC(N[C@H](C2=NC3=C(N2)C=CC=C3)CC(C)C)=O)C(=...         -4.882729"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>Average logS SPR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C12=C(N=C(C3=CC=C(Br)C=C3)N1)C(=O)NC(N)=N2</td>\n",
              "      <td>-4.856985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>O=C(NC1=NC2=C(C=C3OCCOC3=C2)S1)C1=CC=C2CCCNC2=C1</td>\n",
              "      <td>-5.832683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>OC(C1=NN(C2=C(C(NC3=NC4=C(C=C5C(=C4)OCCO5)S3)=...</td>\n",
              "      <td>-4.013676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FC1=CC2=C(C=C1)N=C(N(CCCN1CCOCC1)C(=O)C1=CC=C(...</td>\n",
              "      <td>-6.163043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>N1(CC(N[C@H](C2=NC3=C(N2)C=CC=C3)CC(C)C)=O)C(=...</td>\n",
              "      <td>-4.882729</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepapre the Data Loaders. - root/dataset - ./root/processed/input_SPR_final_random_iter_1\n",
        "# In order\n",
        "train_loader, valid_loader, test_loader = get_loaders(root = './root/',\n",
        "                                                      fpath = './chem_datasets/input_SPR_final_random.csv',\n",
        "                                                      dataset = \"input_SPR_final_random_iter_1\",\n",
        "                                                      task_type = 'regression',\n",
        "                                                      tasks = ['Average logS SPR'],\n",
        "                                                      smiles_col = 'SMILES'\n",
        "                                                  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMDRtHlMNNCt",
        "outputId": "408e81ab-bd88-43e5-c345-23b1e16cd8ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total smiles = 7,141 | train smiles = 5,712 | val smiles = 714 | test smiles = 715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/ec2-user/virtenv/lib64/python3.7/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n",
            "/home/ec2-user/virtenv/lib64/python3.7/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "id": "0MAMtvjnNlhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Build Model\n",
        "spr_hi_gnn = build_model()\n",
        "\n",
        "# Train the model\n",
        "spr_hi_gnn = train_regression(spr_hi_gnn, train_loader, valid_loader, learning_rate = 1e-03, min_lr = 1e-04, epochs = 250, wd = 1e-03)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2hpACLsNbh4",
        "outputId": "105dd4c2-6751-4eee-87e0-8fe768d3d265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:06<00:00, 27.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  2.413             | Val Loss:  0.988             | Train RMSE:  1.350             | Val RMSE:  0.978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.866             | Val Loss:  0.834             | Train RMSE:  0.920             | Val RMSE:  0.896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.812             | Val Loss:  0.917             | Train RMSE:  0.890             | Val RMSE:  0.942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  0.770             | Val Loss:  0.827             | Train RMSE:  0.866             | Val RMSE:  0.899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  0.740             | Val Loss:  0.849             | Train RMSE:  0.849             | Val RMSE:  0.908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 6 | Train Loss:  0.751             | Val Loss:  0.713             | Train RMSE:  0.856             | Val RMSE:  0.827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 7 | Train Loss:  0.736             | Val Loss:  0.777             | Train RMSE:  0.848             | Val RMSE:  0.858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 8 | Train Loss:  0.726             | Val Loss:  0.796             | Train RMSE:  0.842             | Val RMSE:  0.874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 9 | Train Loss:  0.712             | Val Loss:  0.725             | Train RMSE:  0.834             | Val RMSE:  0.831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 10 | Train Loss:  0.709             | Val Loss:  0.761             | Train RMSE:  0.833             | Val RMSE:  0.860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 11 | Train Loss:  0.694             | Val Loss:  0.752             | Train RMSE:  0.820             | Val RMSE:  0.854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 12 | Train Loss:  0.703             | Val Loss:  0.748             | Train RMSE:  0.827             | Val RMSE:  0.848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 13 | Train Loss:  0.703             | Val Loss:  0.713             | Train RMSE:  0.826             | Val RMSE:  0.832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 14 | Train Loss:  0.688             | Val Loss:  0.759             | Train RMSE:  0.818             | Val RMSE:  0.851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 15 | Train Loss:  0.686             | Val Loss:  0.698             | Train RMSE:  0.817             | Val RMSE:  0.817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 16 | Train Loss:  0.683             | Val Loss:  0.726             | Train RMSE:  0.816             | Val RMSE:  0.833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 17 | Train Loss:  0.669             | Val Loss:  0.720             | Train RMSE:  0.804             | Val RMSE:  0.834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 18 | Train Loss:  0.664             | Val Loss:  0.702             | Train RMSE:  0.804             | Val RMSE:  0.825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 19 | Train Loss:  0.663             | Val Loss:  0.701             | Train RMSE:  0.803             | Val RMSE:  0.825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 20 | Train Loss:  0.674             | Val Loss:  0.707             | Train RMSE:  0.811             | Val RMSE:  0.828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 21 | Train Loss:  0.665             | Val Loss:  0.667             | Train RMSE:  0.805             | Val RMSE:  0.798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 22 | Train Loss:  0.658             | Val Loss:  0.669             | Train RMSE:  0.799             | Val RMSE:  0.802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 23 | Train Loss:  0.674             | Val Loss:  0.687             | Train RMSE:  0.810             | Val RMSE:  0.815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 24 | Train Loss:  0.659             | Val Loss:  0.701             | Train RMSE:  0.801             | Val RMSE:  0.820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 25 | Train Loss:  0.637             | Val Loss:  0.735             | Train RMSE:  0.787             | Val RMSE:  0.837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 26 | Train Loss:  0.649             | Val Loss:  0.685             | Train RMSE:  0.793             | Val RMSE:  0.805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 27 | Train Loss:  0.656             | Val Loss:  0.705             | Train RMSE:  0.800             | Val RMSE:  0.820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 28 | Train Loss:  0.641             | Val Loss:  0.736             | Train RMSE:  0.790             | Val RMSE:  0.838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 29 | Train Loss:  0.658             | Val Loss:  0.682             | Train RMSE:  0.801             | Val RMSE:  0.806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 30 | Train Loss:  0.642             | Val Loss:  0.701             | Train RMSE:  0.789             | Val RMSE:  0.821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 31 | Train Loss:  0.630             | Val Loss:  0.655             | Train RMSE:  0.784             | Val RMSE:  0.788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 32 | Train Loss:  0.635             | Val Loss:  0.656             | Train RMSE:  0.786             | Val RMSE:  0.801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 33 | Train Loss:  0.630             | Val Loss:  0.722             | Train RMSE:  0.783             | Val RMSE:  0.832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 34 | Train Loss:  0.617             | Val Loss:  0.624             | Train RMSE:  0.775             | Val RMSE:  0.770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 35 | Train Loss:  0.622             | Val Loss:  0.684             | Train RMSE:  0.778             | Val RMSE:  0.814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 36 | Train Loss:  0.615             | Val Loss:  0.670             | Train RMSE:  0.773             | Val RMSE:  0.798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 37 | Train Loss:  0.619             | Val Loss:  0.637             | Train RMSE:  0.776             | Val RMSE:  0.787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 38 | Train Loss:  0.621             | Val Loss:  0.685             | Train RMSE:  0.778             | Val RMSE:  0.805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 39 | Train Loss:  0.624             | Val Loss:  0.668             | Train RMSE:  0.778             | Val RMSE:  0.798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 40 | Train Loss:  0.601             | Val Loss:  0.716             | Train RMSE:  0.764             | Val RMSE:  0.824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 41 | Train Loss:  0.607             | Val Loss:  0.654             | Train RMSE:  0.767             | Val RMSE:  0.791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 42 | Train Loss:  0.607             | Val Loss:  0.657             | Train RMSE:  0.768             | Val RMSE:  0.794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 43 | Train Loss:  0.609             | Val Loss:  0.679             | Train RMSE:  0.769             | Val RMSE:  0.805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 44 | Train Loss:  0.614             | Val Loss:  0.667             | Train RMSE:  0.772             | Val RMSE:  0.800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 45 | Train Loss:  0.599             | Val Loss:  0.646             | Train RMSE:  0.762             | Val RMSE:  0.787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 46 | Train Loss:  0.598             | Val Loss:  0.624             | Train RMSE:  0.762             | Val RMSE:  0.772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 47 | Train Loss:  0.599             | Val Loss:  0.639             | Train RMSE:  0.762             | Val RMSE:  0.779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 48 | Train Loss:  0.601             | Val Loss:  0.606             | Train RMSE:  0.765             | Val RMSE:  0.762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 49 | Train Loss:  0.594             | Val Loss:  0.628             | Train RMSE:  0.758             | Val RMSE:  0.774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 50 | Train Loss:  0.585             | Val Loss:  0.615             | Train RMSE:  0.755             | Val RMSE:  0.766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 51 | Train Loss:  0.594             | Val Loss:  0.622             | Train RMSE:  0.758             | Val RMSE:  0.773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 52 | Train Loss:  0.595             | Val Loss:  0.625             | Train RMSE:  0.760             | Val RMSE:  0.778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 53 | Train Loss:  0.579             | Val Loss:  0.629             | Train RMSE:  0.752             | Val RMSE:  0.777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 54 | Train Loss:  0.579             | Val Loss:  0.586             | Train RMSE:  0.749             | Val RMSE:  0.753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 55 | Train Loss:  0.592             | Val Loss:  0.652             | Train RMSE:  0.755             | Val RMSE:  0.787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 56 | Train Loss:  0.583             | Val Loss:  0.609             | Train RMSE:  0.752             | Val RMSE:  0.765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 57 | Train Loss:  0.574             | Val Loss:  0.579             | Train RMSE:  0.747             | Val RMSE:  0.749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 58 | Train Loss:  0.582             | Val Loss:  0.626             | Train RMSE:  0.749             | Val RMSE:  0.769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 59 | Train Loss:  0.575             | Val Loss:  0.607             | Train RMSE:  0.748             | Val RMSE:  0.764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 60 | Train Loss:  0.579             | Val Loss:  0.628             | Train RMSE:  0.750             | Val RMSE:  0.780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 61 | Train Loss:  0.577             | Val Loss:  0.616             | Train RMSE:  0.749             | Val RMSE:  0.767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 62 | Train Loss:  0.578             | Val Loss:  0.589             | Train RMSE:  0.748             | Val RMSE:  0.750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 63 | Train Loss:  0.564             | Val Loss:  0.608             | Train RMSE:  0.741             | Val RMSE:  0.763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 64 | Train Loss:  0.572             | Val Loss:  0.609             | Train RMSE:  0.747             | Val RMSE:  0.766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 65 | Train Loss:  0.570             | Val Loss:  0.584             | Train RMSE:  0.745             | Val RMSE:  0.747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 66 | Train Loss:  0.568             | Val Loss:  0.578             | Train RMSE:  0.742             | Val RMSE:  0.743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 67 | Train Loss:  0.566             | Val Loss:  0.609             | Train RMSE:  0.742             | Val RMSE:  0.762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 68 | Train Loss:  0.569             | Val Loss:  0.616             | Train RMSE:  0.745             | Val RMSE:  0.761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 69 | Train Loss:  0.551             | Val Loss:  0.614             | Train RMSE:  0.732             | Val RMSE:  0.769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 70 | Train Loss:  0.578             | Val Loss:  0.595             | Train RMSE:  0.751             | Val RMSE:  0.751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 71 | Train Loss:  0.568             | Val Loss:  0.601             | Train RMSE:  0.742             | Val RMSE:  0.757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 72 | Train Loss:  0.552             | Val Loss:  0.586             | Train RMSE:  0.732             | Val RMSE:  0.750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 73 | Train Loss:  0.557             | Val Loss:  0.578             | Train RMSE:  0.734             | Val RMSE:  0.744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 74 | Train Loss:  0.567             | Val Loss:  0.589             | Train RMSE:  0.741             | Val RMSE:  0.754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 75 | Train Loss:  0.563             | Val Loss:  0.595             | Train RMSE:  0.738             | Val RMSE:  0.758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 76 | Train Loss:  0.559             | Val Loss:  0.589             | Train RMSE:  0.735             | Val RMSE:  0.749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 77 | Train Loss:  0.546             | Val Loss:  0.614             | Train RMSE:  0.729             | Val RMSE:  0.759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 78 | Train Loss:  0.553             | Val Loss:  0.579             | Train RMSE:  0.732             | Val RMSE:  0.739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 79 | Train Loss:  0.553             | Val Loss:  0.551             | Train RMSE:  0.732             | Val RMSE:  0.724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 80 | Train Loss:  0.554             | Val Loss:  0.606             | Train RMSE:  0.733             | Val RMSE:  0.762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 81 | Train Loss:  0.557             | Val Loss:  0.585             | Train RMSE:  0.735             | Val RMSE:  0.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 82 | Train Loss:  0.552             | Val Loss:  0.539             | Train RMSE:  0.732             | Val RMSE:  0.720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 83 | Train Loss:  0.552             | Val Loss:  0.570             | Train RMSE:  0.732             | Val RMSE:  0.738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 84 | Train Loss:  0.556             | Val Loss:  0.601             | Train RMSE:  0.732             | Val RMSE:  0.759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 85 | Train Loss:  0.550             | Val Loss:  0.576             | Train RMSE:  0.730             | Val RMSE:  0.746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 86 | Train Loss:  0.552             | Val Loss:  0.559             | Train RMSE:  0.733             | Val RMSE:  0.729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 87 | Train Loss:  0.541             | Val Loss:  0.643             | Train RMSE:  0.726             | Val RMSE:  0.783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 88 | Train Loss:  0.547             | Val Loss:  0.585             | Train RMSE:  0.726             | Val RMSE:  0.753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 89 | Train Loss:  0.537             | Val Loss:  0.546             | Train RMSE:  0.722             | Val RMSE:  0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 90 | Train Loss:  0.546             | Val Loss:  0.562             | Train RMSE:  0.728             | Val RMSE:  0.737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 91 | Train Loss:  0.542             | Val Loss:  0.563             | Train RMSE:  0.724             | Val RMSE:  0.732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 92 | Train Loss:  0.534             | Val Loss:  0.559             | Train RMSE:  0.720             | Val RMSE:  0.727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 93 | Train Loss:  0.538             | Val Loss:  0.580             | Train RMSE:  0.721             | Val RMSE:  0.745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 94 | Train Loss:  0.543             | Val Loss:  0.569             | Train RMSE:  0.726             | Val RMSE:  0.732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 95 | Train Loss:  0.541             | Val Loss:  0.573             | Train RMSE:  0.723             | Val RMSE:  0.738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 96 | Train Loss:  0.526             | Val Loss:  0.576             | Train RMSE:  0.714             | Val RMSE:  0.747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 97 | Train Loss:  0.533             | Val Loss:  0.576             | Train RMSE:  0.717             | Val RMSE:  0.740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 98 | Train Loss:  0.529             | Val Loss:  0.532             | Train RMSE:  0.715             | Val RMSE:  0.713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 99 | Train Loss:  0.530             | Val Loss:  0.581             | Train RMSE:  0.718             | Val RMSE:  0.744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 100 | Train Loss:  0.536             | Val Loss:  0.552             | Train RMSE:  0.720             | Val RMSE:  0.727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 101 | Train Loss:  0.531             | Val Loss:  0.632             | Train RMSE:  0.718             | Val RMSE:  0.772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 102 | Train Loss:  0.519             | Val Loss:  0.578             | Train RMSE:  0.709             | Val RMSE:  0.741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 103 | Train Loss:  0.532             | Val Loss:  0.590             | Train RMSE:  0.719             | Val RMSE:  0.749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 104 | Train Loss:  0.520             | Val Loss:  0.540             | Train RMSE:  0.712             | Val RMSE:  0.719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 105 | Train Loss:  0.526             | Val Loss:  0.523             | Train RMSE:  0.715             | Val RMSE:  0.709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 106 | Train Loss:  0.530             | Val Loss:  0.558             | Train RMSE:  0.719             | Val RMSE:  0.728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 107 | Train Loss:  0.524             | Val Loss:  0.588             | Train RMSE:  0.713             | Val RMSE:  0.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 108 | Train Loss:  0.530             | Val Loss:  0.583             | Train RMSE:  0.718             | Val RMSE:  0.746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 109 | Train Loss:  0.513             | Val Loss:  0.530             | Train RMSE:  0.706             | Val RMSE:  0.712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 110 | Train Loss:  0.525             | Val Loss:  0.558             | Train RMSE:  0.713             | Val RMSE:  0.729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 111 | Train Loss:  0.520             | Val Loss:  0.541             | Train RMSE:  0.709             | Val RMSE:  0.720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 112 | Train Loss:  0.524             | Val Loss:  0.549             | Train RMSE:  0.712             | Val RMSE:  0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 113 | Train Loss:  0.515             | Val Loss:  0.558             | Train RMSE:  0.708             | Val RMSE:  0.733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 114 | Train Loss:  0.518             | Val Loss:  0.581             | Train RMSE:  0.710             | Val RMSE:  0.753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 115 | Train Loss:  0.515             | Val Loss:  0.528             | Train RMSE:  0.706             | Val RMSE:  0.709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 116 | Train Loss:  0.514             | Val Loss:  0.575             | Train RMSE:  0.704             | Val RMSE:  0.734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 117 | Train Loss:  0.521             | Val Loss:  0.563             | Train RMSE:  0.711             | Val RMSE:  0.732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 118 | Train Loss:  0.534             | Val Loss:  0.594             | Train RMSE:  0.719             | Val RMSE:  0.750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 119 | Train Loss:  0.519             | Val Loss:  0.535             | Train RMSE:  0.710             | Val RMSE:  0.718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 120 | Train Loss:  0.506             | Val Loss:  0.575             | Train RMSE:  0.699             | Val RMSE:  0.740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 121 | Train Loss:  0.515             | Val Loss:  0.553             | Train RMSE:  0.707             | Val RMSE:  0.734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 122 | Train Loss:  0.511             | Val Loss:  0.520             | Train RMSE:  0.704             | Val RMSE:  0.703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 123 | Train Loss:  0.515             | Val Loss:  0.526             | Train RMSE:  0.706             | Val RMSE:  0.711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 124 | Train Loss:  0.508             | Val Loss:  0.590             | Train RMSE:  0.702             | Val RMSE:  0.750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 125 | Train Loss:  0.518             | Val Loss:  0.586             | Train RMSE:  0.708             | Val RMSE:  0.742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 126 | Train Loss:  0.513             | Val Loss:  0.496             | Train RMSE:  0.705             | Val RMSE:  0.689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 127 | Train Loss:  0.513             | Val Loss:  0.538             | Train RMSE:  0.705             | Val RMSE:  0.720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 128 | Train Loss:  0.511             | Val Loss:  0.519             | Train RMSE:  0.705             | Val RMSE:  0.707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 129 | Train Loss:  0.510             | Val Loss:  0.578             | Train RMSE:  0.703             | Val RMSE:  0.738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 130 | Train Loss:  0.510             | Val Loss:  0.498             | Train RMSE:  0.702             | Val RMSE:  0.695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 131 | Train Loss:  0.504             | Val Loss:  0.546             | Train RMSE:  0.698             | Val RMSE:  0.721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 132 | Train Loss:  0.501             | Val Loss:  0.514             | Train RMSE:  0.699             | Val RMSE:  0.698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 133 | Train Loss:  0.516             | Val Loss:  0.560             | Train RMSE:  0.706             | Val RMSE:  0.727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 134 | Train Loss:  0.510             | Val Loss:  0.584             | Train RMSE:  0.703             | Val RMSE:  0.748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 135 | Train Loss:  0.500             | Val Loss:  0.563             | Train RMSE:  0.694             | Val RMSE:  0.728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 136 | Train Loss:  0.506             | Val Loss:  0.572             | Train RMSE:  0.699             | Val RMSE:  0.743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 137 | Train Loss:  0.513             | Val Loss:  0.552             | Train RMSE:  0.706             | Val RMSE:  0.727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 138 | Train Loss:  0.514             | Val Loss:  0.514             | Train RMSE:  0.706             | Val RMSE:  0.701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 139 | Train Loss:  0.494             | Val Loss:  0.527             | Train RMSE:  0.694             | Val RMSE:  0.715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 140 | Train Loss:  0.499             | Val Loss:  0.523             | Train RMSE:  0.695             | Val RMSE:  0.702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 141 | Train Loss:  0.503             | Val Loss:  0.513             | Train RMSE:  0.697             | Val RMSE:  0.695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 142 | Train Loss:  0.496             | Val Loss:  0.552             | Train RMSE:  0.692             | Val RMSE:  0.728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 143 | Train Loss:  0.515             | Val Loss:  0.582             | Train RMSE:  0.705             | Val RMSE:  0.741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 144 | Train Loss:  0.500             | Val Loss:  0.537             | Train RMSE:  0.696             | Val RMSE:  0.714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 145 | Train Loss:  0.497             | Val Loss:  0.516             | Train RMSE:  0.693             | Val RMSE:  0.702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 146 | Train Loss:  0.501             | Val Loss:  0.518             | Train RMSE:  0.697             | Val RMSE:  0.704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 147 | Train Loss:  0.514             | Val Loss:  0.540             | Train RMSE:  0.703             | Val RMSE:  0.710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 148 | Train Loss:  0.499             | Val Loss:  0.537             | Train RMSE:  0.695             | Val RMSE:  0.711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 149 | Train Loss:  0.490             | Val Loss:  0.527             | Train RMSE:  0.690             | Val RMSE:  0.709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 150 | Train Loss:  0.496             | Val Loss:  0.535             | Train RMSE:  0.693             | Val RMSE:  0.711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 151 | Train Loss:  0.499             | Val Loss:  0.538             | Train RMSE:  0.696             | Val RMSE:  0.716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 152 | Train Loss:  0.496             | Val Loss:  0.523             | Train RMSE:  0.693             | Val RMSE:  0.706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 153 | Train Loss:  0.493             | Val Loss:  0.600             | Train RMSE:  0.691             | Val RMSE:  0.758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 154 | Train Loss:  0.510             | Val Loss:  0.524             | Train RMSE:  0.705             | Val RMSE:  0.709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 155 | Train Loss:  0.504             | Val Loss:  0.521             | Train RMSE:  0.700             | Val RMSE:  0.705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 156 | Train Loss:  0.499             | Val Loss:  0.517             | Train RMSE:  0.695             | Val RMSE:  0.704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 157 | Train Loss:  0.493             | Val Loss:  0.595             | Train RMSE:  0.691             | Val RMSE:  0.759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 158 | Train Loss:  0.505             | Val Loss:  0.537             | Train RMSE:  0.698             | Val RMSE:  0.716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 159 | Train Loss:  0.500             | Val Loss:  0.545             | Train RMSE:  0.695             | Val RMSE:  0.718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 160 | Train Loss:  0.487             | Val Loss:  0.517             | Train RMSE:  0.687             | Val RMSE:  0.699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 161 | Train Loss:  0.491             | Val Loss:  0.556             | Train RMSE:  0.690             | Val RMSE:  0.726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 162 | Train Loss:  0.496             | Val Loss:  0.528             | Train RMSE:  0.694             | Val RMSE:  0.714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 163 | Train Loss:  0.507             | Val Loss:  0.507             | Train RMSE:  0.701             | Val RMSE:  0.697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 164 | Train Loss:  0.483             | Val Loss:  0.522             | Train RMSE:  0.684             | Val RMSE:  0.706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 165 | Train Loss:  0.492             | Val Loss:  0.513             | Train RMSE:  0.689             | Val RMSE:  0.700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 166 | Train Loss:  0.494             | Val Loss:  0.513             | Train RMSE:  0.690             | Val RMSE:  0.702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 167 | Train Loss:  0.497             | Val Loss:  0.514             | Train RMSE:  0.695             | Val RMSE:  0.698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 168 | Train Loss:  0.491             | Val Loss:  0.544             | Train RMSE:  0.689             | Val RMSE:  0.720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 169 | Train Loss:  0.490             | Val Loss:  0.552             | Train RMSE:  0.689             | Val RMSE:  0.726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 170 | Train Loss:  0.494             | Val Loss:  0.484             | Train RMSE:  0.692             | Val RMSE:  0.675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 171 | Train Loss:  0.494             | Val Loss:  0.510             | Train RMSE:  0.690             | Val RMSE:  0.697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 172 | Train Loss:  0.492             | Val Loss:  0.521             | Train RMSE:  0.691             | Val RMSE:  0.702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 173 | Train Loss:  0.482             | Val Loss:  0.571             | Train RMSE:  0.684             | Val RMSE:  0.736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 174 | Train Loss:  0.492             | Val Loss:  0.536             | Train RMSE:  0.688             | Val RMSE:  0.718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 175 | Train Loss:  0.495             | Val Loss:  0.495             | Train RMSE:  0.693             | Val RMSE:  0.689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 176 | Train Loss:  0.498             | Val Loss:  0.558             | Train RMSE:  0.694             | Val RMSE:  0.727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 177 | Train Loss:  0.490             | Val Loss:  0.501             | Train RMSE:  0.688             | Val RMSE:  0.693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 178 | Train Loss:  0.473             | Val Loss:  0.543             | Train RMSE:  0.677             | Val RMSE:  0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 179 | Train Loss:  0.491             | Val Loss:  0.552             | Train RMSE:  0.687             | Val RMSE:  0.728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 180 | Train Loss:  0.487             | Val Loss:  0.533             | Train RMSE:  0.685             | Val RMSE:  0.712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 181 | Train Loss:  0.481             | Val Loss:  0.528             | Train RMSE:  0.683             | Val RMSE:  0.706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 182 | Train Loss:  0.480             | Val Loss:  0.510             | Train RMSE:  0.682             | Val RMSE:  0.695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 183 | Train Loss:  0.485             | Val Loss:  0.562             | Train RMSE:  0.685             | Val RMSE:  0.734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 184 | Train Loss:  0.488             | Val Loss:  0.542             | Train RMSE:  0.688             | Val RMSE:  0.716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 185 | Train Loss:  0.478             | Val Loss:  0.516             | Train RMSE:  0.680             | Val RMSE:  0.700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 186 | Train Loss:  0.485             | Val Loss:  0.512             | Train RMSE:  0.684             | Val RMSE:  0.698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 187 | Train Loss:  0.491             | Val Loss:  0.529             | Train RMSE:  0.689             | Val RMSE:  0.708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 188 | Train Loss:  0.485             | Val Loss:  0.527             | Train RMSE:  0.685             | Val RMSE:  0.706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 189 | Train Loss:  0.478             | Val Loss:  0.519             | Train RMSE:  0.680             | Val RMSE:  0.700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 190 | Train Loss:  0.487             | Val Loss:  0.511             | Train RMSE:  0.688             | Val RMSE:  0.695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 191 | Train Loss:  0.485             | Val Loss:  0.499             | Train RMSE:  0.685             | Val RMSE:  0.690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 192 | Train Loss:  0.484             | Val Loss:  0.508             | Train RMSE:  0.686             | Val RMSE:  0.698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 193 | Train Loss:  0.482             | Val Loss:  0.507             | Train RMSE:  0.683             | Val RMSE:  0.693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 194 | Train Loss:  0.480             | Val Loss:  0.512             | Train RMSE:  0.681             | Val RMSE:  0.696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 195 | Train Loss:  0.485             | Val Loss:  0.510             | Train RMSE:  0.685             | Val RMSE:  0.694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 196 | Train Loss:  0.483             | Val Loss:  0.526             | Train RMSE:  0.684             | Val RMSE:  0.706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 197 | Train Loss:  0.473             | Val Loss:  0.500             | Train RMSE:  0.677             | Val RMSE:  0.692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 198 | Train Loss:  0.498             | Val Loss:  0.493             | Train RMSE:  0.695             | Val RMSE:  0.684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 199 | Train Loss:  0.480             | Val Loss:  0.581             | Train RMSE:  0.680             | Val RMSE:  0.740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 200 | Train Loss:  0.473             | Val Loss:  0.514             | Train RMSE:  0.676             | Val RMSE:  0.703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 201 | Train Loss:  0.476             | Val Loss:  0.510             | Train RMSE:  0.679             | Val RMSE:  0.698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 202 | Train Loss:  0.485             | Val Loss:  0.543             | Train RMSE:  0.684             | Val RMSE:  0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 203 | Train Loss:  0.476             | Val Loss:  0.512             | Train RMSE:  0.677             | Val RMSE:  0.700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 204 | Train Loss:  0.477             | Val Loss:  0.509             | Train RMSE:  0.680             | Val RMSE:  0.697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 205 | Train Loss:  0.473             | Val Loss:  0.516             | Train RMSE:  0.676             | Val RMSE:  0.703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 206 | Train Loss:  0.480             | Val Loss:  0.520             | Train RMSE:  0.682             | Val RMSE:  0.703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 207 | Train Loss:  0.481             | Val Loss:  0.500             | Train RMSE:  0.683             | Val RMSE:  0.687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 208 | Train Loss:  0.491             | Val Loss:  0.512             | Train RMSE:  0.688             | Val RMSE:  0.699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 209 | Train Loss:  0.482             | Val Loss:  0.492             | Train RMSE:  0.683             | Val RMSE:  0.678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 210 | Train Loss:  0.489             | Val Loss:  0.602             | Train RMSE:  0.686             | Val RMSE:  0.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 211 | Train Loss:  0.478             | Val Loss:  0.510             | Train RMSE:  0.679             | Val RMSE:  0.700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 212 | Train Loss:  0.482             | Val Loss:  0.531             | Train RMSE:  0.683             | Val RMSE:  0.713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 213 | Train Loss:  0.476             | Val Loss:  0.510             | Train RMSE:  0.679             | Val RMSE:  0.693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 214 | Train Loss:  0.485             | Val Loss:  0.564             | Train RMSE:  0.684             | Val RMSE:  0.728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 215 | Train Loss:  0.479             | Val Loss:  0.498             | Train RMSE:  0.679             | Val RMSE:  0.692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 216 | Train Loss:  0.471             | Val Loss:  0.510             | Train RMSE:  0.675             | Val RMSE:  0.692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 217 | Train Loss:  0.470             | Val Loss:  0.551             | Train RMSE:  0.673             | Val RMSE:  0.719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 218 | Train Loss:  0.471             | Val Loss:  0.514             | Train RMSE:  0.676             | Val RMSE:  0.695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 219 | Train Loss:  0.478             | Val Loss:  0.481             | Train RMSE:  0.681             | Val RMSE:  0.676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 220 | Train Loss:  0.485             | Val Loss:  0.532             | Train RMSE:  0.685             | Val RMSE:  0.710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 221 | Train Loss:  0.479             | Val Loss:  0.512             | Train RMSE:  0.680             | Val RMSE:  0.694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 222 | Train Loss:  0.473             | Val Loss:  0.478             | Train RMSE:  0.675             | Val RMSE:  0.672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 223 | Train Loss:  0.467             | Val Loss:  0.496             | Train RMSE:  0.673             | Val RMSE:  0.688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 224 | Train Loss:  0.473             | Val Loss:  0.529             | Train RMSE:  0.678             | Val RMSE:  0.708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 225 | Train Loss:  0.464             | Val Loss:  0.513             | Train RMSE:  0.669             | Val RMSE:  0.695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 226 | Train Loss:  0.476             | Val Loss:  0.525             | Train RMSE:  0.680             | Val RMSE:  0.704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 227 | Train Loss:  0.469             | Val Loss:  0.520             | Train RMSE:  0.672             | Val RMSE:  0.700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 228 | Train Loss:  0.471             | Val Loss:  0.527             | Train RMSE:  0.675             | Val RMSE:  0.713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 229 | Train Loss:  0.466             | Val Loss:  0.533             | Train RMSE:  0.670             | Val RMSE:  0.708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 230 | Train Loss:  0.472             | Val Loss:  0.544             | Train RMSE:  0.677             | Val RMSE:  0.717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 231 | Train Loss:  0.465             | Val Loss:  0.500             | Train RMSE:  0.672             | Val RMSE:  0.691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 232 | Train Loss:  0.479             | Val Loss:  0.557             | Train RMSE:  0.679             | Val RMSE:  0.725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 233 | Train Loss:  0.481             | Val Loss:  0.512             | Train RMSE:  0.681             | Val RMSE:  0.700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 234 | Train Loss:  0.481             | Val Loss:  0.527             | Train RMSE:  0.683             | Val RMSE:  0.711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 235 | Train Loss:  0.465             | Val Loss:  0.507             | Train RMSE:  0.670             | Val RMSE:  0.696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 236 | Train Loss:  0.477             | Val Loss:  0.503             | Train RMSE:  0.679             | Val RMSE:  0.689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 36.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 237 | Train Loss:  0.459             | Val Loss:  0.495             | Train RMSE:  0.665             | Val RMSE:  0.681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 238 | Train Loss:  0.483             | Val Loss:  0.495             | Train RMSE:  0.683             | Val RMSE:  0.682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 239 | Train Loss:  0.465             | Val Loss:  0.503             | Train RMSE:  0.671             | Val RMSE:  0.693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 240 | Train Loss:  0.463             | Val Loss:  0.495             | Train RMSE:  0.669             | Val RMSE:  0.689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 241 | Train Loss:  0.467             | Val Loss:  0.579             | Train RMSE:  0.672             | Val RMSE:  0.740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 242 | Train Loss:  0.469             | Val Loss:  0.498             | Train RMSE:  0.673             | Val RMSE:  0.692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 243 | Train Loss:  0.466             | Val Loss:  0.511             | Train RMSE:  0.670             | Val RMSE:  0.701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 244 | Train Loss:  0.473             | Val Loss:  0.523             | Train RMSE:  0.674             | Val RMSE:  0.708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 245 | Train Loss:  0.459             | Val Loss:  0.494             | Train RMSE:  0.667             | Val RMSE:  0.682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 179/179 [00:04<00:00, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 246 | Train Loss:  0.468             | Val Loss:  0.493             | Train RMSE:  0.671             | Val RMSE:  0.685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 12/179 [00:00<00:04, 37.32it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Model after training.\n",
        "spr_hi_gnn.save_model(\"./models/spr_hi_gnn_finetuned_complete_v1.pth\")"
      ],
      "metadata": {
        "id": "ZANwoDkpswRR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section - 4: Arrakis GNN"
      ],
      "metadata": {
        "id": "dhMXiDUHABeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_layer(in_channels, out_channels):\n",
        "  return nn.Sequential(nn.Linear(in_channels, out_channels),\n",
        "                      nn.BatchNorm1d(out_channels),\n",
        "                      nn.LeakyReLU(1e-02))\n",
        "\n",
        "def attn_heads(in_channels, out_channels):\n",
        "  return nn.Sequential(nn.Linear(in_channels, out_channels), nn.Tanh())\n",
        "\n",
        "class ResLayer(nn.Module):\n",
        "  def __init__(self, in_c, out_c):\n",
        "    super().__init__()\n",
        "    self.l1 = linear_layer(in_c, out_c)\n",
        "    self.l2 = linear_layer(out_c, out_c)\n",
        "    self.l3 = linear_layer(out_c, out_c)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.l1(x)\n",
        "    return self.l3(self.l2(x)) + x\n",
        "\n",
        "class GATv2ConvEV2(MessagePassing):\n",
        "\n",
        "  def __init__(self, n_in, n_out, e_in, e_out):\n",
        "    super().__init__(aggr = 'add')\n",
        "    self.n_transform = ResLayer(n_in, n_out)\n",
        "    self.e_transform = ResLayer(e_in, e_out)\n",
        "\n",
        "    # Node\n",
        "    self.n_attn = attn_heads(2*n_out + e_out, 1)\n",
        "    self.e_attn = attn_heads(2*n_out + e_out, 1)\n",
        "    self.s_attn = attn_heads(2*n_out + e_out, 1)\n",
        "    self.n_message = ResLayer(e_out + 2*n_out , n_out)\n",
        "\n",
        "    # For Edge\n",
        "    self.n1_attn = ResLayer(e_out + 2*n_out, 1)\n",
        "    self.n2_attn = ResLayer(e_out + 2*n_out, 1)\n",
        "    self.s_e_attn = ResLayer(e_out + 2*n_out, 1)\n",
        "\n",
        "    # For Node Update\n",
        "    self.u_m_attn = attn_heads(2*n_out, 1)\n",
        "    self.u_s_attn = attn_heads(2*n_out, 1)\n",
        "    self.n_update = ResLayer(2*n_out, n_out)\n",
        "\n",
        "    self.e_update = ResLayer(e_out + 2*n_out, e_out)\n",
        "\n",
        "    self.n_in = n_in\n",
        "    self.n_out = n_out\n",
        "    self.e_in = e_in\n",
        "    self.e_out = e_out\n",
        "\n",
        "  def forward(self, x, edge_index, edge_attr):\n",
        "    # st()\n",
        "    x = self.n_transform(x)\n",
        "    edge_attr = self.e_transform(edge_attr)\n",
        "\n",
        "    node_features = self.propagate(edge_index, x = x, edge_attr = edge_attr)\n",
        "    edge_features = self.edge_updater(edge_index, x = x, edge_attr = edge_attr)\n",
        "\n",
        "    return node_features, edge_features\n",
        "\n",
        "  def edge_update(self, edge_index, x_i, x_j, edge_attr):\n",
        "    # 2. Edge Message Calculation\n",
        "\n",
        "    input = torch.cat([x_i, x_j, edge_attr], dim = 1)\n",
        "    n1_attn = self.n1_attn(input)\n",
        "    n2_attn = self.n2_attn(input)\n",
        "    self_attn = self.s_e_attn(input)\n",
        "\n",
        "    edge_message = torch.cat([n1_attn*x_i, n2_attn*x_j, self_attn*edge_attr], dim = 1)\n",
        "    return self.e_update(edge_message) + edge_attr\n",
        "\n",
        "  def message(self, x_i, x_j, edge_index, edge_attr):\n",
        "\n",
        "    input = torch.cat([x_i, x_j, edge_attr], dim = 1)\n",
        "    # 1. Node Message Calculation\n",
        "\n",
        "    neighbour_attn = self.n_attn(input)\n",
        "    edge_attn = self.e_attn(input)\n",
        "    self_attn = self.s_attn(input)\n",
        "\n",
        "    # 1.1 Attention Softmax\n",
        "    neighbour_attn = softmax(neighbour_attn, edge_index[0])\n",
        "    edge_attn = softmax(edge_attn, edge_index[0])\n",
        "    self_attn = softmax(self_attn, edge_index[0])\n",
        "\n",
        "    # 1.2 Gather the message\n",
        "    node_message = torch.cat([self_attn*x_i, neighbour_attn*x_j, edge_attn*edge_attr], dim = 1)\n",
        "\n",
        "    op = self.n_message(node_message)\n",
        "    return op\n",
        "\n",
        "  def update(self, aggregated_output, x):\n",
        "    '''\n",
        "    input = aggregated_output || x\n",
        "    message_attn = msg_attn(input)\n",
        "    self_attn = self_attn(input)\n",
        "\n",
        "    h` = update(message_attn*aggregated_output || self_attn*x)\n",
        "    return h`\n",
        "    '''\n",
        "\n",
        "    input = torch.cat([aggregated_output, x], dim = 1)\n",
        "    m_attn = self.u_m_attn(input)\n",
        "    s_attn = self.u_s_attn(input)\n",
        "\n",
        "    return self.n_update(torch.cat([m_attn*aggregated_output, s_attn*x], dim = 1))\n",
        "\n",
        "\n",
        "class GATV2(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels = 64, num_node_features = 45, num_edge_features = 10, num_classes = 1, regression = True):\n",
        "        super(GATV2, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GATv2ConvEV2(num_node_features, hidden_channels, num_edge_features, hidden_channels)\n",
        "        self.conv2 = GATv2ConvEV2(hidden_channels, hidden_channels, hidden_channels, hidden_channels)\n",
        "        self.conv3 = GATv2ConvEV2(hidden_channels, hidden_channels, hidden_channels, hidden_channels)\n",
        "        self.conv4 = GATv2ConvEV2(hidden_channels, hidden_channels, hidden_channels, hidden_channels)\n",
        "\n",
        "        self.regression = regression\n",
        "        if regression:\n",
        "          self.lin = nn.Sequential(nn.Linear(hidden_channels, 1))\n",
        "        else:\n",
        "          self.lin = ResLayer(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # 1. Obtain node embeddings\n",
        "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
        "        x, edge_attr = self.conv1(x, edge_index, edge_attr = edge_attr)\n",
        "        x, edge_attr = F.dropout(x, p = 0.4), F.dropout(edge_attr, p = 0.4)\n",
        "        x, edge_attr = self.conv2(x, edge_index, edge_attr = edge_attr)\n",
        "        x, edge_attr = F.dropout(x, p = 0.4), F.dropout(edge_attr, p = 0.4)\n",
        "        x, edge_attr = self.conv3(x, edge_index, edge_attr = edge_attr)\n",
        "        x, edge_attr = F.dropout(x, p = 0.4), F.dropout(edge_attr, p = 0.4)\n",
        "        x, edge_attr = self.conv4(x, edge_index, edge_attr = edge_attr)\n",
        "        x, edge_attr = F.dropout(x, p = 0.2), F.dropout(edge_attr, p = 0.2)\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        if self.regression:\n",
        "          x = self.lin(x)\n",
        "        else:\n",
        "          x = F.sigmoid(self.lin(x))\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "lGmjlAzQAGmN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadGATv2ConvEV2(nn.Module):\n",
        "\n",
        "    def __init__(self, n_in, n_out, e_in, e_out, n_heads = 4):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([GATv2ConvEV2(n_in, n_out, e_in, e_out) for i in range(n_heads)])\n",
        "\n",
        "        self.res_n = ResLayer(n_out*n_heads, n_out)\n",
        "        self.res_e = ResLayer(e_out*n_heads, e_out)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, f_att):\n",
        "\n",
        "        out = [i(x, edge_index = edge_index, edge_attr = edge_attr) for i in self.layers]\n",
        "        node_out, e_out = torch.cat([i[0] for i in out], dim = 1), torch.cat([j[1] for j in out], dim = 1)\n",
        "        return self.res_n(node_out), self.res_e(e_out)"
      ],
      "metadata": {
        "id": "4vHVF4JLBdDe"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = MultiHeadGATv2ConvEV2(45, 64, 10, 64)\n",
        "results = layer(batch.x, batch.edge_index, batch.edge_attr)"
      ],
      "metadata": {
        "id": "YlhWFs3WEnHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results[0].shape,  results[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSD2lKcpEwkS",
        "outputId": "a22fabb5-3e9c-40b6-cc3e-d817e13c1e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([439, 64]), torch.Size([908, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init('ArrakisGNN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "oiopuaKGyaHk",
        "outputId": "9e1ada6c-5093-4208-f42b-eab7c2b3fd07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbindelapranay1997\u001b[0m (\u001b[33mcomp_chem\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "wandb version 0.15.4 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/home/ec2-user/project/wandb/run-20230625_204805-eqo5u746</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/comp_chem/uncategorized/runs/eqo5u746' target=\"_blank\">swept-dew-2</a></strong> to <a href='https://wandb.ai/comp_chem/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/comp_chem/uncategorized' target=\"_blank\">https://wandb.ai/comp_chem/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/comp_chem/uncategorized/runs/eqo5u746' target=\"_blank\">https://wandb.ai/comp_chem/uncategorized/runs/eqo5u746</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/comp_chem/uncategorized/runs/eqo5u746?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f255ac686d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = GATV2()\n",
        "# train_regression(model, train_loader, val_loader, learning_rate = 1e-03, epochs = 250, wd = 1e-03)"
      ],
      "metadata": {
        "id": "4LGyZnWaycf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GATV2()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-03, weight_decay = 1e-03)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer,\n",
        "            mode = 'min',\n",
        "            factor = 0.7,\n",
        "            patience = 10,\n",
        "            min_lr = 5e-05\n",
        ")\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "NFn0JATvJNMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "        data.to(device)\n",
        "        out = model(data)\n",
        "        # out = model(data.x, data.edge_index, data.batch)\n",
        "        loss = criterion(out.squeeze(), data.y)  # Compute the loss.\n",
        "        loss.backward()  # Derive gradients.\n",
        "        optimizer.step()  # Update parameters based on gradients.\n",
        "        optimizer.zero_grad()  # Clear gradients.\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    with torch.no_grad():\n",
        "        for data in val_loader:\n",
        "            data.to(device)\n",
        "            out = model(data)\n",
        "            loss = criterion(out.squeeze(), data.y)\n",
        "            val_losses.append(loss.item())\n",
        "        lr_scheduler.step(np.mean(val_losses))\n",
        "\n",
        "    print(f'Train RMSE: {np.mean(np.sqrt(train_losses))}, Valid Losses: {np.mean(np.sqrt(val_losses))}')\n"
      ],
      "metadata": {
        "id": "6ONdxLU-BINm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCNLanA7Ugel",
        "outputId": "97c46c06-55aa-47e7-c644-bd98311e0bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch_geometric.deprecation.DataLoader at 0x7f255a9aaf10>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "lnhup9BxswVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlsaXfxhassq",
        "outputId": "cee8dad7-e319-4597-b972-c69a88dce9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MolDataBatch(x=[439, 45], edge_index=[2, 908], edge_attr=[908, 10], cluster_index=[439], fra_edge_index=[2, 826], fra_edge_attr=[826, 10], y=[32], batch=[439], ptr=[33])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv1 = GATv2ConvEV2(45, 64, 10, 64)"
      ],
      "metadata": {
        "id": "vqPxim9JU-NH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, edge_attr = conv1(x = batch.x, edge_index = batch.edge_index, edge_attr = batch.edge_attr)"
      ],
      "metadata": {
        "id": "CxWFzy5_VHHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn.pool import SAGPooling"
      ],
      "metadata": {
        "id": "IxyRaPpZWB1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poll = SAGPooling(\n",
        "    in_channels = 64,\n",
        "    ratio = 0.5,\n",
        ")"
      ],
      "metadata": {
        "id": "vWTfV9vAWp4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = poll(x = x, edge_index = batch.edge_index, edge_attr = edge_attr, batch = batch.batch)"
      ],
      "metadata": {
        "id": "NbFeajGFW6fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFvYO5HBXPpF",
        "outputId": "f7a5e37b-1baf-44e1-fa91-97b467650c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([439, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHEne9VgXKx4",
        "outputId": "02097098-374a-4e4d-ad05-38d4761bb246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([228, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results[-3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srjuyhubXWf1",
        "outputId": "171f7dad-a665-497b-c9ca-0ab6cc7dca8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  2,  2,  2,  2,  2,  3,  3,  3,\n",
              "         3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,\n",
              "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  7,  7,\n",
              "         7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
              "         8,  8,  8,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 11, 11,\n",
              "        11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13,\n",
              "        13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "        16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 18, 19, 19, 19, 19,\n",
              "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21,\n",
              "        21, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24,\n",
              "        24, 24, 24, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27,\n",
              "        27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29,\n",
              "        29, 29, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GATV3(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels = 64, num_node_features = 45, num_edge_features = 10, num_classes = 1, regression = True):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GATv2ConvEV2(num_node_features, hidden_channels, num_edge_features, hidden_channels)\n",
        "        self.conv2 = GATv2ConvEV2(hidden_channels, hidden_channels, hidden_channels, hidden_channels)\n",
        "        self.conv3 = GATv2ConvEV2(hidden_channels, hidden_channels, hidden_channels, hidden_channels)\n",
        "        self.conv4 = GATv2ConvEV2(hidden_channels, hidden_channels, hidden_channels, hidden_channels)\n",
        "\n",
        "        self.regression = regression\n",
        "\n",
        "        self.f_att = FeatureAttention(channels=hidden_channels, reduction = 4)\n",
        "\n",
        "        self.cross_att = GATConv(hidden_channels, hidden_channels, heads=4,\n",
        "                                     dropout = 0.2, add_self_loops=False,\n",
        "                                     negative_slope=0.01, concat=False)\n",
        "\n",
        "        # self.pool = SAGPooling(hidden_channels)\n",
        "\n",
        "        if regression:\n",
        "          self.lin = nn.Sequential(nn.Linear(hidden_channels, 1))\n",
        "        else:\n",
        "          self.lin = ResLayer(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # 1. Obtain node embeddings\n",
        "\n",
        "        '''\n",
        "        mol_vec = global_add_pool(x, batch).relu_()\n",
        "\n",
        "        if self.brics:\n",
        "            # get fragment input\n",
        "            fra_x = data.x\n",
        "            fra_edge_index = data.fra_edge_index\n",
        "            fra_edge_attr = data.fra_edge_attr\n",
        "            cluster = data.cluster_index\n",
        "\n",
        "            fra_x = F.relu(self.lin_a(fra_x))  # (N, 46) -> (N, hidden_channels)\n",
        "            fra_edge_attr = F.relu(self.lin_b(fra_edge_attr))  # (N, 10) -> (N, hidden_channels)\n",
        "\n",
        "            # fragment convs block\n",
        "            for i in range(0, self.num_layers):\n",
        "                fra_h = F.relu(self.atom_convs[i](fra_x, fra_edge_index, fra_edge_attr))\n",
        "                beta = self.lin_gate(torch.cat([fra_x, fra_h, fra_x - fra_h], 1)).sigmoid()\n",
        "                fra_x = beta * fra_x + (1 - beta) * fra_h\n",
        "\n",
        "                if self.f_att:\n",
        "                    fra_x = self.feature_att(fra_x, cluster)\n",
        "\n",
        "            fra_x = global_add_pool(fra_x, cluster).relu_()\n",
        "\n",
        "            # get fragment batch\n",
        "            cluster, perm = consecutive_cluster(cluster)\n",
        "            fra_batch = pool_batch(perm, data.batch)\n",
        "\n",
        "            # molecule-fragment attention\n",
        "            row = torch.arange(fra_batch.size(0), device=batch.device)\n",
        "            mol_fra_index = torch.stack([row, fra_batch], dim=0)\n",
        "            fra_vec = self.cross_att((fra_x, mol_vec), mol_fra_index).relu_()\n",
        "\n",
        "            vectors_concat = list()\n",
        "            vectors_concat.append(mol_vec)\n",
        "            vectors_concat.append(fra_vec)\n",
        "\n",
        "            out = torch.cat(vectors_concat, 1)\n",
        "        '''\n",
        "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
        "        x, edge_attr = self.conv1(x, edge_index, edge_attr = edge_attr)\n",
        "        x = self.f_att(x, batch)\n",
        "        x, edge_attr = F.dropout(x, p = 0.4), F.dropout(edge_attr, p = 0.4)\n",
        "        x, edge_attr = self.conv2(x, edge_index, edge_attr = edge_attr)\n",
        "        x = self.f_att(x, batch)\n",
        "        x, edge_attr = F.dropout(x, p = 0.4), F.dropout(edge_attr, p = 0.4)\n",
        "        x, edge_attr = self.conv3(x, edge_index, edge_attr = edge_attr)\n",
        "        x = self.f_att(x, batch)\n",
        "        x, edge_attr = F.dropout(x, p = 0.4), F.dropout(edge_attr, p = 0.4)\n",
        "        x, edge_attr = self.conv4(x, edge_index, edge_attr = edge_attr)\n",
        "        x = self.f_att(x, batch)\n",
        "        x, edge_attr = F.dropout(x, p = 0.2), F.dropout(edge_attr, p = 0.2)\n",
        "\n",
        "        mol_vec = global_mean_pool(x, batch)\n",
        "\n",
        "        out = mol_vec\n",
        "\n",
        "        out = F.dropout(out, p=0.2, training=self.training)\n",
        "        if self.regression:\n",
        "          out = self.lin(out)\n",
        "        else:\n",
        "          out = F.sigmoid(self.lin(out))\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "qNiGH9mldVq2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GATV3()\n",
        "yhat = model(batch)"
      ],
      "metadata": {
        "id": "LiNWMcFqd00g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiKrX3USjZAH",
        "outputId": "9ce61f10-79d3-4ca2-e346-418a9b41334d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GATV3()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-03, weight_decay = 1e-02)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer,\n",
        "            mode = 'min',\n",
        "            factor = 0.7,\n",
        "            patience = 10,\n",
        "            min_lr = 5e-05\n",
        ")\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "        data.to(device)\n",
        "        out = model(data)\n",
        "        # out = model(data.x, data.edge_index, data.batch)\n",
        "        loss = criterion(out.squeeze(), data.y)  # Compute the loss.\n",
        "        loss.backward()  # Derive gradients.\n",
        "        optimizer.step()  # Update parameters based on gradients.\n",
        "        optimizer.zero_grad()  # Clear gradients.\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    with torch.no_grad():\n",
        "        for data in val_loader:\n",
        "            data.to(device)\n",
        "            out = model(data)\n",
        "            loss = criterion(out.squeeze(), data.y)\n",
        "            val_losses.append(loss.item())\n",
        "        lr_scheduler.step(np.mean(val_losses))\n",
        "\n",
        "    print(f'Train RMSE: {np.mean(np.sqrt(train_losses))}, Valid Losses: {np.mean(np.sqrt(val_losses))}')\n",
        "\n",
        "\n",
        "for epoch in range(1, 150):\n",
        "    train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6otXMX92d-ZU",
        "outputId": "a9e256b3-32aa-49fa-f759-ae673de2a8c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 3.400248248124444, Valid Losses: 2.991268308280298\n",
            "Train RMSE: 2.2827690435616343, Valid Losses: 1.8206401418262548\n",
            "Train RMSE: 1.6990140753245646, Valid Losses: 1.4607409038501178\n",
            "Train RMSE: 1.5723290652607669, Valid Losses: 1.3188192792617532\n",
            "Train RMSE: 1.377244443309599, Valid Losses: 1.3349492352891676\n",
            "Train RMSE: 1.251257478049895, Valid Losses: 1.1785874257085263\n",
            "Train RMSE: 1.2116517309992003, Valid Losses: 1.1094417081062748\n",
            "Train RMSE: 1.1754300490480352, Valid Losses: 1.0376966012523667\n",
            "Train RMSE: 1.1621967692379338, Valid Losses: 1.106565663095354\n",
            "Train RMSE: 1.1582052914518466, Valid Losses: 0.9371782549396932\n",
            "Train RMSE: 1.1215483036530811, Valid Losses: 0.9890749444971806\n",
            "Train RMSE: 1.0389021412812165, Valid Losses: 0.9231088329105299\n",
            "Train RMSE: 1.0467408307282062, Valid Losses: 0.9633297009517967\n",
            "Train RMSE: 1.0477751313752968, Valid Losses: 0.9244987815009452\n",
            "Train RMSE: 1.0152549875824426, Valid Losses: 0.9987712555932905\n",
            "Train RMSE: 1.079957898957609, Valid Losses: 0.8985605870381267\n",
            "Train RMSE: 0.9870264776776769, Valid Losses: 0.9610116191815443\n",
            "Train RMSE: 0.978848159380597, Valid Losses: 0.7785560668189473\n",
            "Train RMSE: 0.9702278655767284, Valid Losses: 0.7853132210829477\n",
            "Train RMSE: 0.9705363296145932, Valid Losses: 0.8150728844978011\n",
            "Train RMSE: 0.955103781383021, Valid Losses: 0.9063188073787557\n",
            "Train RMSE: 0.952112572200559, Valid Losses: 0.8299310512786775\n",
            "Train RMSE: 0.9577411034164771, Valid Losses: 0.7697254760141627\n",
            "Train RMSE: 0.9069860829622148, Valid Losses: 0.8368137700179038\n",
            "Train RMSE: 0.9098336159164797, Valid Losses: 0.7509277536962748\n",
            "Train RMSE: 0.900207349401541, Valid Losses: 0.7639052282052216\n",
            "Train RMSE: 0.8802465624829734, Valid Losses: 0.7812245579806201\n",
            "Train RMSE: 0.8945722018993771, Valid Losses: 0.7986114175951763\n",
            "Train RMSE: 0.8883702343215938, Valid Losses: 0.7567619227171475\n",
            "Train RMSE: 0.8564553245764175, Valid Losses: 0.7448261376453075\n",
            "Train RMSE: 0.877968400484667, Valid Losses: 0.7947322882326259\n",
            "Train RMSE: 0.8783036488397185, Valid Losses: 0.7838410009546093\n",
            "Train RMSE: 0.8887799531747467, Valid Losses: 0.7317151771334683\n",
            "Train RMSE: 0.9042416535443333, Valid Losses: 0.842222921286027\n",
            "Train RMSE: 0.9381111697185831, Valid Losses: 0.902834472252857\n",
            "Train RMSE: 0.9024003066853579, Valid Losses: 0.7006051872125311\n",
            "Train RMSE: 0.8815630613295641, Valid Losses: 0.7501369591899111\n",
            "Train RMSE: 0.9095665967545359, Valid Losses: 0.7442176950680843\n",
            "Train RMSE: 0.9147790253728277, Valid Losses: 0.7693897433195859\n",
            "Train RMSE: 0.8548946017804514, Valid Losses: 0.7346013757374675\n",
            "Train RMSE: 0.859306404512484, Valid Losses: 0.6947275731299059\n",
            "Train RMSE: 0.8314549562763309, Valid Losses: 0.7721126805042462\n",
            "Train RMSE: 0.8203904252050804, Valid Losses: 0.6820753352982905\n",
            "Train RMSE: 0.8723041207714728, Valid Losses: 0.7433224759489435\n",
            "Train RMSE: 0.8414778506657821, Valid Losses: 0.8047685513803214\n",
            "Train RMSE: 0.8463835802184622, Valid Losses: 0.7619411873499712\n",
            "Train RMSE: 0.8542203169042876, Valid Losses: 0.7239779014909897\n",
            "Train RMSE: 0.8420143485210176, Valid Losses: 0.8151207444476634\n",
            "Train RMSE: 0.821710664308083, Valid Losses: 0.697701619334379\n",
            "Train RMSE: 0.808826576613088, Valid Losses: 0.7032530328117743\n",
            "Train RMSE: 0.833028123245892, Valid Losses: 0.6980092056818875\n",
            "Train RMSE: 0.8572460915818729, Valid Losses: 0.7203573886173302\n",
            "Train RMSE: 0.8047216085214421, Valid Losses: 0.7077259237534805\n",
            "Train RMSE: 0.8177274169622394, Valid Losses: 0.7831461766013532\n",
            "Train RMSE: 0.7921157812347855, Valid Losses: 0.7594387210281094\n",
            "Train RMSE: 0.7934139641247019, Valid Losses: 0.6901118307827449\n",
            "Train RMSE: 0.7983388144733803, Valid Losses: 0.6369370585686573\n",
            "Train RMSE: 0.8362094738865334, Valid Losses: 0.6684935309324893\n",
            "Train RMSE: 0.8031804648620046, Valid Losses: 0.7224688305646659\n",
            "Train RMSE: 0.8289737745241039, Valid Losses: 0.7423052971380085\n",
            "Train RMSE: 0.8109394183301479, Valid Losses: 0.7046811907727796\n",
            "Train RMSE: 0.8015625690683861, Valid Losses: 0.6450623317455626\n",
            "Train RMSE: 0.7531914976202662, Valid Losses: 0.7229754346472472\n",
            "Train RMSE: 0.7718225151511093, Valid Losses: 0.6413295934959582\n",
            "Train RMSE: 0.7546162180669679, Valid Losses: 0.6382498080629164\n",
            "Train RMSE: 0.7737264519729835, Valid Losses: 0.6314121778539461\n",
            "Train RMSE: 0.7584742950343923, Valid Losses: 0.7315226607180261\n",
            "Train RMSE: 0.7631454003854908, Valid Losses: 0.7341348675668307\n",
            "Train RMSE: 0.7737034456062172, Valid Losses: 0.6579465679601613\n",
            "Train RMSE: 0.781451077926983, Valid Losses: 0.6418799019701977\n",
            "Train RMSE: 0.7731263570352058, Valid Losses: 0.6931964922958763\n",
            "Train RMSE: 0.8364671815968486, Valid Losses: 0.7133450829410845\n",
            "Train RMSE: 0.7282533555852262, Valid Losses: 0.6643535869131106\n",
            "Train RMSE: 0.8029821067166264, Valid Losses: 0.6623047890696435\n",
            "Train RMSE: 0.7736177676716225, Valid Losses: 0.7055198489396651\n",
            "Train RMSE: 0.7434051733837154, Valid Losses: 0.7288054066173357\n",
            "Train RMSE: 0.7837021479269495, Valid Losses: 0.6698889027034831\n",
            "Train RMSE: 0.7433315572840447, Valid Losses: 0.6537847791120797\n",
            "Train RMSE: 0.7601841840207643, Valid Losses: 0.6551808365656782\n",
            "Train RMSE: 0.7652890647584082, Valid Losses: 0.7036253066639288\n",
            "Train RMSE: 0.7462134162678278, Valid Losses: 0.6469136265214904\n",
            "Train RMSE: 0.7415209909033357, Valid Losses: 0.6624443762249383\n",
            "Train RMSE: 0.7135096190245466, Valid Losses: 0.6705207832104949\n",
            "Train RMSE: 0.714278601661379, Valid Losses: 0.6406404184761556\n",
            "Train RMSE: 0.7511591668799992, Valid Losses: 0.6390831018476248\n",
            "Train RMSE: 0.722913172072262, Valid Losses: 0.6079664060348604\n",
            "Train RMSE: 0.7185349454714356, Valid Losses: 0.6177260740447348\n",
            "Train RMSE: 0.7243832102254735, Valid Losses: 0.5721151178882025\n",
            "Train RMSE: 0.6964940675662137, Valid Losses: 0.6114389635758998\n",
            "Train RMSE: 0.7275751474286416, Valid Losses: 0.6750690853370732\n",
            "Train RMSE: 0.7223964845866788, Valid Losses: 0.615636079372159\n",
            "Train RMSE: 0.7495872970840728, Valid Losses: 0.6544413011769036\n",
            "Train RMSE: 0.6905417993690803, Valid Losses: 0.7178385365055812\n",
            "Train RMSE: 0.7707834476795641, Valid Losses: 0.6783698488713721\n",
            "Train RMSE: 0.76012734297284, Valid Losses: 0.6386970061649947\n",
            "Train RMSE: 0.7656651187977084, Valid Losses: 0.6974620990302098\n",
            "Train RMSE: 0.764356587319764, Valid Losses: 0.6747136878404415\n",
            "Train RMSE: 0.7573070519289744, Valid Losses: 0.6034069357987496\n",
            "Train RMSE: 0.7266562027722058, Valid Losses: 0.609856840561464\n",
            "Train RMSE: 0.6983738393791725, Valid Losses: 0.5832420737998268\n",
            "Train RMSE: 0.6917682589968939, Valid Losses: 0.5987748399387449\n",
            "Train RMSE: 0.7012784077743578, Valid Losses: 0.568808598557317\n",
            "Train RMSE: 0.7202655993975999, Valid Losses: 0.5897955049936943\n",
            "Train RMSE: 0.742423040812655, Valid Losses: 0.6128036032260051\n",
            "Train RMSE: 0.7374042020106008, Valid Losses: 0.6168218286325258\n",
            "Train RMSE: 0.7161832515492725, Valid Losses: 0.5789009505483833\n",
            "Train RMSE: 0.7645427447519502, Valid Losses: 0.5985438089950417\n",
            "Train RMSE: 0.6925550809749553, Valid Losses: 0.6228760252401606\n",
            "Train RMSE: 0.662458791076201, Valid Losses: 0.5884122675811689\n",
            "Train RMSE: 0.6875586983873856, Valid Losses: 0.6517260162609589\n",
            "Train RMSE: 0.6617357462106743, Valid Losses: 0.6001138296992016\n",
            "Train RMSE: 0.6816156073132057, Valid Losses: 0.6011573251471621\n",
            "Train RMSE: 0.7022632434351354, Valid Losses: 0.5671818356608169\n",
            "Train RMSE: 0.7215227410317941, Valid Losses: 0.6068653215424068\n",
            "Train RMSE: 0.6880828137430602, Valid Losses: 0.5779605587182556\n",
            "Train RMSE: 0.6669014008702653, Valid Losses: 0.6219627005095346\n",
            "Train RMSE: 0.6615669650524181, Valid Losses: 0.5789373579244558\n",
            "Train RMSE: 0.6899403134075789, Valid Losses: 0.58322521656928\n",
            "Train RMSE: 0.7013298535140051, Valid Losses: 0.5887614631305653\n",
            "Train RMSE: 0.6622571334535607, Valid Losses: 0.6112265579792132\n",
            "Train RMSE: 0.6836415701441703, Valid Losses: 0.5708872867833931\n",
            "Train RMSE: 0.7021520495855094, Valid Losses: 0.598392936897937\n",
            "Train RMSE: 0.6883693944307597, Valid Losses: 0.5937422414282284\n",
            "Train RMSE: 0.6661074559150899, Valid Losses: 0.5431525449148674\n",
            "Train RMSE: 0.6600616494878799, Valid Losses: 0.592986015345401\n",
            "Train RMSE: 0.6635981527725584, Valid Losses: 0.6099332109264106\n",
            "Train RMSE: 0.6708858149873611, Valid Losses: 0.6250799302701572\n",
            "Train RMSE: 0.6614953766399416, Valid Losses: 0.6366874900794371\n",
            "Train RMSE: 0.6493317860393287, Valid Losses: 0.5439345454420896\n",
            "Train RMSE: 0.6681551918271392, Valid Losses: 0.6013797979956548\n",
            "Train RMSE: 0.6581354197387624, Valid Losses: 0.5671133933420398\n",
            "Train RMSE: 0.6453663603785977, Valid Losses: 0.5783080950405112\n",
            "Train RMSE: 0.6634215053558195, Valid Losses: 0.4978611024466695\n",
            "Train RMSE: 0.6321888699876276, Valid Losses: 0.5551293013972826\n",
            "Train RMSE: 0.6409429499807693, Valid Losses: 0.5462476469470867\n",
            "Train RMSE: 0.6274425085398588, Valid Losses: 0.6237427704156705\n",
            "Train RMSE: 0.671170204626409, Valid Losses: 0.5788562563056197\n",
            "Train RMSE: 0.6469435746503185, Valid Losses: 0.6266201451267255\n",
            "Train RMSE: 0.684897051587173, Valid Losses: 0.5919540311249523\n",
            "Train RMSE: 0.6747806338301244, Valid Losses: 0.6333569067677335\n",
            "Train RMSE: 0.6062688347062669, Valid Losses: 0.5988134134702945\n",
            "Train RMSE: 0.6732282395314171, Valid Losses: 0.5739796993674977\n",
            "Train RMSE: 0.6668494847025207, Valid Losses: 0.5786409201767101\n",
            "Train RMSE: 0.6521670292329665, Valid Losses: 0.5914205834811936\n",
            "Train RMSE: 0.6519149503767006, Valid Losses: 0.6211949149949949\n",
            "Train RMSE: 0.6176419325234923, Valid Losses: 0.5800561113068813\n",
            "Train RMSE: 0.6306615030182073, Valid Losses: 0.5488100980099236\n",
            "Train RMSE: 0.6149118856237945, Valid Losses: 0.5438583177637579\n",
            "Train RMSE: 0.6063010167549355, Valid Losses: 0.5294025399284635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 150):\n",
        "    train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXbJ0E9cqvYj",
        "outputId": "6eac0cec-a4a9-4ac2-9b3d-a9a1fa9dd7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 0.6937379033765744, Valid Losses: 0.5179732512345189\n",
            "Train RMSE: 0.6800312429451907, Valid Losses: 0.5653500727598703\n",
            "Train RMSE: 0.6036149992319468, Valid Losses: 0.5779908563101285\n",
            "Train RMSE: 0.6411733088402959, Valid Losses: 0.5746442992547252\n",
            "Train RMSE: 0.6451669579735426, Valid Losses: 0.5710047845411389\n",
            "Train RMSE: 0.615684936223692, Valid Losses: 0.5826755585333527\n",
            "Train RMSE: 0.6177300414934402, Valid Losses: 0.5486188112138968\n",
            "Train RMSE: 0.6420171511953122, Valid Losses: 0.5598852368125777\n",
            "Train RMSE: 0.6018550749898338, Valid Losses: 0.5839248557479892\n",
            "Train RMSE: 0.5894411015179676, Valid Losses: 0.5387001497876084\n",
            "Train RMSE: 0.5891836826493689, Valid Losses: 0.5455377357919855\n",
            "Train RMSE: 0.6398945443934864, Valid Losses: 0.5200548831707131\n",
            "Train RMSE: 0.6295798339459001, Valid Losses: 0.5524677006423165\n",
            "Train RMSE: 0.6322705993185701, Valid Losses: 0.5760578557568532\n",
            "Train RMSE: 0.5903749686352014, Valid Losses: 0.5519906506588834\n",
            "Train RMSE: 0.6186243071391648, Valid Losses: 0.5408870387078933\n",
            "Train RMSE: 0.6085657931061255, Valid Losses: 0.5706232339639922\n",
            "Train RMSE: 0.6053724927984603, Valid Losses: 0.603676299590451\n",
            "Train RMSE: 0.6117600424436361, Valid Losses: 0.5136700434468469\n",
            "Train RMSE: 0.6271679326323635, Valid Losses: 0.5641745607478326\n",
            "Train RMSE: 0.5990097155536808, Valid Losses: 0.5830406977443102\n",
            "Train RMSE: 0.6056423545195836, Valid Losses: 0.5961954429271236\n",
            "Train RMSE: 0.6175550127671474, Valid Losses: 0.5602951843869339\n",
            "Train RMSE: 0.5979246463646917, Valid Losses: 0.5574089315018724\n",
            "Train RMSE: 0.5819551798190612, Valid Losses: 0.5444921867688177\n",
            "Train RMSE: 0.5993284764876123, Valid Losses: 0.5062778314961297\n",
            "Train RMSE: 0.574015404222579, Valid Losses: 0.4995317909365351\n",
            "Train RMSE: 0.632283152117804, Valid Losses: 0.5745713471713447\n",
            "Train RMSE: 0.6037516123892621, Valid Losses: 0.528781697674758\n",
            "Train RMSE: 0.5795900313351768, Valid Losses: 0.5502835277382891\n",
            "Train RMSE: 0.6008833600385632, Valid Losses: 0.5939560070812113\n",
            "Train RMSE: 0.5891828889187235, Valid Losses: 0.5764005418130336\n",
            "Train RMSE: 0.585169359142765, Valid Losses: 0.5517174997992044\n",
            "Train RMSE: 0.5746782639706624, Valid Losses: 0.5596383434435908\n",
            "Train RMSE: 0.5684888630394391, Valid Losses: 0.5642921410328684\n",
            "Train RMSE: 0.5924340298244882, Valid Losses: 0.5351539517267088\n",
            "Train RMSE: 0.602964139067822, Valid Losses: 0.5662276192520727\n",
            "Train RMSE: 0.5757802722149656, Valid Losses: 0.5688556894630508\n",
            "Train RMSE: 0.5827409319982703, Valid Losses: 0.5836402344112126\n",
            "Train RMSE: 0.585448783822957, Valid Losses: 0.5719606058818295\n",
            "Train RMSE: 0.5722623434027445, Valid Losses: 0.5410796158574661\n",
            "Train RMSE: 0.5530268853059476, Valid Losses: 0.5743603643013561\n",
            "Train RMSE: 0.5577366558395929, Valid Losses: 0.5583031784945244\n",
            "Train RMSE: 0.5654582673573716, Valid Losses: 0.5281885029963841\n",
            "Train RMSE: 0.5615247572876189, Valid Losses: 0.589648658619066\n",
            "Train RMSE: 0.5624648660815394, Valid Losses: 0.5718397556033915\n",
            "Train RMSE: 0.5556996291263387, Valid Losses: 0.5362780209402541\n",
            "Train RMSE: 0.588907349941578, Valid Losses: 0.5438076022997386\n",
            "Train RMSE: 0.589885848345874, Valid Losses: 0.5535692627404989\n",
            "Train RMSE: 0.5496507251916425, Valid Losses: 0.5508285292813655\n",
            "Train RMSE: 0.5386211267627029, Valid Losses: 0.5294949865438076\n",
            "Train RMSE: 0.5739604446760105, Valid Losses: 0.566799941261715\n",
            "Train RMSE: 0.5682956424746415, Valid Losses: 0.577796424165874\n",
            "Train RMSE: 0.5541503001401661, Valid Losses: 0.563956616977487\n",
            "Train RMSE: 0.5973447082971125, Valid Losses: 0.5470724649743987\n",
            "Train RMSE: 0.5699897279760693, Valid Losses: 0.6085355408591122\n",
            "Train RMSE: 0.5753115285763891, Valid Losses: 0.5959464042143773\n",
            "Train RMSE: 0.5718466128607043, Valid Losses: 0.5624881464196312\n",
            "Train RMSE: 0.59955687039159, Valid Losses: 0.606666849160054\n",
            "Train RMSE: 0.5718374930995714, Valid Losses: 0.5453354099130638\n",
            "Train RMSE: 0.5645619852782902, Valid Losses: 0.5397898538394825\n",
            "Train RMSE: 0.558608073305857, Valid Losses: 0.5723048175525609\n",
            "Train RMSE: 0.5435896154358554, Valid Losses: 0.5663600769995409\n",
            "Train RMSE: 0.5469737188645889, Valid Losses: 0.5402055650480891\n",
            "Train RMSE: 0.5640266517921049, Valid Losses: 0.5547061326381423\n",
            "Train RMSE: 0.5635890433119684, Valid Losses: 0.5856369020312922\n",
            "Train RMSE: 0.5811378184102998, Valid Losses: 0.5592147957682728\n",
            "Train RMSE: 0.5331866683664171, Valid Losses: 0.5712029938567118\n",
            "Train RMSE: 0.5478319598838616, Valid Losses: 0.5839927996117663\n",
            "Train RMSE: 0.5775207350473346, Valid Losses: 0.5320592646317971\n",
            "Train RMSE: 0.5528246166615883, Valid Losses: 0.570856606032765\n",
            "Train RMSE: 0.5604143149487086, Valid Losses: 0.5585839266901848\n",
            "Train RMSE: 0.5569778558379073, Valid Losses: 0.5499643042740767\n",
            "Train RMSE: 0.5664352740512728, Valid Losses: 0.5699423605469367\n",
            "Train RMSE: 0.5560784321251842, Valid Losses: 0.5402775449648112\n",
            "Train RMSE: 0.5399442069784768, Valid Losses: 0.5525919682936257\n",
            "Train RMSE: 0.544236747661804, Valid Losses: 0.5528464433352471\n",
            "Train RMSE: 0.5664045940611484, Valid Losses: 0.5512164307433427\n",
            "Train RMSE: 0.5370918021190675, Valid Losses: 0.5628804371286834\n",
            "Train RMSE: 0.535526278683793, Valid Losses: 0.5726191168354323\n",
            "Train RMSE: 0.5638821274066717, Valid Losses: 0.5565221051781561\n",
            "Train RMSE: 0.554668932889298, Valid Losses: 0.5863924084696446\n",
            "Train RMSE: 0.5549563456518269, Valid Losses: 0.5489404144468667\n",
            "Train RMSE: 0.5378729970075167, Valid Losses: 0.6008787752331212\n",
            "Train RMSE: 0.5412412996239007, Valid Losses: 0.5578576739370322\n",
            "Train RMSE: 0.5441059855649455, Valid Losses: 0.5484895833182426\n",
            "Train RMSE: 0.5455469429844307, Valid Losses: 0.5039271023327418\n",
            "Train RMSE: 0.5489374847494987, Valid Losses: 0.5442466152742239\n",
            "Train RMSE: 0.5551467437480949, Valid Losses: 0.5320701723150366\n",
            "Train RMSE: 0.529784422903332, Valid Losses: 0.5688420462920734\n",
            "Train RMSE: 0.5845920800010567, Valid Losses: 0.5731747773998342\n",
            "Train RMSE: 0.5481413067755148, Valid Losses: 0.565690477085232\n",
            "Train RMSE: 0.5449711676455657, Valid Losses: 0.57810788491138\n",
            "Train RMSE: 0.5860443410728182, Valid Losses: 0.5679054730220775\n",
            "Train RMSE: 0.5574425957010996, Valid Losses: 0.5633231380756119\n",
            "Train RMSE: 0.5609560716249657, Valid Losses: 0.5793371670494497\n",
            "Train RMSE: 0.563469234843939, Valid Losses: 0.5523886215684889\n",
            "Train RMSE: 0.548285170014942, Valid Losses: 0.5709828813470026\n",
            "Train RMSE: 0.5609468586603615, Valid Losses: 0.5375265606099511\n",
            "Train RMSE: 0.5220726723754554, Valid Losses: 0.5756373342492838\n",
            "Train RMSE: 0.5423262319257289, Valid Losses: 0.5825210741221354\n",
            "Train RMSE: 0.5489430643813037, Valid Losses: 0.5648639081085677\n",
            "Train RMSE: 0.5599634207969807, Valid Losses: 0.553525330918271\n",
            "Train RMSE: 0.5483721664893316, Valid Losses: 0.5441305591717761\n",
            "Train RMSE: 0.5265788401031284, Valid Losses: 0.5532578707634104\n",
            "Train RMSE: 0.5638842006402789, Valid Losses: 0.5489063123990745\n",
            "Train RMSE: 0.554140257191458, Valid Losses: 0.547638766453999\n",
            "Train RMSE: 0.5535248991200802, Valid Losses: 0.5599109801678107\n",
            "Train RMSE: 0.5349926806368945, Valid Losses: 0.5396780861512028\n",
            "Train RMSE: 0.5295833680698302, Valid Losses: 0.5756157137060639\n",
            "Train RMSE: 0.5101874786392603, Valid Losses: 0.5121280894852422\n",
            "Train RMSE: 0.5230013661151992, Valid Losses: 0.546108327566956\n",
            "Train RMSE: 0.536128358342957, Valid Losses: 0.5360351494906205\n",
            "Train RMSE: 0.5320329924355927, Valid Losses: 0.5369759510470988\n",
            "Train RMSE: 0.5322434402282561, Valid Losses: 0.5049059709110296\n",
            "Train RMSE: 0.5261231807371128, Valid Losses: 0.5199260343107369\n",
            "Train RMSE: 0.5392108006433628, Valid Losses: 0.5185820492734662\n",
            "Train RMSE: 0.5358028207966272, Valid Losses: 0.5689998024639601\n",
            "Train RMSE: 0.5314574299524661, Valid Losses: 0.5647380690312278\n",
            "Train RMSE: 0.5522901083916463, Valid Losses: 0.5048587274188762\n",
            "Train RMSE: 0.5352377219108572, Valid Losses: 0.5232827327058182\n",
            "Train RMSE: 0.5353325845995367, Valid Losses: 0.549368816242204\n",
            "Train RMSE: 0.5387824943507245, Valid Losses: 0.5541797121992813\n",
            "Train RMSE: 0.5291843569199325, Valid Losses: 0.5449627021126274\n",
            "Train RMSE: 0.5501506755934799, Valid Losses: 0.570489905714018\n",
            "Train RMSE: 0.5358407424978816, Valid Losses: 0.5578916195206932\n",
            "Train RMSE: 0.5489519839428806, Valid Losses: 0.5655703658370606\n",
            "Train RMSE: 0.5585885150452936, Valid Losses: 0.5449902032931796\n",
            "Train RMSE: 0.5606251430265462, Valid Losses: 0.5746430891530346\n",
            "Train RMSE: 0.5480455410291709, Valid Losses: 0.5930362546628927\n",
            "Train RMSE: 0.5463447855016312, Valid Losses: 0.5560804183526395\n",
            "Train RMSE: 0.5215216008094568, Valid Losses: 0.5811427472429165\n",
            "Train RMSE: 0.5075109530823847, Valid Losses: 0.5714541308424079\n",
            "Train RMSE: 0.5547167556293383, Valid Losses: 0.6117985810849209\n",
            "Train RMSE: 0.5304857757011083, Valid Losses: 0.5831082902197346\n",
            "Train RMSE: 0.5221241208795256, Valid Losses: 0.5684458084258637\n",
            "Train RMSE: 0.5397903927355225, Valid Losses: 0.5518327051474395\n",
            "Train RMSE: 0.5530956408895448, Valid Losses: 0.5622306369202303\n",
            "Train RMSE: 0.5436361149192329, Valid Losses: 0.5632014233409942\n",
            "Train RMSE: 0.5241952344754544, Valid Losses: 0.6053078002871719\n",
            "Train RMSE: 0.5223208858234162, Valid Losses: 0.5546332472706966\n",
            "Train RMSE: 0.5130306562277497, Valid Losses: 0.5579607528469065\n",
            "Train RMSE: 0.5339375484911657, Valid Losses: 0.579479584027806\n",
            "Train RMSE: 0.5551991683177525, Valid Losses: 0.5724887915800247\n",
            "Train RMSE: 0.5237225142149858, Valid Losses: 0.5318643191323051\n",
            "Train RMSE: 0.5334787252118806, Valid Losses: 0.5340945373621157\n",
            "Train RMSE: 0.5230493239444314, Valid Losses: 0.5625722488943975\n",
            "Train RMSE: 0.5697436610863424, Valid Losses: 0.57052819268674\n",
            "Train RMSE: 0.5501470668704311, Valid Losses: 0.5514882548968096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aofRQLrlz8_0",
        "outputId": "55617a54-95e9-49ee-cb8f-b553bb86420f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MolDataBatch(x=[439, 45], edge_index=[2, 908], edge_attr=[908, 10], cluster_index=[439], fra_edge_index=[2, 826], fra_edge_attr=[826, 10], y=[32], batch=[439], ptr=[33])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GATV4(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels = 64, num_node_features = 45, num_edge_features = 10, num_classes = 1, regression = True, n_heads = 4):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = MultiHeadGATv2ConvEV2(num_node_features, hidden_channels, num_edge_features, hidden_channels, n_heads = n_heads)\n",
        "        self.conv2 = MultiHeadGATv2ConvEV2(hidden_channels, hidden_channels, hidden_channels, hidden_channels, n_heads = n_heads)\n",
        "        self.conv3 = MultiHeadGATv2ConvEV2(hidden_channels, hidden_channels, hidden_channels, hidden_channels, n_heads = n_heads)\n",
        "        self.conv4 = MultiHeadGATv2ConvEV2(hidden_channels, hidden_channels, hidden_channels, hidden_channels, n_heads = n_heads)\n",
        "\n",
        "        self.regression = regression\n",
        "\n",
        "        self.f_att = FeatureAttention(channels=hidden_channels, reduction = 4)\n",
        "\n",
        "        self.res = ResLayer(hidden_channels, hidden_channels)\n",
        "        # self.pool = SAGPooling(hidden_channels)\n",
        "\n",
        "        if regression:\n",
        "          self.lin = nn.Sequential(nn.Linear(hidden_channels, 1))\n",
        "        else:\n",
        "          self.lin = ResLayer(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # 1. Obtain node embeddings\n",
        "\n",
        "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
        "        x, edge_attr = self.conv1(x, edge_index, edge_attr = edge_attr)\n",
        "        x = self.f_att(x, batch)\n",
        "\n",
        "        # mol_vec = global_mean_pool(x, batch)\n",
        "\n",
        "        x, edge_attr = F.dropout(x, p = 0.4), F.dropout(edge_attr, p = 0.4)\n",
        "        x, edge_attr = self.conv2(x, edge_index, edge_attr = edge_attr)\n",
        "        x = self.f_att(x, batch)\n",
        "\n",
        "        # mol_vec += global_mean_pool(x, batch)\n",
        "\n",
        "        x, edge_attr = F.dropout(x, p = 0.4), F.dropout(edge_attr, p = 0.4)\n",
        "        x, edge_attr = self.conv3(x, edge_index, edge_attr = edge_attr)\n",
        "        x = self.f_att(x, batch)\n",
        "\n",
        "        # mol_vec += global_mean_pool(x, batch)\n",
        "\n",
        "        x, edge_attr = F.dropout(x, p = 0.4), F.dropout(edge_attr, p = 0.4)\n",
        "        x, edge_attr = self.conv4(x, edge_index, edge_attr = edge_attr)\n",
        "        x = self.f_att(x, batch)\n",
        "        x, edge_attr = F.dropout(x, p = 0.2), F.dropout(edge_attr, p = 0.2)\n",
        "\n",
        "        # results = self.pool(x, edge_index = edge_index, edge_attr = edge_attr, batch = batch)\n",
        "\n",
        "        # x, new_batch = results[0], results[-3]\n",
        "        mol_vec = global_mean_pool(x, batch)\n",
        "\n",
        "        # out = self.res(mol_vec)\n",
        "        out = mol_vec\n",
        "        out = F.dropout(out, p=0.2, training=self.training)\n",
        "        if self.regression:\n",
        "          out = self.lin(out)\n",
        "        else:\n",
        "          out = F.sigmoid(self.lin(out))\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "l6eP1vqvvLbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GATV4(hidden_channels= 128)\n",
        "model(batch)"
      ],
      "metadata": {
        "id": "Sl9LZd0702Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_Gvi7GiFSP_",
        "outputId": "6c33de3e-725e-43b6-895c-e6f935d0393b"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GATV4(hidden_channels = 128)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-03, weight_decay = 1e-03)\n",
        "# lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "#             optimizer,\n",
        "#             mode = 'min',\n",
        "#             factor = 0.7,\n",
        "#             patience = 10,\n",
        "#             min_lr = 5e-05\n",
        "# )\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr = 1e-03,\n",
        "    epochs = 250,\n",
        "    steps_per_epoch = len(train_loader)\n",
        ")\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "        data.to(device)\n",
        "        out = model(data)\n",
        "        # out = model(data.x, data.edge_index, data.batch)\n",
        "        loss = criterion(out.squeeze(), data.y)  # Compute the loss.\n",
        "        loss.backward()  # Derive gradients.\n",
        "        optimizer.step()  # Update parameters based on gradients.\n",
        "        optimizer.zero_grad()  # Clear gradients.\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    with torch.no_grad():\n",
        "        for data in val_loader:\n",
        "            data.to(device)\n",
        "            out = model(data)\n",
        "            loss = criterion(out.squeeze(), data.y)\n",
        "            val_losses.append(loss.item())\n",
        "        lr_scheduler.step(np.mean(val_losses))\n",
        "\n",
        "    print(f'Train RMSE: {np.mean(np.sqrt(train_losses))}, Valid Losses: {np.mean(np.sqrt(val_losses))}')\n",
        "\n",
        "\n",
        "for epoch in range(1, 250):\n",
        "    train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC4cD3iFvu4Q",
        "outputId": "ac81978e-09c3-49a5-d458-16bd76b5d1ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 2.7149897921995327, Valid Losses: 2.32883527083911\n",
            "Train RMSE: 1.8061926069451855, Valid Losses: 2.206508559527851\n",
            "Train RMSE: 1.544204898167386, Valid Losses: 1.711243951495466\n",
            "Train RMSE: 1.416636652663055, Valid Losses: 1.5511585716226317\n",
            "Train RMSE: 1.3092830463948033, Valid Losses: 1.58008059084729\n",
            "Train RMSE: 1.3068012533620135, Valid Losses: 1.3168007080862547\n",
            "Train RMSE: 1.2165544446052032, Valid Losses: 1.1047186313327764\n",
            "Train RMSE: 1.147266531153502, Valid Losses: 1.3711730420584605\n",
            "Train RMSE: 1.0534742124852525, Valid Losses: 1.086479976739377\n",
            "Train RMSE: 1.0374653361819093, Valid Losses: 1.0097324926372537\n",
            "Train RMSE: 1.0301041478518151, Valid Losses: 0.8463671132875785\n",
            "Train RMSE: 0.9810862363407924, Valid Losses: 1.0139828257502657\n",
            "Train RMSE: 0.9168565312025015, Valid Losses: 0.7597968225709\n",
            "Train RMSE: 0.9289993415888591, Valid Losses: 0.7742265584272746\n",
            "Train RMSE: 0.8611756809609681, Valid Losses: 0.8394028537939329\n",
            "Train RMSE: 0.9098639061475758, Valid Losses: 0.8400852366416593\n",
            "Train RMSE: 0.936702494275647, Valid Losses: 0.8878591868552158\n",
            "Train RMSE: 0.8706771765684351, Valid Losses: 0.8388410032583186\n",
            "Train RMSE: 0.8656498582522287, Valid Losses: 0.8140687571624192\n",
            "Train RMSE: 0.8741621733244392, Valid Losses: 0.8012410113737048\n",
            "Train RMSE: 0.8297134651571718, Valid Losses: 0.7611974944101464\n",
            "Train RMSE: 0.837816366204584, Valid Losses: 0.8115661149124618\n",
            "Train RMSE: 0.9033939990174088, Valid Losses: 0.6736250506767882\n",
            "Train RMSE: 0.8615402708367199, Valid Losses: 0.7324554058167891\n",
            "Train RMSE: 0.8532190827705256, Valid Losses: 0.7523154634576822\n",
            "Train RMSE: 0.8171546173672369, Valid Losses: 0.8259161917307629\n",
            "Train RMSE: 0.7714541432170832, Valid Losses: 0.7090498279210762\n",
            "Train RMSE: 0.8482024768604626, Valid Losses: 0.8883232646881875\n",
            "Train RMSE: 0.8305200753025056, Valid Losses: 0.7300480080442163\n",
            "Train RMSE: 0.811157877799913, Valid Losses: 0.7188890142920155\n",
            "Train RMSE: 0.8304094046592291, Valid Losses: 0.7656570993673818\n",
            "Train RMSE: 0.821423676102164, Valid Losses: 0.7995290367526068\n",
            "Train RMSE: 0.7859941054333026, Valid Losses: 0.7355509426881304\n",
            "Train RMSE: 0.8248161292916708, Valid Losses: 0.7164729022749119\n",
            "Train RMSE: 0.841838127711764, Valid Losses: 0.7505151572497286\n",
            "Train RMSE: 0.8004447183795075, Valid Losses: 0.7478465998408266\n",
            "Train RMSE: 0.7979932909034158, Valid Losses: 0.717759965337613\n",
            "Train RMSE: 0.7759185514863477, Valid Losses: 0.7021787864138365\n",
            "Train RMSE: 0.7678960280985607, Valid Losses: 0.7223905672283023\n",
            "Train RMSE: 0.7368623885135996, Valid Losses: 0.6976997889950664\n",
            "Train RMSE: 0.7308716632475054, Valid Losses: 0.6745418063039661\n",
            "Train RMSE: 0.7595012421059868, Valid Losses: 0.6787990971638003\n",
            "Train RMSE: 0.7691094485298493, Valid Losses: 0.643604023385483\n",
            "Train RMSE: 0.7657690495347264, Valid Losses: 0.7133023763645909\n",
            "Train RMSE: 0.7312171128444471, Valid Losses: 0.7267602209315555\n",
            "Train RMSE: 0.7064870174693024, Valid Losses: 0.7012456664226916\n",
            "Train RMSE: 0.7167133888378199, Valid Losses: 0.699023420286286\n",
            "Train RMSE: 0.7116068201927364, Valid Losses: 0.7240332479078433\n",
            "Train RMSE: 0.7327930827878776, Valid Losses: 0.7078036695424258\n",
            "Train RMSE: 0.7351821300933217, Valid Losses: 0.7515703300708404\n",
            "Train RMSE: 0.720012828488658, Valid Losses: 0.6869647635321895\n",
            "Train RMSE: 0.7140912912536694, Valid Losses: 0.6776651706347656\n",
            "Train RMSE: 0.7182298368312958, Valid Losses: 0.6946849314947133\n",
            "Train RMSE: 0.7044602678866043, Valid Losses: 0.6698302013152616\n",
            "Train RMSE: 0.6840193724186463, Valid Losses: 0.682821921385431\n",
            "Train RMSE: 0.7040483644517861, Valid Losses: 0.6474451827029732\n",
            "Train RMSE: 0.6354364832777243, Valid Losses: 0.6520634934075807\n",
            "Train RMSE: 0.6623483668229804, Valid Losses: 0.672014158374036\n",
            "Train RMSE: 0.6750965733441545, Valid Losses: 0.7065763893443702\n",
            "Train RMSE: 0.6394094721623985, Valid Losses: 0.6281411825941347\n",
            "Train RMSE: 0.6848259492686285, Valid Losses: 0.6872804964553414\n",
            "Train RMSE: 0.655592087542349, Valid Losses: 0.6544554697448185\n",
            "Train RMSE: 0.6497074344441137, Valid Losses: 0.6052910274335499\n",
            "Train RMSE: 0.7071816048895571, Valid Losses: 0.6557700715153265\n",
            "Train RMSE: 0.7231010028396512, Valid Losses: 0.707511847064498\n",
            "Train RMSE: 0.6258704896941998, Valid Losses: 0.635343905362667\n",
            "Train RMSE: 0.6709662113626167, Valid Losses: 0.6793945551276459\n",
            "Train RMSE: 0.6609525946463897, Valid Losses: 0.612395131885709\n",
            "Train RMSE: 0.6557366062309018, Valid Losses: 0.6352392984595416\n",
            "Train RMSE: 0.6461783658701388, Valid Losses: 0.6403223472767519\n",
            "Train RMSE: 0.6925583711041384, Valid Losses: 0.6561033962832086\n",
            "Train RMSE: 0.6729499532564751, Valid Losses: 0.6357307259397149\n",
            "Train RMSE: 0.633326803852568, Valid Losses: 0.6317378105133733\n",
            "Train RMSE: 0.6637928563270676, Valid Losses: 0.6223570752143416\n",
            "Train RMSE: 0.6674084987339401, Valid Losses: 0.6135945742621125\n",
            "Train RMSE: 0.6446465144262553, Valid Losses: 0.6028120420540313\n",
            "Train RMSE: 0.6666941985970114, Valid Losses: 0.6796829690585396\n",
            "Train RMSE: 0.6081935353458785, Valid Losses: 0.6263933801082822\n",
            "Train RMSE: 0.601657160766161, Valid Losses: 0.6038819615219514\n",
            "Train RMSE: 0.6176341568497693, Valid Losses: 0.6470562121429358\n",
            "Train RMSE: 0.6080671869720065, Valid Losses: 0.6383149820482379\n",
            "Train RMSE: 0.5986266171740402, Valid Losses: 0.6289995832165602\n",
            "Train RMSE: 0.6350882027538841, Valid Losses: 0.6428770535833378\n",
            "Train RMSE: 0.6045704024244075, Valid Losses: 0.5859969901743617\n",
            "Train RMSE: 0.6492588163821258, Valid Losses: 0.6432892254572998\n",
            "Train RMSE: 0.6361932129607758, Valid Losses: 0.6391093407940727\n",
            "Train RMSE: 0.581581689921079, Valid Losses: 0.6241289907290228\n",
            "Train RMSE: 0.6202915118683912, Valid Losses: 0.6257967927093449\n",
            "Train RMSE: 0.6257752306129618, Valid Losses: 0.6261371382301476\n",
            "Train RMSE: 0.6232017316098584, Valid Losses: 0.6770097899639864\n",
            "Train RMSE: 0.6215944008015853, Valid Losses: 0.6469613788665369\n",
            "Train RMSE: 0.628261734140925, Valid Losses: 0.6820919804735662\n",
            "Train RMSE: 0.6102975077437122, Valid Losses: 0.6848771170846053\n",
            "Train RMSE: 0.6662129004941575, Valid Losses: 0.6265441789585187\n",
            "Train RMSE: 0.629581457703612, Valid Losses: 0.6631716065856739\n",
            "Train RMSE: 0.6093032733192603, Valid Losses: 0.5762710344911609\n",
            "Train RMSE: 0.6067854875848326, Valid Losses: 0.6420065225493256\n",
            "Train RMSE: 0.5813788559099515, Valid Losses: 0.5780767371322159\n",
            "Train RMSE: 0.587400500339214, Valid Losses: 0.5697038747881662\n",
            "Train RMSE: 0.6071826152198112, Valid Losses: 0.5959580169822664\n",
            "Train RMSE: 0.5879059381980708, Valid Losses: 0.6760611081657484\n",
            "Train RMSE: 0.60021300013431, Valid Losses: 0.6144794031201254\n",
            "Train RMSE: 0.5982268620578053, Valid Losses: 0.6301042765484155\n",
            "Train RMSE: 0.5890073352328336, Valid Losses: 0.5849022198735978\n",
            "Train RMSE: 0.5627794603995678, Valid Losses: 0.617852790908963\n",
            "Train RMSE: 0.5994622829881008, Valid Losses: 0.595789525116402\n",
            "Train RMSE: 0.567497283795353, Valid Losses: 0.583780493365599\n",
            "Train RMSE: 0.6021496044889885, Valid Losses: 0.6316906147341362\n",
            "Train RMSE: 0.5873373462798588, Valid Losses: 0.552899765452562\n",
            "Train RMSE: 0.5825509075163787, Valid Losses: 0.6390435209468983\n",
            "Train RMSE: 0.5995053126050733, Valid Losses: 0.6480391026065175\n",
            "Train RMSE: 0.5828103896113938, Valid Losses: 0.5777060708899793\n",
            "Train RMSE: 0.5882154097871231, Valid Losses: 0.6098794508957677\n",
            "Train RMSE: 0.5477102565741788, Valid Losses: 0.6351730862218017\n",
            "Train RMSE: 0.5472529655674838, Valid Losses: 0.6086099528913893\n",
            "Train RMSE: 0.5713256833360418, Valid Losses: 0.6221659866008631\n",
            "Train RMSE: 0.576641524872057, Valid Losses: 0.5709518013576544\n",
            "Train RMSE: 0.6076523826721199, Valid Losses: 0.6124845279031556\n",
            "Train RMSE: 0.6084009789610815, Valid Losses: 0.5731923089254604\n",
            "Train RMSE: 0.5195270990166956, Valid Losses: 0.6445662133411277\n",
            "Train RMSE: 0.5459567861970269, Valid Losses: 0.5883841008620138\n",
            "Train RMSE: 0.5524338739541179, Valid Losses: 0.5659407540920075\n",
            "Train RMSE: 0.5625360161269606, Valid Losses: 0.6202491942902582\n",
            "Train RMSE: 0.5410839160032793, Valid Losses: 0.5889019764139524\n",
            "Train RMSE: 0.5626399863097248, Valid Losses: 0.625794771715445\n",
            "Train RMSE: 0.5670242044991763, Valid Losses: 0.6127573054652521\n",
            "Train RMSE: 0.5611497013825791, Valid Losses: 0.626289358871684\n",
            "Train RMSE: 0.5575198837016502, Valid Losses: 0.5795726601382261\n",
            "Train RMSE: 0.5219155967866708, Valid Losses: 0.6068434778401348\n",
            "Train RMSE: 0.5611489042474254, Valid Losses: 0.5775557900652027\n",
            "Train RMSE: 0.5487472167361603, Valid Losses: 0.5930068751491746\n",
            "Train RMSE: 0.5324785485047437, Valid Losses: 0.5894368988619602\n",
            "Train RMSE: 0.503203236730827, Valid Losses: 0.5858400305809228\n",
            "Train RMSE: 0.553037722649361, Valid Losses: 0.5713532110995585\n",
            "Train RMSE: 0.5254874832487932, Valid Losses: 0.5776233447062409\n",
            "Train RMSE: 0.5421016402726244, Valid Losses: 0.5613626873736742\n",
            "Train RMSE: 0.5317881544351717, Valid Losses: 0.5855306348910905\n",
            "Train RMSE: 0.5191275332716742, Valid Losses: 0.510934841307854\n",
            "Train RMSE: 0.49872835575229724, Valid Losses: 0.5549368912741144\n",
            "Train RMSE: 0.5221044144162065, Valid Losses: 0.5768826024952616\n",
            "Train RMSE: 0.5046633151276193, Valid Losses: 0.5916171735057038\n",
            "Train RMSE: 0.5188287889327428, Valid Losses: 0.5220603824795178\n",
            "Train RMSE: 0.5387349210138757, Valid Losses: 0.5747906426702639\n",
            "Train RMSE: 0.5469851243282077, Valid Losses: 0.6135596385393934\n",
            "Train RMSE: 0.5089784649397598, Valid Losses: 0.6011535155749484\n",
            "Train RMSE: 0.49025988068628173, Valid Losses: 0.5666374678095193\n",
            "Train RMSE: 0.5108925059241843, Valid Losses: 0.5651589254300108\n",
            "Train RMSE: 0.5200830120003789, Valid Losses: 0.5561470406963296\n",
            "Train RMSE: 0.49861733987229345, Valid Losses: 0.5865543192281535\n",
            "Train RMSE: 0.5284729432957697, Valid Losses: 0.5524157880894656\n",
            "Train RMSE: 0.5011487214369553, Valid Losses: 0.5633817091712836\n",
            "Train RMSE: 0.49873890803359905, Valid Losses: 0.5487609260798815\n",
            "Train RMSE: 0.4921966960619467, Valid Losses: 0.5974712048403941\n",
            "Train RMSE: 0.5013536838463414, Valid Losses: 0.5916080126604275\n",
            "Train RMSE: 0.48944498384432344, Valid Losses: 0.5397936689805005\n",
            "Train RMSE: 0.5020131469199061, Valid Losses: 0.567263318319967\n",
            "Train RMSE: 0.5029183582683501, Valid Losses: 0.5512876901338131\n",
            "Train RMSE: 0.4919549226194928, Valid Losses: 0.570826199446244\n",
            "Train RMSE: 0.50125470521624, Valid Losses: 0.5457617500374059\n",
            "Train RMSE: 0.48125655347697777, Valid Losses: 0.5391396240430913\n",
            "Train RMSE: 0.49168568188604334, Valid Losses: 0.5524240487949688\n",
            "Train RMSE: 0.4763042626091057, Valid Losses: 0.5324952367455709\n",
            "Train RMSE: 0.4926217136860639, Valid Losses: 0.5332906127645991\n",
            "Train RMSE: 0.44714048602424533, Valid Losses: 0.5268480860253993\n",
            "Train RMSE: 0.48646610989562433, Valid Losses: 0.5634317015362047\n",
            "Train RMSE: 0.49243983243889206, Valid Losses: 0.5533405540464607\n",
            "Train RMSE: 0.465313449226078, Valid Losses: 0.5261638685111653\n",
            "Train RMSE: 0.5192075564099262, Valid Losses: 0.509096457937714\n",
            "Train RMSE: 0.45179504988514185, Valid Losses: 0.558155396914076\n",
            "Train RMSE: 0.4993288727214687, Valid Losses: 0.5557847061495964\n",
            "Train RMSE: 0.47741129464731163, Valid Losses: 0.5249759298053185\n",
            "Train RMSE: 0.47375674578984106, Valid Losses: 0.5752069416283515\n",
            "Train RMSE: 0.45320455611953203, Valid Losses: 0.5200447347942105\n",
            "Train RMSE: 0.460185679896974, Valid Losses: 0.5519625728746428\n",
            "Train RMSE: 0.48302924329064645, Valid Losses: 0.5305476825500338\n",
            "Train RMSE: 0.48885980510687604, Valid Losses: 0.5984613121007701\n",
            "Train RMSE: 0.5010345639938891, Valid Losses: 0.5604036172398741\n",
            "Train RMSE: 0.48553919017418257, Valid Losses: 0.5841702522460924\n",
            "Train RMSE: 0.47042149052538146, Valid Losses: 0.5676112202693497\n",
            "Train RMSE: 0.47338834354227644, Valid Losses: 0.5626560189471248\n",
            "Train RMSE: 0.5000016589616046, Valid Losses: 0.5698634657642019\n",
            "Train RMSE: 0.47173992876830834, Valid Losses: 0.5768512130953407\n",
            "Train RMSE: 0.4471264232036542, Valid Losses: 0.5379829337463515\n",
            "Train RMSE: 0.4805585057660743, Valid Losses: 0.5566566118359682\n",
            "Train RMSE: 0.47454296538582597, Valid Losses: 0.5350805404546295\n",
            "Train RMSE: 0.4671734615155955, Valid Losses: 0.5430304137133155\n",
            "Train RMSE: 0.4562358199887519, Valid Losses: 0.5861585009608739\n",
            "Train RMSE: 0.47096512260528167, Valid Losses: 0.5789500203342361\n",
            "Train RMSE: 0.47106367553222067, Valid Losses: 0.5724401913346449\n",
            "Train RMSE: 0.4738256633658847, Valid Losses: 0.5691613657705806\n",
            "Train RMSE: 0.4756080951946569, Valid Losses: 0.5503116013546747\n",
            "Train RMSE: 0.4799263709417616, Valid Losses: 0.5499529318903594\n",
            "Train RMSE: 0.4364478637367053, Valid Losses: 0.5239635590259204\n",
            "Train RMSE: 0.4723404912438199, Valid Losses: 0.569112928505219\n",
            "Train RMSE: 0.4692153361180469, Valid Losses: 0.5641507301009987\n",
            "Train RMSE: 0.46458726327053557, Valid Losses: 0.5587721415846197\n",
            "Train RMSE: 0.464310328425341, Valid Losses: 0.584530721170629\n",
            "Train RMSE: 0.4461965705324397, Valid Losses: 0.5374436915274792\n",
            "Train RMSE: 0.46002306272161636, Valid Losses: 0.5481043728150438\n",
            "Train RMSE: 0.4784762924509729, Valid Losses: 0.577516217423062\n",
            "Train RMSE: 0.4626815805039839, Valid Losses: 0.5074526808303775\n",
            "Train RMSE: 0.4748571293493117, Valid Losses: 0.5403644999264655\n",
            "Train RMSE: 0.4506872557484524, Valid Losses: 0.5507450129682586\n",
            "Train RMSE: 0.47025577356121817, Valid Losses: 0.5611742405266773\n",
            "Train RMSE: 0.4658872848985035, Valid Losses: 0.5527096525442633\n",
            "Train RMSE: 0.4553072070431305, Valid Losses: 0.5492214487902729\n",
            "Train RMSE: 0.45844529379568316, Valid Losses: 0.5587936066296733\n",
            "Train RMSE: 0.49311666498164974, Valid Losses: 0.5466345269021192\n",
            "Train RMSE: 0.47249074601259666, Valid Losses: 0.5613098384711513\n",
            "Train RMSE: 0.4640377480142321, Valid Losses: 0.5617554768751413\n",
            "Train RMSE: 0.4732979484628288, Valid Losses: 0.5959397837806193\n",
            "Train RMSE: 0.4727422095127762, Valid Losses: 0.5749515308700486\n",
            "Train RMSE: 0.45642164122264794, Valid Losses: 0.5473315780931387\n",
            "Train RMSE: 0.44856970644337335, Valid Losses: 0.5449539724043674\n",
            "Train RMSE: 0.45645300400425637, Valid Losses: 0.5514325480630229\n",
            "Train RMSE: 0.49958182084782427, Valid Losses: 0.5569267074467518\n",
            "Train RMSE: 0.46767473279477245, Valid Losses: 0.5555127812385121\n",
            "Train RMSE: 0.4474099502828864, Valid Losses: 0.5212312027504136\n",
            "Train RMSE: 0.4437229703600563, Valid Losses: 0.5397488712150036\n",
            "Train RMSE: 0.4487713096687092, Valid Losses: 0.5468599802379318\n",
            "Train RMSE: 0.46555709688650504, Valid Losses: 0.5357615316877853\n",
            "Train RMSE: 0.4511462258254244, Valid Losses: 0.5673379813358103\n",
            "Train RMSE: 0.45346518448004913, Valid Losses: 0.5562484370167055\n",
            "Train RMSE: 0.4709661017356658, Valid Losses: 0.5533707278454515\n",
            "Train RMSE: 0.4799143403725255, Valid Losses: 0.5658294076331302\n",
            "Train RMSE: 0.46752210970093755, Valid Losses: 0.5633289261390718\n",
            "Train RMSE: 0.46004785824630806, Valid Losses: 0.5560849650184214\n",
            "Train RMSE: 0.458801496280429, Valid Losses: 0.5631605696676127\n",
            "Train RMSE: 0.4540871286055847, Valid Losses: 0.5824630994507217\n",
            "Train RMSE: 0.4877392238866424, Valid Losses: 0.5464229841017936\n",
            "Train RMSE: 0.4606833074343994, Valid Losses: 0.6027025344670427\n",
            "Train RMSE: 0.4568550584467278, Valid Losses: 0.5310714040667615\n",
            "Train RMSE: 0.4452074648328717, Valid Losses: 0.5345027703444933\n",
            "Train RMSE: 0.45327496429869646, Valid Losses: 0.5567469499814484\n",
            "Train RMSE: 0.4435171016001894, Valid Losses: 0.5741571559320492\n",
            "Train RMSE: 0.449205047585156, Valid Losses: 0.499310787840771\n",
            "Train RMSE: 0.4566983872147054, Valid Losses: 0.5454295587451139\n",
            "Train RMSE: 0.423072315100456, Valid Losses: 0.5870446712656964\n",
            "Train RMSE: 0.45904215256460174, Valid Losses: 0.588365507643301\n",
            "Train RMSE: 0.43881000842381374, Valid Losses: 0.5883598132006319\n",
            "Train RMSE: 0.43335398681643705, Valid Losses: 0.5457456194831249\n",
            "Train RMSE: 0.45994950761088577, Valid Losses: 0.5547577609920913\n",
            "Train RMSE: 0.45314762885562304, Valid Losses: 0.5720416064578525\n",
            "Train RMSE: 0.44135348429123417, Valid Losses: 0.5498871396592179\n",
            "Train RMSE: 0.44855180335943595, Valid Losses: 0.59086368883393\n",
            "Train RMSE: 0.46196546326426985, Valid Losses: 0.5543978433376029\n",
            "Train RMSE: 0.46880781227999824, Valid Losses: 0.5746799435497818\n",
            "Train RMSE: 0.4645600222170997, Valid Losses: 0.5250134692949482\n",
            "Train RMSE: 0.4316891449748186, Valid Losses: 0.5664870519552854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GATV5(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels = 64, num_node_features = 45, num_edge_features = 10, num_classes = 1, regression = True, n_heads = 4):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = MultiHeadGATv2ConvEV2(num_node_features, hidden_channels, num_edge_features, hidden_channels, n_heads = n_heads)\n",
        "        self.conv2 = MultiHeadGATv2ConvEV2(hidden_channels, hidden_channels, hidden_channels, hidden_channels, n_heads = n_heads)\n",
        "        self.conv3 = MultiHeadGATv2ConvEV2(hidden_channels, hidden_channels, hidden_channels, hidden_channels, n_heads = n_heads)\n",
        "        self.conv4 = MultiHeadGATv2ConvEV2(hidden_channels, hidden_channels, hidden_channels, hidden_channels, n_heads = n_heads)\n",
        "\n",
        "        self.regression = regression\n",
        "\n",
        "        self.f_att = FeatureAttention(channels=hidden_channels, reduction = 4)\n",
        "\n",
        "        self.res = ResLayer(hidden_channels, hidden_channels)\n",
        "        # self.pool = SAGPooling(hidden_channels)\n",
        "\n",
        "        if regression:\n",
        "          self.lin = nn.Sequential(nn.Linear(hidden_channels, 1))\n",
        "        else:\n",
        "          self.lin = ResLayer(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # 1. Obtain node embeddings\n",
        "\n",
        "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
        "        x, edge_attr = self.conv1(x, edge_index, edge_attr = edge_attr)\n",
        "        x = self.f_att(x, batch)\n",
        "\n",
        "        # mol_vec = global_mean_pool(x, batch)\n",
        "\n",
        "        x, edge_attr = F.dropout(x, p = 0.4), F.dropout(edge_attr, p = 0.4)\n",
        "        x, edge_attr = self.conv2(x, edge_index, edge_attr = edge_attr)\n",
        "        x = self.f_att(x, batch)\n",
        "\n",
        "        # mol_vec += global_mean_pool(x, batch)\n",
        "\n",
        "        x, edge_attr = F.dropout(x, p = 0.4), F.dropout(edge_attr, p = 0.4)\n",
        "        x, edge_attr = self.conv3(x, edge_index, edge_attr = edge_attr)\n",
        "        x = self.f_att(x, batch)\n",
        "\n",
        "        # mol_vec += global_mean_pool(x, batch)\n",
        "\n",
        "        x, edge_attr = F.dropout(x, p = 0.4), F.dropout(edge_attr, p = 0.4)\n",
        "        x, edge_attr = self.conv4(x, edge_index, edge_attr = edge_attr)\n",
        "        x = self.f_att(x, batch)\n",
        "        x, edge_attr = F.dropout(x, p = 0.2), F.dropout(edge_attr, p = 0.2)\n",
        "\n",
        "        # results = self.pool(x, edge_index = edge_index, edge_attr = edge_attr, batch = batch)\n",
        "\n",
        "        # x, new_batch = results[0], results[-3]\n",
        "        mol_vec = global_mean_pool(x, batch)\n",
        "\n",
        "        # out = self.res(mol_vec)\n",
        "        out = mol_vec\n",
        "        out = F.dropout(out, p=0.2, training=self.training)\n",
        "        if self.regression:\n",
        "          out = self.lin(out)\n",
        "        else:\n",
        "          out = F.sigmoid(self.lin(out))\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "ovUc8JIZazGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GATV5(hidden_channels = 128)"
      ],
      "metadata": {
        "id": "YaMFtpISbAUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        init.kaiming_normal_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.zeros_(m.bias)\n",
        "\n",
        "model.apply(weights_init)"
      ],
      "metadata": {
        "id": "MmUwWvBQbWGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GATV5(hidden_channels = 128)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-03, weight_decay = 1e-02)\n",
        "model.apply(weights_init)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer,\n",
        "            mode = 'min',\n",
        "            factor = 0.7,\n",
        "            patience = 10,\n",
        "            min_lr = 5e-05\n",
        ")\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(1, 300):\n",
        "    train()"
      ],
      "metadata": {
        "id": "GGoDu8edcBf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = valid_loader"
      ],
      "metadata": {
        "id": "SWubf6QbJaGG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GATV3()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-03, weight_decay = 1e-03)\n",
        "# model.apply(weights_init)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer,\n",
        "            mode = 'min',\n",
        "            factor = 0.7,\n",
        "            patience = 10,\n",
        "            min_lr = 1e-05\n",
        ")\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(1, 300):\n",
        "    train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pNVnoD7aCUUr",
        "outputId": "a6ceddac-367f-462b-cb05-d1edfd289459"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/ec2-user/virtenv/lib64/python3.7/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/home/ec2-user/virtenv/lib64/python3.7/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([31, 1])) that is different to the input size (torch.Size([31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/home/ec2-user/virtenv/lib64/python3.7/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([19, 1])) that is different to the input size (torch.Size([19])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 3.4082550968473995, Valid Losses: 1.4039438803529691\n",
            "Train RMSE: 1.4407199254658385, Valid Losses: 1.3637817878747542\n",
            "Train RMSE: 1.4303922172581611, Valid Losses: 1.3709688207336024\n",
            "Train RMSE: 1.4360271975184162, Valid Losses: 1.371837274199889\n",
            "Train RMSE: 1.4278416665341551, Valid Losses: 1.3583469686193628\n",
            "Train RMSE: 1.4194070150124383, Valid Losses: 1.4164847808684924\n",
            "Train RMSE: 1.4193032327096113, Valid Losses: 1.3550428375652128\n",
            "Train RMSE: 1.4150181414192453, Valid Losses: 1.3774237457184688\n",
            "Train RMSE: 1.420961975821467, Valid Losses: 1.356550591948799\n",
            "Train RMSE: 1.4176093340874274, Valid Losses: 1.3700332531911326\n",
            "Train RMSE: 1.41282726018431, Valid Losses: 1.3718150734512793\n",
            "Train RMSE: 1.4100098030587096, Valid Losses: 1.3587291035685964\n",
            "Train RMSE: 1.4108551113665662, Valid Losses: 1.3579477337963446\n",
            "Train RMSE: 1.4074980846206993, Valid Losses: 1.3540439398730806\n",
            "Train RMSE: 1.4074180087923909, Valid Losses: 1.3612908388631972\n",
            "Train RMSE: 1.4078264789707053, Valid Losses: 1.3541732519278706\n",
            "Train RMSE: 1.4092666004413519, Valid Losses: 1.362003877041218\n",
            "Train RMSE: 1.4098042668575368, Valid Losses: 1.356282441035581\n",
            "Train RMSE: 1.4029912467474517, Valid Losses: 1.370640855639569\n",
            "Train RMSE: 1.4107061605888696, Valid Losses: 1.3651413438695694\n",
            "Train RMSE: 1.4078825453154684, Valid Losses: 1.3644404684617886\n",
            "Train RMSE: 1.4040980834449623, Valid Losses: 1.3559290873894725\n",
            "Train RMSE: 1.4097228695941917, Valid Losses: 1.3573193843476956\n",
            "Train RMSE: 1.404228650584658, Valid Losses: 1.3614586902341317\n",
            "Train RMSE: 1.4027249407330218, Valid Losses: 1.3670296953299284\n",
            "Train RMSE: 1.4012459685083034, Valid Losses: 1.3556750279506848\n",
            "Train RMSE: 1.3967989078773628, Valid Losses: 1.366411214845435\n",
            "Train RMSE: 1.4039327938249802, Valid Losses: 1.353899197541496\n",
            "Train RMSE: 1.402139313919522, Valid Losses: 1.3536076725715513\n",
            "Train RMSE: 1.39624103663869, Valid Losses: 1.353661929422034\n",
            "Train RMSE: 1.3989470744008599, Valid Losses: 1.3564464371424396\n",
            "Train RMSE: 1.3970282020035965, Valid Losses: 1.3534886758398776\n",
            "Train RMSE: 1.3967395110608605, Valid Losses: 1.3530936768244954\n",
            "Train RMSE: 1.3990280980740963, Valid Losses: 1.3530729392224037\n",
            "Train RMSE: 1.3997751775778697, Valid Losses: 1.3541014541550345\n",
            "Train RMSE: 1.3988777958973757, Valid Losses: 1.3538373816851568\n",
            "Train RMSE: 1.3971371794649792, Valid Losses: 1.3535419856903397\n",
            "Train RMSE: 1.3974843438701563, Valid Losses: 1.3565962096637059\n",
            "Train RMSE: 1.395151983638876, Valid Losses: 1.3549276879247614\n",
            "Train RMSE: 1.400382026099342, Valid Losses: 1.3526455129088355\n",
            "Train RMSE: 1.3977869504162301, Valid Losses: 1.3542095560569265\n",
            "Train RMSE: 1.3979795538137443, Valid Losses: 1.353860633053246\n",
            "Train RMSE: 1.3897660777397076, Valid Losses: 1.3544010985096016\n",
            "Train RMSE: 1.3893112213593077, Valid Losses: 1.355288966722118\n",
            "Train RMSE: 1.3911364155902965, Valid Losses: 1.3549420956482525\n",
            "Train RMSE: 1.3931054074787228, Valid Losses: 1.353488911819058\n",
            "Train RMSE: 1.392106592799855, Valid Losses: 1.3579616865870905\n",
            "Train RMSE: 1.3947479956994326, Valid Losses: 1.3536034893245592\n",
            "Train RMSE: 1.3980107014745045, Valid Losses: 1.3599463679095762\n",
            "Train RMSE: 1.3920430833400532, Valid Losses: 1.3527480050211829\n",
            "Train RMSE: 1.384307306601855, Valid Losses: 1.3658869324720577\n",
            "Train RMSE: 1.3875296029883002, Valid Losses: 1.3539793537595506\n",
            "Train RMSE: 1.3930635519227468, Valid Losses: 1.3534325057119483\n",
            "Train RMSE: 1.3942521502389105, Valid Losses: 1.3520887481812167\n",
            "Train RMSE: 1.3853830171889097, Valid Losses: 1.3565662641745442\n",
            "Train RMSE: 1.3895712711386141, Valid Losses: 1.3527221251148083\n",
            "Train RMSE: 1.3859351910296962, Valid Losses: 1.3605291356669473\n",
            "Train RMSE: 1.3906530956181027, Valid Losses: 1.3537669140063446\n",
            "Train RMSE: 1.3886803151974243, Valid Losses: 1.3528414344517072\n",
            "Train RMSE: 1.3861214831712176, Valid Losses: 1.35290278170491\n",
            "Train RMSE: 1.385755048822778, Valid Losses: 1.3532398297399346\n",
            "Train RMSE: 1.3885688537199696, Valid Losses: 1.3532047927594872\n",
            "Train RMSE: 1.3854223367676632, Valid Losses: 1.3537098713027893\n",
            "Train RMSE: 1.3890533784620396, Valid Losses: 1.3532001313482205\n",
            "Train RMSE: 1.3858112452454414, Valid Losses: 1.3542260993425723\n",
            "Train RMSE: 1.3805328268931525, Valid Losses: 1.3524189715437351\n",
            "Train RMSE: 1.3860106843968698, Valid Losses: 1.3538739251656224\n",
            "Train RMSE: 1.385334413276676, Valid Losses: 1.3559457050010388\n",
            "Train RMSE: 1.3823431951554648, Valid Losses: 1.3560151957230857\n",
            "Train RMSE: 1.38328675080022, Valid Losses: 1.352048239911815\n",
            "Train RMSE: 1.3854970929964296, Valid Losses: 1.3533728573342028\n",
            "Train RMSE: 1.386040111230265, Valid Losses: 1.3541631232929892\n",
            "Train RMSE: 1.385726721712917, Valid Losses: 1.3564751702633142\n",
            "Train RMSE: 1.386278089204303, Valid Losses: 1.3531046563980738\n",
            "Train RMSE: 1.3849034300391145, Valid Losses: 1.3594436839270791\n",
            "Train RMSE: 1.3839374773282584, Valid Losses: 1.3536613130796857\n",
            "Train RMSE: 1.3822730643781018, Valid Losses: 1.3522808822938688\n",
            "Train RMSE: 1.3847034233087476, Valid Losses: 1.3524882136910328\n",
            "Train RMSE: 1.3838700215541742, Valid Losses: 1.3556637272106113\n",
            "Train RMSE: 1.3826026182487507, Valid Losses: 1.3523973106299048\n",
            "Train RMSE: 1.3817828472521927, Valid Losses: 1.3527391077371318\n",
            "Train RMSE: 1.3800569515557963, Valid Losses: 1.3593687478955598\n",
            "Train RMSE: 1.3812438896264774, Valid Losses: 1.353356901726359\n",
            "Train RMSE: 1.3818782504365548, Valid Losses: 1.3531716402260967\n",
            "Train RMSE: 1.3827737002381226, Valid Losses: 1.3612816480000018\n",
            "Train RMSE: 1.3787910890226505, Valid Losses: 1.3539733888306873\n",
            "Train RMSE: 1.3821432026859715, Valid Losses: 1.3573995497698244\n",
            "Train RMSE: 1.3801389071613583, Valid Losses: 1.353422784204201\n",
            "Train RMSE: 1.381082461718854, Valid Losses: 1.3518018856943785\n",
            "Train RMSE: 1.379559410440128, Valid Losses: 1.351963838527916\n",
            "Train RMSE: 1.3776416313754951, Valid Losses: 1.3529149615890808\n",
            "Train RMSE: 1.3774156017994583, Valid Losses: 1.3524255440466588\n",
            "Train RMSE: 1.377378918834652, Valid Losses: 1.3524518718081249\n",
            "Train RMSE: 1.378203608792115, Valid Losses: 1.3544163074348867\n",
            "Train RMSE: 1.3783798700527556, Valid Losses: 1.3519445271904564\n",
            "Train RMSE: 1.381145024214986, Valid Losses: 1.3519125678728816\n",
            "Train RMSE: 1.3767957242948274, Valid Losses: 1.3516409891503711\n",
            "Train RMSE: 1.3786297363979014, Valid Losses: 1.3517588726008745\n",
            "Train RMSE: 1.381528833408145, Valid Losses: 1.3517136687375417\n",
            "Train RMSE: 1.3788368707171386, Valid Losses: 1.3514641074757332\n",
            "Train RMSE: 1.3813420441091215, Valid Losses: 1.3519456250929156\n",
            "Train RMSE: 1.3754246636315182, Valid Losses: 1.3528332311495956\n",
            "Train RMSE: 1.379912038632667, Valid Losses: 1.351802185264443\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_7287/1041590507.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_7287/1952531460.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Compute the loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Derive gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update parameters based on gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Clear gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/virtenv/lib64/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/virtenv/lib64/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/virtenv/lib64/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    250\u001b[0m                  \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fused'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                  \u001b[0mgrad_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                  found_inf=found_inf)\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/virtenv/lib64/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    314\u001b[0m          \u001b[0mdifferentiable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdifferentiable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m          \u001b[0mgrad_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m          found_inf=found_inf)\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/virtenv/lib64/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction of compounds."
      ],
      "metadata": {
        "id": "Vt3GuvWjtASL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Predict.\n",
        "def predict(model, dl, device = device):\n",
        "\n",
        "  '''\n",
        "  This model takes in model and dataloader and gives out predicted values for all the samples in the dataloader.\n",
        "\n",
        "  Args:\n",
        "    model {nn.module}: Model Object (HiGNN)\n",
        "    dl {DataLoader}: DataLoader object.\n",
        "    device {torch.device}: cuda if GPU available else cpu\n",
        "  '''\n",
        "  out = torch.Tensor([])\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for x in tqdm(dl):\n",
        "      x = x.to(device)\n",
        "      outputs = model(x)\n",
        "      yhat = outputs.squeeze()\n",
        "      yhat = yhat.to(torch.device('cpu'))\n",
        "      out = torch.cat([out, yhat], dim = -1)\n",
        "  return out.numpy()"
      ],
      "metadata": {
        "id": "78N0HOpUtLl5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to prepare a dataloader object\n",
        "\n",
        "def prepare_loader(fpath, root = './root/', dataset = 'experiment_1', task_type = 'regression', tasks = [], smiles_col = 'smiles', bs = 32): # Use bs = 32 only if GPU is available, else use bs = 4\n",
        "    pyg_dataset = MolDataset(root=root, fpath = fpath, dataset=dataset, task_type=task_type, tasks=tasks, smiles_col = smiles_col)\n",
        "    # del pyg_dataset.data.smiles\n",
        "\n",
        "    return DataLoader(pyg_dataset, batch_size = bs)\n"
      ],
      "metadata": {
        "id": "4bq0BFo2tYkN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "df = pd.read_csv(\"./chem_datasets/clintox_cleaned.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8D5DVYb0wJNB",
        "outputId": "62d51eec-7664-4656-8378-5344cac89872"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                                ids  CT_TOX\n",
              "0           0  c1nc(nc(=O)n1[C@H]2[C@@H]([C@@H]([C@H](O2)CO)O...     0.0\n",
              "1           1  C[C@@H]1C[C@H]2[C@@H]3C[C@@H](C4=CC(=O)C=C[C@@...     0.0\n",
              "2           2                 C[NH+](C)CCC(c1ccc(cc1)Br)c2ccccn2     0.0\n",
              "3           3                                             CC(C)O     0.0\n",
              "4           4          CN1C(=C(c2ccccc2S1(=O)=O)O)C(=O)Nc3ccccn3     0.0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ids</th>\n",
              "      <th>CT_TOX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>c1nc(nc(=O)n1[C@H]2[C@@H]([C@@H]([C@H](O2)CO)O...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>C[C@@H]1C[C@H]2[C@@H]3C[C@@H](C4=CC(=O)C=C[C@@...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>C[NH+](C)CCC(c1ccc(cc1)Br)c2ccccn2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>CC(C)O</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>CN1C(=C(c2ccccc2S1(=O)=O)O)C(=O)Nc3ccccn3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Batch size\n",
        "\n",
        "bs = 4\n",
        "device = torch.device('cpu')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    bs = 32\n",
        "    device = torch.device('cuda')\n"
      ],
      "metadata": {
        "id": "GbEw9fJ_vzRp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clintox_loader = prepare_loader(fpath = \"./chem_datasets/clintox_cleaned.csv\",\n",
        "               dataset= 'clintox_experiment_1',\n",
        "               smiles_col = 'ids',\n",
        "               bs = bs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6AOL8G-wf7x",
        "outputId": "69d1d404-6525-4e68-e21f-d6e83753f85b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/ec2-user/virtenv/lib64/python3.7/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(clintox_loader))"
      ],
      "metadata": {
        "id": "BJPvxllBw-X0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smiles = batch.smiles"
      ],
      "metadata": {
        "id": "3tRkTxuZEIVH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smiles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_-kI-YpEN1K",
        "outputId": "1a83123f-5f19-4d8b-a4eb-217bef37a7e1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Nc1ncn([C@@H]2O[C@H](CO)[C@@H](O)[C@H]2O)c(=O)n1',\n",
              " 'C[C@@H]1C[C@H]2[C@@H]3C[C@H](F)C4=CC(=O)C=C[C@]4(C)[C@@]3(F)[C@@H](O)C[C@]2(C)[C@@]1(O)C(=O)COC(=O)C(C)(C)C',\n",
              " 'C[NH+](C)CCC(c1ccc(Br)cc1)c1ccccn1',\n",
              " 'CC(C)O',\n",
              " 'CN1C(C(=O)Nc2ccccn2)=C(O)c2ccccc2S1(=O)=O',\n",
              " 'CC(=O)Oc1ccccc1C(=O)Nc1ncc([N+](=O)[O-])s1',\n",
              " 'COCc1c(C(C)C)nc(C(C)C)c(/C=C/[C@@H](O)C[C@@H](O)CC(=O)[O-])c1-c1ccc(F)cc1',\n",
              " 'CC(CN1c2ccccc2Sc2ccccc21)C[NH+](C)C',\n",
              " 'CC(C)C(=O)Nc1ccc([N+](=O)[O-])c(C(F)(F)F)c1',\n",
              " 'CC(C)(C)[NH2+]CC(O)c1cc(O)cc(O)c1',\n",
              " 'NS(=O)(=O)c1cc2c(cc1Cl)NC(C1CC3C=CC1C3)NS2(=O)=O',\n",
              " 'CC(=O)N(CC(C)C(=O)[O-])c1c(I)cc(I)c(N)c1I',\n",
              " 'CC(C)NCC(O)COc1cccc2ccccc12',\n",
              " 'CO/N=C(\\\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N+]3(C)CCCC3)CS[C@H]12)c1csc(N)n1',\n",
              " 'CC(C)[NH+](CCC(C(N)=O)(c1ccccc1)c1ccccn1)C(C)C',\n",
              " 'CCCNC(=O)[N-]S(=O)(=O)c1ccc(Cl)cc1',\n",
              " 'C/C(=N\\\\O)[C@@H](C)[NH2+]CC(C)(C)C[NH2+][C@H](C)/C(C)=N/O',\n",
              " 'CC(=O)OC(C)C[N+](C)(C)C',\n",
              " 'Nc1ccn(C[C@@H](CO)OCP(=O)([O-])[O-])c(=O)n1',\n",
              " 'Cc1nnc(SCC2=C(C(=O)[O-])N3C(=O)[C@@H](NC(=O)Cn4cnnn4)[C@H]3SC2)s1',\n",
              " 'CN(CCCCCCCCCCN(C)C(=O)Oc1cccc([N+](C)(C)C)c1)C(=O)Oc1cccc([N+](C)(C)C)c1',\n",
              " 'Fc1ccc([C@@H]2CC[NH2+]C[C@H]2COc2ccc3c(c2)OCO3)cc1',\n",
              " 'CCC[C@@H]1C[C@@H](C(=O)N[C@@H]([C@H]2O[C@H](SC)[C@H](O)[C@@H](O)[C@H]2O)[C@@H](C)O)[NH+](C)C1',\n",
              " 'CCOC(=O)[C@H](CCc1ccccc1)[NH2+][C@@H](C)C(=O)N1[C@H](C(=O)[O-])C[C@H]2CCCC[C@@H]21',\n",
              " '[NH3+]CC1(CC(=O)[O-])CCCCC1',\n",
              " 'CCCCCCC[NH+](CC)CCCC(O)c1ccc(NS(C)(=O)=O)cc1',\n",
              " 'COc1ccnc(CS(=O)c2nc3ccc(OC(F)F)cc3[nH]2)c1OC',\n",
              " 'Nc1nc(Cl)nc2c1ncn2[C@@H]1O[C@H](CO)[C@@H](O)[C@@H]1F',\n",
              " 'CC(=O)O[C@H]1C[C@H](OC2[C@@H](O)C[C@H](O[C@H]3[C@@H](O)C[C@H](OC4CC[C@@]5(C)[C@H](CC[C@@H]6[C@@H]5CC[C@]5(C)[C@@H](C7=CC(=O)OC7)CC[C@]65O)C4)O[C@@H]3C)O[C@@H]2C)O[C@H](C)[C@H]1O',\n",
              " 'C[C@@H]1C[C@H]2[C@@H]3C[C@H](F)C4=CC(=O)C=C[C@]4(C)[C@@]3(Cl)[C@@H](O)C[C@]2(C)[C@H]1C(=O)COC(=O)C(C)(C)C',\n",
              " 'C[N+]12CCC(CC1)C(OC(=O)C(O)(c1ccccc1)c1ccccc1)C2',\n",
              " 'CC(C)CN(C[C@@H](O)[C@H](Cc1ccccc1)NC(=O)O[C@H]1CO[C@H]2OCC[C@H]21)S(=O)(=O)c1ccc(N)cc1']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a model\n",
        "test_model = build_model(num_outputs = 1)\n",
        "\n",
        "# Get it onto the device\n",
        "test_model = test_model.to(device)"
      ],
      "metadata": {
        "id": "mdXq7TCyxBGO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained model\n",
        "test_model.load_model(load_path = \"./models/spr_hi_gnn_finetuned_complete_v1.pth\")"
      ],
      "metadata": {
        "id": "D9CC4YfSxOFE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predictions\n",
        "predictions = predict(test_model, clintox_loader, device = device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJw5A85axZBF",
        "outputId": "a00e2748-a3e1-465c-bca7-966cd0d8bc13"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 47/47 [00:00<00:00, 58.10it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpcQchKCxxHU",
        "outputId": "b5e559ca-0f48-48aa-e202-d1c1e01d37ce"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.15445851,\n",
              " 0.017813165,\n",
              " 0.16268986,\n",
              " 0.013013933,\n",
              " 0.21852762,\n",
              " 0.2426529,\n",
              " 0.110599205,\n",
              " 0.17818458,\n",
              " 0.15332972,\n",
              " 0.11543213,\n",
              " 0.19913237,\n",
              " 0.11057602,\n",
              " 0.13827683,\n",
              " 0.17350352,\n",
              " 0.16590823,\n",
              " 0.15800305,\n",
              " 0.061678093,\n",
              " 0.07911573,\n",
              " 0.12856063,\n",
              " 0.18931325,\n",
              " 0.19768417,\n",
              " 0.1950032,\n",
              " 0.00032541528,\n",
              " 0.13226676,\n",
              " 0.09922576,\n",
              " 0.12376462,\n",
              " 0.21844068,\n",
              " 0.17510603,\n",
              " -0.18439578,\n",
              " 0.05874883,\n",
              " 0.22261883,\n",
              " 0.1674865,\n",
              " 0.15828387,\n",
              " 0.24784584,\n",
              " 0.18353789,\n",
              " 0.1638126,\n",
              " 0.24389145,\n",
              " 0.08790596,\n",
              " 0.10132022,\n",
              " 0.07829523,\n",
              " 0.11513744,\n",
              " 0.23754257,\n",
              " 0.1442268,\n",
              " 0.19574784,\n",
              " 0.16129081,\n",
              " -0.0057227425,\n",
              " 0.10646446,\n",
              " 0.17353787,\n",
              " 0.17132607,\n",
              " 0.18174334,\n",
              " 0.18977654,\n",
              " 0.2522938,\n",
              " 0.15255082,\n",
              " -0.10322149,\n",
              " 0.15698127,\n",
              " 0.09675819,\n",
              " 0.19129561,\n",
              " 0.20760097,\n",
              " -0.25837126,\n",
              " 0.21894267,\n",
              " 0.13423608,\n",
              " 0.01927409,\n",
              " 0.14145432,\n",
              " 0.21893708,\n",
              " 0.1390802,\n",
              " 0.16067994,\n",
              " -0.50207275,\n",
              " 0.18349673,\n",
              " 0.2356656,\n",
              " 0.15235065,\n",
              " 0.14162335,\n",
              " 0.15510835,\n",
              " 0.22084762,\n",
              " 0.23261058,\n",
              " 0.10263787,\n",
              " 0.12493886,\n",
              " 0.14165153,\n",
              " -0.25744087,\n",
              " 0.098895386,\n",
              " 0.15972441,\n",
              " 0.11458893,\n",
              " 0.19421779,\n",
              " 0.16697094,\n",
              " 0.14379394,\n",
              " 0.25342736,\n",
              " -0.025389548,\n",
              " 0.30438823,\n",
              " 0.15614429,\n",
              " 0.19441585,\n",
              " 0.11603019,\n",
              " -0.39052248,\n",
              " 0.15960671,\n",
              " 0.07792008,\n",
              " 0.14058642,\n",
              " 0.35097882,\n",
              " 0.10082252,\n",
              " 0.108551055,\n",
              " 0.23089634,\n",
              " 0.03969958,\n",
              " 0.15238969,\n",
              " 0.1663812,\n",
              " 0.011650283,\n",
              " 0.15910119,\n",
              " 0.12059581,\n",
              " 0.21323888,\n",
              " 0.10565798,\n",
              " 0.23720932,\n",
              " -0.2808731,\n",
              " 0.1459843,\n",
              " 0.1578368,\n",
              " 0.20581602,\n",
              " 0.21030007,\n",
              " 0.07049124,\n",
              " 0.24101633,\n",
              " 0.118792474,\n",
              " 0.06323539,\n",
              " 0.29915264,\n",
              " 0.16979007,\n",
              " 0.15676348,\n",
              " 0.16480294,\n",
              " 0.29275647,\n",
              " 0.21388744,\n",
              " 0.20127966,\n",
              " 0.17117363,\n",
              " 0.10092029,\n",
              " -0.01981571,\n",
              " -0.3132253,\n",
              " 0.10174751,\n",
              " 0.08350968,\n",
              " 0.20936392,\n",
              " 0.049735513,\n",
              " 0.20998986,\n",
              " -0.044220116,\n",
              " 0.033161502,\n",
              " 0.16240062,\n",
              " 0.20351039,\n",
              " 0.09382105,\n",
              " 0.2033455,\n",
              " 0.13605233,\n",
              " 0.15703268,\n",
              " 0.15164837,\n",
              " 0.13513765,\n",
              " 0.30801132,\n",
              " 0.4019918,\n",
              " 0.18070611,\n",
              " 0.18923117,\n",
              " 0.18099414,\n",
              " 0.08546604,\n",
              " 0.11204849,\n",
              " 0.14416589,\n",
              " 0.13175215,\n",
              " 0.20841494,\n",
              " 0.112206385,\n",
              " 0.10977313,\n",
              " 0.020048518,\n",
              " -0.05561086,\n",
              " 0.13069794,\n",
              " 0.17412195,\n",
              " 0.22810802,\n",
              " 0.15640628,\n",
              " 0.20179828,\n",
              " 0.1969329,\n",
              " 0.17644362,\n",
              " 0.17594178,\n",
              " 0.07683429,\n",
              " 0.017665777,\n",
              " -0.001995746,\n",
              " 0.29881874,\n",
              " 0.22730985,\n",
              " 0.21648075,\n",
              " 0.12830019,\n",
              " -0.0657759,\n",
              " 0.23107451,\n",
              " 0.17923589,\n",
              " 0.13694642,\n",
              " 0.13445526,\n",
              " 0.114308015,\n",
              " 0.16325277,\n",
              " -0.007375229,\n",
              " 0.22844796,\n",
              " 0.11875273,\n",
              " 0.09461315,\n",
              " 0.06448054,\n",
              " 0.14338163,\n",
              " 0.10273205,\n",
              " 0.20927446,\n",
              " 0.2668638,\n",
              " 0.19665116,\n",
              " 0.14317867,\n",
              " 0.1478359,\n",
              " 0.21467112,\n",
              " 0.13537823,\n",
              " 0.07191342,\n",
              " 0.2231222,\n",
              " 0.10041393,\n",
              " 0.16695794,\n",
              " 0.10930483,\n",
              " 0.19416945,\n",
              " 0.15609328,\n",
              " -0.43988085,\n",
              " 0.006286029,\n",
              " 0.12685858,\n",
              " 0.19721772,\n",
              " 0.11986251,\n",
              " 0.008503806,\n",
              " 0.11244522,\n",
              " 0.18889405,\n",
              " 0.117128626,\n",
              " 0.18840614,\n",
              " 0.20111646,\n",
              " 0.08308722,\n",
              " 0.12128274,\n",
              " 0.5247284,\n",
              " 0.2612823,\n",
              " 0.22433643,\n",
              " 0.15594564,\n",
              " 0.09935866,\n",
              " 0.15350664,\n",
              " 0.1477317,\n",
              " 0.26132688,\n",
              " 0.10808794,\n",
              " 0.14818065,\n",
              " 0.05583917,\n",
              " 0.04442734,\n",
              " 0.14070432,\n",
              " 0.05114417,\n",
              " 0.1287879,\n",
              " 0.15537693,\n",
              " 0.085419804,\n",
              " 0.20624906,\n",
              " 0.11539525,\n",
              " 0.30199674,\n",
              " 0.04539435,\n",
              " 0.19497603,\n",
              " 0.15052296,\n",
              " 0.17890726,\n",
              " 0.12238346,\n",
              " 0.1540507,\n",
              " 0.24010257,\n",
              " 0.18672,\n",
              " 0.1677572,\n",
              " 0.07025845,\n",
              " 0.156752,\n",
              " 0.22600307,\n",
              " 0.162791,\n",
              " 0.13680741,\n",
              " 0.14105672,\n",
              " 0.08882876,\n",
              " 0.12584491,\n",
              " 0.21744382,\n",
              " 0.23210248,\n",
              " 0.24114478,\n",
              " 0.20313996,\n",
              " 0.14313132,\n",
              " 0.20517005,\n",
              " 0.108853936,\n",
              " 0.14810042,\n",
              " 0.20054986,\n",
              " 0.07179473,\n",
              " 0.11567235,\n",
              " 0.08303076,\n",
              " 0.13600783,\n",
              " 0.10962418,\n",
              " 0.19548394,\n",
              " 0.033510905,\n",
              " 0.1370054,\n",
              " 0.23437403,\n",
              " 0.16853602,\n",
              " 0.15874366,\n",
              " 0.12592296,\n",
              " 0.19104072,\n",
              " 0.22480097,\n",
              " 0.09401479,\n",
              " 0.23099223,\n",
              " 0.032298688,\n",
              " 0.19054832,\n",
              " 0.11740647,\n",
              " 0.15273926,\n",
              " 0.072471246,\n",
              " 0.120013684,\n",
              " 0.13655877,\n",
              " 0.11802459,\n",
              " 0.17469296,\n",
              " 0.19342871,\n",
              " 0.1612135,\n",
              " 0.15966842,\n",
              " 0.26619703,\n",
              " 0.15957452,\n",
              " 0.12357254,\n",
              " 0.1696427,\n",
              " 0.30587277,\n",
              " 0.13401487,\n",
              " 0.10818227,\n",
              " 0.23349686,\n",
              " 0.16253808,\n",
              " 0.13316867,\n",
              " 0.20652291,\n",
              " 0.21882004,\n",
              " 0.100478396,\n",
              " 0.08949247,\n",
              " 0.15747015,\n",
              " 0.1335446,\n",
              " 0.17081206,\n",
              " 0.13047922,\n",
              " -0.0020757578,\n",
              " 0.19561766,\n",
              " 0.08861789,\n",
              " 0.18910816,\n",
              " 0.08281319,\n",
              " 0.11983605,\n",
              " 0.113728866,\n",
              " 0.28975773,\n",
              " -0.0071949027,\n",
              " 0.104191884,\n",
              " 0.1840146,\n",
              " 0.20970744,\n",
              " 0.17250349,\n",
              " 0.15805307,\n",
              " 0.11118965,\n",
              " 0.07790828,\n",
              " 0.116328135,\n",
              " 0.20898859,\n",
              " 0.18981598,\n",
              " 0.05643292,\n",
              " 0.14620396,\n",
              " 0.17510606,\n",
              " -0.0043502413,\n",
              " 0.17976303,\n",
              " 0.19448982,\n",
              " 0.08958554,\n",
              " 0.15594862,\n",
              " 0.0804687,\n",
              " 0.15137513,\n",
              " 0.06534798,\n",
              " 0.19359837,\n",
              " 0.035145003,\n",
              " 0.2353973,\n",
              " 0.13369375,\n",
              " 0.15087174,\n",
              " 0.14658843,\n",
              " 0.24195684,\n",
              " 0.17934628,\n",
              " 0.033287417,\n",
              " 0.21189739,\n",
              " 0.27137554,\n",
              " 0.19001357,\n",
              " 0.18148457,\n",
              " 0.15321502,\n",
              " 0.121907696,\n",
              " 0.26710632,\n",
              " 0.10324292,\n",
              " 0.1371676,\n",
              " 0.094629765,\n",
              " 0.32403854,\n",
              " 0.21500129,\n",
              " 0.33015004,\n",
              " 0.31703475,\n",
              " 0.22748376,\n",
              " 0.17760053,\n",
              " 0.18908529,\n",
              " 0.029025454,\n",
              " 0.28858036,\n",
              " 0.21058656,\n",
              " 0.11038554,\n",
              " 0.18137199,\n",
              " 0.27653545,\n",
              " 0.3211238,\n",
              " 0.18735377,\n",
              " 0.1587274,\n",
              " 0.17639105,\n",
              " 0.43035012,\n",
              " 0.1400054,\n",
              " 0.2328042,\n",
              " 0.18936725,\n",
              " 0.15843402,\n",
              " 0.06427251,\n",
              " 0.17943685,\n",
              " 0.15529406,\n",
              " 0.23388304,\n",
              " 0.1780939,\n",
              " 0.40240648,\n",
              " 0.18854858,\n",
              " 0.18879308,\n",
              " -0.2995866,\n",
              " 0.15338239,\n",
              " 0.1355133,\n",
              " 0.11500347,\n",
              " -0.29653567,\n",
              " 0.10712309,\n",
              " 0.08063437,\n",
              " 0.16760793,\n",
              " 0.11908877,\n",
              " 0.12045281,\n",
              " 0.12201661,\n",
              " 0.10471232,\n",
              " 0.20786099,\n",
              " -0.0010637529,\n",
              " 0.16112135,\n",
              " 0.11108351,\n",
              " 0.18841402,\n",
              " 0.21337043,\n",
              " 0.16466923,\n",
              " 0.15320146,\n",
              " 0.17754732,\n",
              " 0.09845404,\n",
              " 0.21094932,\n",
              " 0.13086072,\n",
              " 0.1063066,\n",
              " 0.15304215,\n",
              " 0.072812214,\n",
              " 0.1573588,\n",
              " 0.10953279,\n",
              " 0.1455494,\n",
              " 0.1403641,\n",
              " 0.026123565,\n",
              " 0.57831556,\n",
              " 0.23084228,\n",
              " 0.21027954,\n",
              " 0.07394542,\n",
              " 0.08627002,\n",
              " 0.10001932,\n",
              " 0.24133615,\n",
              " 0.18061958,\n",
              " 0.16992763,\n",
              " 0.23601416,\n",
              " 0.1556357,\n",
              " 0.22856174,\n",
              " 0.15659843,\n",
              " 0.046436433,\n",
              " 0.24909298,\n",
              " 0.21158232,\n",
              " 0.15992735,\n",
              " 0.21031423,\n",
              " 0.20527816,\n",
              " 0.096784756,\n",
              " 0.010297287,\n",
              " 0.15493603,\n",
              " 0.12355387,\n",
              " 0.104727864,\n",
              " 0.091340825,\n",
              " 0.11993046,\n",
              " 0.13563013,\n",
              " 0.0837865,\n",
              " 0.17084794,\n",
              " 0.15310772,\n",
              " 0.21672145,\n",
              " 0.13309795,\n",
              " 0.17110457,\n",
              " 0.16330549,\n",
              " 0.1293808,\n",
              " 0.2841033,\n",
              " 0.15502052,\n",
              " 0.16069882,\n",
              " 0.12570322,\n",
              " 0.1392372,\n",
              " 0.16017283,\n",
              " 0.1509854,\n",
              " 0.15882695,\n",
              " 0.22867435,\n",
              " 0.18409355,\n",
              " 0.21299852,\n",
              " 0.14603963,\n",
              " 0.043398526,\n",
              " 0.10720964,\n",
              " 0.18177192,\n",
              " 0.17376049,\n",
              " 0.17866953,\n",
              " 0.27360815,\n",
              " 0.17501667,\n",
              " 0.14300153,\n",
              " 0.054734785,\n",
              " 0.23280431,\n",
              " 0.13927028,\n",
              " 0.019414384,\n",
              " 0.16181149,\n",
              " 0.15416251,\n",
              " 0.15403658,\n",
              " 0.19119065,\n",
              " 0.10936895,\n",
              " 0.1051206,\n",
              " 0.21897772,\n",
              " 0.2551226,\n",
              " 0.16375501,\n",
              " 0.09505126,\n",
              " 0.20630981,\n",
              " 0.19309448,\n",
              " 0.25135076,\n",
              " 0.03762007,\n",
              " 0.36639318,\n",
              " 0.15191554,\n",
              " 0.14399861,\n",
              " 0.16067673,\n",
              " 0.19832218,\n",
              " 0.059381012,\n",
              " 0.15049212,\n",
              " 0.22379214,\n",
              " 0.09632617,\n",
              " 0.22825953,\n",
              " 0.079728335,\n",
              " 0.08669528,\n",
              " 0.27481976,\n",
              " 0.19796501,\n",
              " 0.35019735,\n",
              " 0.121941134,\n",
              " 0.11836402,\n",
              " 0.2947494,\n",
              " -0.31171715,\n",
              " 0.1793314,\n",
              " 0.1898009,\n",
              " 0.45151648,\n",
              " 0.13263252,\n",
              " 0.22980635,\n",
              " 0.16850398,\n",
              " 0.21257488,\n",
              " 0.22695118,\n",
              " 0.08865619,\n",
              " 0.15523963,\n",
              " 0.20171352,\n",
              " 0.09344569,\n",
              " 0.12729347,\n",
              " -1.5119938,\n",
              " 0.22727145,\n",
              " 0.110899016,\n",
              " 0.27078393,\n",
              " 0.20438673,\n",
              " 0.22427095,\n",
              " 0.08747466,\n",
              " 0.22275008,\n",
              " 0.163702,\n",
              " 0.18792517,\n",
              " 0.25311103,\n",
              " 0.1885203,\n",
              " 0.2662804,\n",
              " 0.081777945,\n",
              " 0.1108228,\n",
              " 0.4038444,\n",
              " 0.14611025,\n",
              " 0.14575598,\n",
              " 0.16325502,\n",
              " 0.21211812,\n",
              " 0.2167707,\n",
              " 0.15345657,\n",
              " 0.14363626,\n",
              " 0.24196687,\n",
              " 0.20729478,\n",
              " 0.13082667,\n",
              " 0.085298836,\n",
              " 0.056141008,\n",
              " 0.0650927,\n",
              " 0.18886174,\n",
              " 0.16007014,\n",
              " 0.09741935,\n",
              " 0.15319264,\n",
              " 0.18881498,\n",
              " 0.148459,\n",
              " 0.16000547,\n",
              " 0.11360045,\n",
              " 0.35466066,\n",
              " 0.164006,\n",
              " 0.07702583,\n",
              " -0.23489921,\n",
              " 0.06757431,\n",
              " 0.23046137,\n",
              " 0.07893664,\n",
              " 0.2529518,\n",
              " 0.19109519,\n",
              " 0.30887398,\n",
              " 0.21664168,\n",
              " 0.15739362,\n",
              " 0.13979295,\n",
              " 0.081547275,\n",
              " 0.23211776,\n",
              " 0.09858847,\n",
              " -0.043779816,\n",
              " 0.13796227,\n",
              " 0.09512904,\n",
              " 0.119752616,\n",
              " 0.13098784,\n",
              " 0.20805329,\n",
              " 0.2242835,\n",
              " 0.11290079,\n",
              " 0.18117523,\n",
              " 0.106934145,\n",
              " 0.08696617,\n",
              " 0.13903295,\n",
              " 0.21207054,\n",
              " 0.13163902,\n",
              " 0.1444247,\n",
              " 0.21248494,\n",
              " 0.2321014,\n",
              " 0.20298107,\n",
              " 0.31318647,\n",
              " 0.28584564,\n",
              " 0.24037117,\n",
              " 0.15147534,\n",
              " 0.18676493,\n",
              " 0.09728651,\n",
              " 0.14082572,\n",
              " 0.16687052,\n",
              " 0.1372492,\n",
              " 0.18787608,\n",
              " 0.20010208,\n",
              " 0.14401348,\n",
              " 0.17896582,\n",
              " 0.14017116,\n",
              " 0.14556415,\n",
              " 0.011572596,\n",
              " 0.20662375,\n",
              " 0.31603342,\n",
              " 0.17206207,\n",
              " 0.18985118,\n",
              " 0.107244015,\n",
              " 0.20209888,\n",
              " 0.2248696,\n",
              " 0.23728092,\n",
              " 0.03200378,\n",
              " 0.1633129,\n",
              " 0.12318061,\n",
              " 0.20215906,\n",
              " 0.13858306,\n",
              " 0.14182507,\n",
              " 0.116791114,\n",
              " 0.24029516,\n",
              " 0.12096487,\n",
              " 0.2921053,\n",
              " 0.1549674,\n",
              " 0.17612982,\n",
              " 0.16291957,\n",
              " 0.17666076,\n",
              " 0.21574964,\n",
              " -0.0041975044,\n",
              " 0.2193719,\n",
              " 0.26378337,\n",
              " 0.1425012,\n",
              " 0.16300572,\n",
              " 0.100742385,\n",
              " 0.15706547,\n",
              " 0.19752334,\n",
              " 0.23527701,\n",
              " 0.5936175,\n",
              " 0.06732899,\n",
              " 0.05394166,\n",
              " 0.0880457,\n",
              " 0.19918787,\n",
              " 0.20510241,\n",
              " 0.16114086,\n",
              " 0.330847,\n",
              " 0.18814814,\n",
              " 0.15808913,\n",
              " 0.18840747,\n",
              " 0.24540327,\n",
              " 0.06444365,\n",
              " 0.0864844,\n",
              " 0.15762113,\n",
              " -0.17263351,\n",
              " 0.13457981,\n",
              " 0.11527936,\n",
              " 0.18483694,\n",
              " 0.11525802,\n",
              " 0.19764434,\n",
              " 0.049500402,\n",
              " 0.1197782,\n",
              " 0.15210067,\n",
              " 0.105501786,\n",
              " 0.10372156,\n",
              " 0.11776902,\n",
              " 0.1676862,\n",
              " 0.098452136,\n",
              " 0.22946404,\n",
              " 0.1470346,\n",
              " 0.19953838,\n",
              " 0.17384231,\n",
              " -0.09922604,\n",
              " 0.21743241,\n",
              " 0.2013355,\n",
              " 0.4073961,\n",
              " 0.22693585,\n",
              " 0.26044628,\n",
              " 0.15495653,\n",
              " 0.19011511,\n",
              " 0.13542534,\n",
              " 0.10765776,\n",
              " 0.256414,\n",
              " 0.11634627,\n",
              " 0.13844247,\n",
              " 0.25079694,\n",
              " 0.021740045,\n",
              " 0.073579386,\n",
              " 0.19807333,\n",
              " 0.15302144,\n",
              " 0.17596893,\n",
              " 0.21030012,\n",
              " 0.09714945,\n",
              " 0.2889744,\n",
              " 0.12103486,\n",
              " 0.09500456,\n",
              " 0.21813023,\n",
              " 0.0713851,\n",
              " 0.096119314,\n",
              " 0.14323111,\n",
              " 0.07970066,\n",
              " 0.17894681,\n",
              " 0.16672309,\n",
              " 0.08639835,\n",
              " 0.3096191,\n",
              " 0.049335692,\n",
              " 0.099218026,\n",
              " 0.15452136,\n",
              " 0.11069512,\n",
              " 0.14965962,\n",
              " 0.112483785,\n",
              " 0.17117524,\n",
              " 0.17285015,\n",
              " 0.13049911,\n",
              " 0.05969729,\n",
              " 0.12139644,\n",
              " 0.14977945,\n",
              " 0.14785427,\n",
              " 0.21395826,\n",
              " 0.15081331,\n",
              " 0.10669176,\n",
              " 0.30846187,\n",
              " 0.14574073,\n",
              " 0.106766224,\n",
              " 0.11636928,\n",
              " 0.14223471,\n",
              " 0.098059446,\n",
              " -0.03633335,\n",
              " 0.19891158,\n",
              " 0.16480792,\n",
              " 0.1742584,\n",
              " 0.24549899,\n",
              " 0.19184737,\n",
              " 0.15354666,\n",
              " 0.064943776,\n",
              " 0.20680279,\n",
              " 0.02895281,\n",
              " 0.09874396,\n",
              " 0.10023993,\n",
              " 0.17023629,\n",
              " 0.26628038,\n",
              " 0.07904598,\n",
              " 0.2636948,\n",
              " 0.21948524,\n",
              " 0.11066042,\n",
              " 0.11518249,\n",
              " 0.0769341,\n",
              " 0.10627809,\n",
              " 0.20207016,\n",
              " 0.15550104,\n",
              " 0.14565906,\n",
              " 0.2332728,\n",
              " 0.04653104,\n",
              " 0.16488054,\n",
              " 0.17018132,\n",
              " 0.15666623,\n",
              " 0.13521472,\n",
              " 0.11824775,\n",
              " 0.10128477,\n",
              " 0.119998276,\n",
              " 0.08538717,\n",
              " 0.21579973,\n",
              " 0.20717947,\n",
              " 0.21117671,\n",
              " 0.23530595,\n",
              " 0.15408936,\n",
              " 0.17887034,\n",
              " 0.23603414,\n",
              " 0.1841859,\n",
              " 0.15284765,\n",
              " 0.17932396,\n",
              " 0.17898512,\n",
              " 0.19696547,\n",
              " 0.17141445,\n",
              " 0.11256492,\n",
              " 0.1796568,\n",
              " 0.23279475,\n",
              " 0.22635737,\n",
              " 0.16023956,\n",
              " 0.106478184,\n",
              " 0.10540281,\n",
              " 0.19035527,\n",
              " 0.14332035,\n",
              " 0.09591089,\n",
              " 0.008577522,\n",
              " 0.084869996,\n",
              " 0.2161655,\n",
              " 0.15072612,\n",
              " 0.1538315,\n",
              " -0.28931725,\n",
              " 0.081757985,\n",
              " 0.17773221,\n",
              " 0.09619109,\n",
              " 0.14552274,\n",
              " 0.21690166,\n",
              " -0.0022101067,\n",
              " 0.27713788,\n",
              " 0.16047236,\n",
              " 0.19688259,\n",
              " 0.1019261,\n",
              " 0.182575,\n",
              " 0.3743002,\n",
              " 0.06907897,\n",
              " 0.145624,\n",
              " 0.24509232,\n",
              " 0.23046024,\n",
              " 0.12472099,\n",
              " 0.10806565,\n",
              " 0.21959284,\n",
              " 0.1507474,\n",
              " 0.23032361,\n",
              " 0.22915886,\n",
              " 0.20446847,\n",
              " 0.06635457,\n",
              " 0.2024682,\n",
              " 0.18893884,\n",
              " 0.3128853,\n",
              " 0.17522602,\n",
              " 0.14679335,\n",
              " 0.1946251,\n",
              " 0.23255672,\n",
              " 0.10415821,\n",
              " 0.19356985,\n",
              " 0.13561314,\n",
              " 0.078715876,\n",
              " 0.1406572,\n",
              " 0.28035787,\n",
              " 0.15479596,\n",
              " 0.16042368,\n",
              " 0.25556946,\n",
              " 0.2746549,\n",
              " 0.18917562,\n",
              " 0.09956826,\n",
              " 0.33086693,\n",
              " 0.17050053,\n",
              " 0.25240472,\n",
              " 0.13581312,\n",
              " 0.0985464,\n",
              " 0.15617153,\n",
              " 0.16397288,\n",
              " 0.19034551,\n",
              " 0.17039384,\n",
              " 0.21927238,\n",
              " 0.19566208,\n",
              " 0.18933521,\n",
              " 0.22803552,\n",
              " 0.049603853,\n",
              " 0.16469452,\n",
              " 0.074263066,\n",
              " 0.17071898,\n",
              " 0.10411619,\n",
              " 0.032798287,\n",
              " 0.08073494,\n",
              " -0.0055897795,\n",
              " 0.07797618,\n",
              " 0.1362208,\n",
              " 0.1709745,\n",
              " 0.10464746,\n",
              " 0.22659165,\n",
              " 0.19583215,\n",
              " 0.18838239,\n",
              " 0.16796611,\n",
              " 0.23773347,\n",
              " 0.15251616,\n",
              " 0.096127614,\n",
              " 0.27793473,\n",
              " 0.18813886,\n",
              " 0.21065135,\n",
              " 0.10685603,\n",
              " 0.2208472,\n",
              " 0.18231164,\n",
              " 0.16220279,\n",
              " 0.1161824,\n",
              " 0.27248767,\n",
              " 0.20871018,\n",
              " -0.12803341,\n",
              " 0.19556561,\n",
              " 0.21036588,\n",
              " 0.04792774,\n",
              " 0.29566804,\n",
              " -0.00832982,\n",
              " 0.1474464,\n",
              " 0.1921133,\n",
              " 0.049976695,\n",
              " 0.14552271,\n",
              " 0.116792396,\n",
              " 0.2148485,\n",
              " 0.17199971,\n",
              " 0.26119712,\n",
              " 0.16494359,\n",
              " 0.12693816,\n",
              " 0.20086776,\n",
              " 0.018675331,\n",
              " 0.13536151,\n",
              " 0.17730555,\n",
              " 0.1756219,\n",
              " 0.09549683,\n",
              " -0.0040450953,\n",
              " 0.11830315,\n",
              " 0.16897695,\n",
              " 0.12033181,\n",
              " 0.14763628,\n",
              " 0.14887555,\n",
              " 0.21350001,\n",
              " 0.12829144,\n",
              " 0.16995732,\n",
              " 0.19817775,\n",
              " 0.14605664,\n",
              " 0.24186172,\n",
              " 0.2051154,\n",
              " 0.19004957,\n",
              " 0.15006489,\n",
              " 0.175918,\n",
              " 0.13778791,\n",
              " 0.05693007,\n",
              " 0.11010179,\n",
              " 0.14252721,\n",
              " 0.03691222,\n",
              " 0.17314121,\n",
              " 0.18618731,\n",
              " 0.17873214,\n",
              " 0.06735872,\n",
              " 0.04332376,\n",
              " 0.2157953,\n",
              " 0.057255972,\n",
              " 0.1607915,\n",
              " 0.50585353,\n",
              " 0.09032127,\n",
              " 0.25563744,\n",
              " 0.16771634,\n",
              " 0.10242127,\n",
              " 0.26297355,\n",
              " -0.06167757,\n",
              " 0.17925306,\n",
              " 0.09652938,\n",
              " 0.15464856,\n",
              " 0.0947852,\n",
              " 0.16627511,\n",
              " 0.064277425,\n",
              " 0.043955144,\n",
              " 0.19138466,\n",
              " 0.15449469,\n",
              " 0.10022232,\n",
              " 0.23229283,\n",
              " 0.16909692,\n",
              " 0.100660875,\n",
              " 0.10201272,\n",
              " 0.28410324,\n",
              " 0.14093255,\n",
              " 0.108810216,\n",
              " 0.19665115,\n",
              " 0.14172477,\n",
              " 0.20168294,\n",
              " 0.17226945,\n",
              " 0.15639518,\n",
              " 0.1366094,\n",
              " 0.20085518,\n",
              " 0.50803566,\n",
              " 0.14024849,\n",
              " 0.17187555,\n",
              " 0.10836144,\n",
              " 0.087212086,\n",
              " 0.20936386,\n",
              " 0.20430852,\n",
              " 0.30560538,\n",
              " 0.17874405,\n",
              " 0.24139965,\n",
              " 0.13338928,\n",
              " 0.14338149,\n",
              " 0.15028304,\n",
              " 0.12461461,\n",
              " -0.04061697,\n",
              " 0.23201974,\n",
              " 0.007896829,\n",
              " 0.09684566,\n",
              " 0.17593774,\n",
              " 0.05076554,\n",
              " 0.16218439,\n",
              " 0.16265228,\n",
              " 0.18852904,\n",
              " 0.014717381,\n",
              " 0.096888095,\n",
              " 0.10051352,\n",
              " 0.143977,\n",
              " 0.15227546,\n",
              " 0.13402115,\n",
              " 0.15615265,\n",
              " 0.18614325,\n",
              " 0.11289759,\n",
              " 0.106113836,\n",
              " 0.02538002,\n",
              " 0.15317981,\n",
              " 0.13716605,\n",
              " 0.033242967,\n",
              " 0.18691531,\n",
              " 0.07683197,\n",
              " 0.07536097,\n",
              " 0.062101875,\n",
              " 0.23583035,\n",
              " 0.20054536,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}